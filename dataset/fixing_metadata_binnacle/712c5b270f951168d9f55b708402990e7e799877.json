{"seed":382749730,"processedDockerfileHash":"ae919cb48ab04c095c2b29b8473baa55","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-copy-instead-of-add","have-a-healthcheck","have-a-user"],"processedDockerfile":"#   Licensed to the Apache Software Foundation (ASF) under one or more\n#   contributor license agreements.  See the NOTICE file distributed with\n#   this work for additional information regarding copyright ownership.\n#   The ASF licenses this file to You under the Apache License, Version 2.0\n#   (the \"License\"); you may not use this file except in compliance with\n#   the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\nFROM centos:centos6\nENV SPARK_PROFILE=\"2.0\"\nENV SPARK_VERSION=\"2.0.0\"\nENV HADOOP_PROFILE=\"2.7\"\nENV HADOOP_VERSION=\"2.7.0\"\n#   Update the image with the latest packages\nRUN yum update -y ; yum clean all\n#   Get utils\nRUN yum install -y wget tar curl \\\n && yum clean all\n#   Remove old jdk\nRUN yum remove java ; yum remove jdk\n#   install jdk7\nRUN yum install -y java-1.7.0-openjdk-devel\nENV JAVA_HOME=\"/usr/lib/jvm/java\"\nENV PATH=\"$PATH:$JAVA_HOME/bin\"\n#   install hadoop \nRUN yum install -y curl which tar sudo openssh-server openssh-clients rsync\n#   hadoop\nRUN curl -s https://archive.apache.org/dist/hadoop/core/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz | tar -xz -C /usr/local/\nRUN cd /usr/local \\\n && ln -s ./hadoop-$HADOOP_VERSION hadoop\nENV HADOOP_PREFIX=\"/usr/local/hadoop\"\nENV HADOOP_COMMON_HOME=\"/usr/local/hadoop\"\nENV HADOOP_HDFS_HOME=\"/usr/local/hadoop\"\nENV HADOOP_MAPRED_HOME=\"/usr/local/hadoop\"\nENV HADOOP_YARN_HOME=\"/usr/local/hadoop\"\nENV HADOOP_CONF_DIR=\"/usr/local/hadoop/etc/hadoop\"\nRUN sed -i '/^export JAVA_HOME/ s:.*:export JAVA_HOME=/usr/lib/jvm/jre-1.7.0-openjdk.x86_64\\nexport HADOOP_PREFIX=/usr/local/hadoop\\nexport HADOOP_HOME=/usr/local/hadoop\\n:' $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\nRUN sed -i '/^export HADOOP_CONF_DIR/ s:.*:export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop/:' $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\nRUN mkdir $HADOOP_PREFIX/input\nRUN cp $HADOOP_PREFIX/etc/hadoop/*.xml $HADOOP_PREFIX/input\n#   hadoop configurations\nCOPY hdfs_conf/core-site.xml $HADOOP_PREFIX/etc/hadoop/core-site.xml\nCOPY hdfs_conf/hdfs-site.xml $HADOOP_PREFIX/etc/hadoop/hdfs-site.xml\nCOPY hdfs_conf/mapred-site.xml $HADOOP_PREFIX/etc/hadoop/mapred-site.xml\nCOPY hdfs_conf/yarn-site.xml $HADOOP_PREFIX/etc/hadoop/yarn-site.xml\nRUN mkdir /data/\nRUN chmod 777 /data/\nRUN $HADOOP_PREFIX/bin/hdfs namenode -format\nRUN rm /usr/local/hadoop/lib/native/*\nRUN curl -Ls http://dl.bintray.com/sequenceiq/sequenceiq-bin/hadoop-native-64-$HADOOP_VERSION.tar | tar -x -C /usr/local/hadoop/lib/native/\n#   install spark\nRUN curl -s http://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_PROFILE.tgz | tar -xz -C /usr/local/\nRUN cd /usr/local \\\n && ln -s spark-$SPARK_VERSION-bin-hadoop$HADOOP_PROFILE spark\nENV SPARK_HOME=\"/usr/local/spark\"\nENV YARN_CONF_DIR=\"$HADOOP_PREFIX/etc/hadoop\"\nENV PATH=\"$PATH:$SPARK_HOME/bin:$HADOOP_PREFIX/bin\"\n#   passwordless ssh\nRUN ssh-keygen -q -N \"\" -t dsa -f /etc/ssh/ssh_host_dsa_key\nRUN ssh-keygen -q -N \"\" -t rsa -f /etc/ssh/ssh_host_rsa_key\nRUN ssh-keygen -q -N \"\" -t rsa -f /root/.ssh/id_rsa\nRUN cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys\nCOPY ssh_config /root/.ssh/config\nRUN chmod 600 /root/.ssh/config\nRUN chown root:root /root/.ssh/config\nRUN chmod +x /usr/local/hadoop/etc/hadoop/*-env.sh\n#   update boot script\nCOPY entrypoint.sh /etc/entrypoint.sh\nRUN chown root.root /etc/entrypoint.sh\nRUN chmod 700 /etc/entrypoint.sh\n#   Hdfs ports\nEXPOSE 50010/tcp 50020/tcp 50070/tcp 50075/tcp 50090/tcp\n#   Mapred ports\nEXPOSE 9000/tcp 9001/tcp\n#  Yarn ports\nEXPOSE 8030/tcp 8031/tcp 8032/tcp 8033/tcp 8040/tcp 8042/tcp 8088/tcp\n#  spark\nEXPOSE 8080/tcp 7077/tcp 8888/tcp 8081/tcp\nENTRYPOINT [\"/etc/entrypoint.sh\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"#  Licensed to the Apache Software Foundation (ASF) under one or more\n#  contributor license agreements.  See the NOTICE file distributed with\n#  this work for additional information regarding copyright ownership.\n#  The ASF licenses this file to You under the Apache License, Version 2.0\n#  (the \"License\"); you may not use this file except in compliance with\n#  the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\nFROM centos:centos6\nENV SPARK_PROFILE=\"2.0\"\nENV SPARK_VERSION=\"2.0.0\"\nENV HADOOP_PROFILE=\"2.7\"\nENV HADOOP_VERSION=\"2.7.0\"\n#  Update the image with the latest packages\nRUN yum update -y ; yum clean all\n#  Get utils\nRUN yum install -y wget tar curl \\\n && yum clean all\n#  Remove old jdk\nRUN yum remove java ; yum remove jdk\n#  install jdk7\nRUN yum install -y java-1.7.0-openjdk-devel\nENV JAVA_HOME=\"/usr/lib/jvm/java\"\nENV PATH=\"$PATH:$JAVA_HOME/bin\"\n#  install hadoop \nRUN yum install -y curl which tar sudo openssh-server openssh-clients rsync\n#  hadoop\nRUN curl -s https://archive.apache.org/dist/hadoop/core/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz | tar -xz -C /usr/local/\nRUN cd /usr/local \\\n && ln -s ./hadoop-$HADOOP_VERSION hadoop\nENV HADOOP_PREFIX=\"/usr/local/hadoop\"\nENV HADOOP_COMMON_HOME=\"/usr/local/hadoop\"\nENV HADOOP_HDFS_HOME=\"/usr/local/hadoop\"\nENV HADOOP_MAPRED_HOME=\"/usr/local/hadoop\"\nENV HADOOP_YARN_HOME=\"/usr/local/hadoop\"\nENV HADOOP_CONF_DIR=\"/usr/local/hadoop/etc/hadoop\"\nRUN sed -i '/^export JAVA_HOME/ s:.*:export JAVA_HOME=/usr/lib/jvm/jre-1.7.0-openjdk.x86_64\\nexport HADOOP_PREFIX=/usr/local/hadoop\\nexport HADOOP_HOME=/usr/local/hadoop\\n:' $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\nRUN sed -i '/^export HADOOP_CONF_DIR/ s:.*:export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop/:' $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\nRUN mkdir $HADOOP_PREFIX/input\nRUN cp $HADOOP_PREFIX/etc/hadoop/*.xml $HADOOP_PREFIX/input\n#  hadoop configurations\nADD hdfs_conf/core-site.xml $HADOOP_PREFIX/etc/hadoop/core-site.xml\nADD hdfs_conf/hdfs-site.xml $HADOOP_PREFIX/etc/hadoop/hdfs-site.xml\nADD hdfs_conf/mapred-site.xml $HADOOP_PREFIX/etc/hadoop/mapred-site.xml\nADD hdfs_conf/yarn-site.xml $HADOOP_PREFIX/etc/hadoop/yarn-site.xml\nRUN mkdir /data/\nRUN chmod 777 /data/\nRUN $HADOOP_PREFIX/bin/hdfs namenode -format\nRUN rm /usr/local/hadoop/lib/native/*\nRUN curl -Ls http://dl.bintray.com/sequenceiq/sequenceiq-bin/hadoop-native-64-$HADOOP_VERSION.tar | tar -x -C /usr/local/hadoop/lib/native/\n#  install spark\nRUN curl -s http://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_PROFILE.tgz | tar -xz -C /usr/local/\nRUN cd /usr/local \\\n && ln -s spark-$SPARK_VERSION-bin-hadoop$HADOOP_PROFILE spark\nENV SPARK_HOME=\"/usr/local/spark\"\nENV YARN_CONF_DIR=\"$HADOOP_PREFIX/etc/hadoop\"\nENV PATH=\"$PATH:$SPARK_HOME/bin:$HADOOP_PREFIX/bin\"\n#  passwordless ssh\nRUN ssh-keygen -q -N \"\" -t dsa -f /etc/ssh/ssh_host_dsa_key\nRUN ssh-keygen -q -N \"\" -t rsa -f /etc/ssh/ssh_host_rsa_key\nRUN ssh-keygen -q -N \"\" -t rsa -f /root/.ssh/id_rsa\nRUN cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys\nADD ssh_config /root/.ssh/config\nRUN chmod 600 /root/.ssh/config\nRUN chown root:root /root/.ssh/config\nRUN chmod +x /usr/local/hadoop/etc/hadoop/*-env.sh\n#  update boot script\nCOPY entrypoint.sh /etc/entrypoint.sh\nRUN chown root.root /etc/entrypoint.sh\nRUN chmod 700 /etc/entrypoint.sh\n#  Hdfs ports\nEXPOSE 50010/tcp 50020/tcp 50070/tcp 50075/tcp 50090/tcp\n#  Mapred ports\nEXPOSE 9000/tcp 9001/tcp\n# Yarn ports\nEXPOSE 8030/tcp 8031/tcp 8032/tcp 8033/tcp 8040/tcp 8042/tcp 8088/tcp\n# spark\nEXPOSE 8080/tcp 7077/tcp 8888/tcp 8081/tcp\nENTRYPOINT [\"/etc/entrypoint.sh\"]\n","injectedSmells":[],"originalDockerfileHash":"0ac0b7e245974e2046f4a31116d04c22","successfullyInjectedSmells":[],"originalDockerfileUglified":"#   Licensed to the Apache Software Foundation (ASF) under one or more\n#   contributor license agreements.  See the NOTICE file distributed with\n#   this work for additional information regarding copyright ownership.\n#   The ASF licenses this file to You under the Apache License, Version 2.0\n#   (the \"License\"); you may not use this file except in compliance with\n#   the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\nFROM centos:centos6\nENV SPARK_PROFILE=\"2.0\"\nENV SPARK_VERSION=\"2.0.0\"\nENV HADOOP_PROFILE=\"2.7\"\nENV HADOOP_VERSION=\"2.7.0\"\n#   Update the image with the latest packages\nRUN yum update -y ; yum clean all\n#   Get utils\nRUN yum install -y wget tar curl \\\n && yum clean all\n#   Remove old jdk\nRUN yum remove java ; yum remove jdk\n#   install jdk7\nRUN yum install -y java-1.7.0-openjdk-devel\nENV JAVA_HOME=\"/usr/lib/jvm/java\"\nENV PATH=\"$PATH:$JAVA_HOME/bin\"\n#   install hadoop \nRUN yum install -y curl which tar sudo openssh-server openssh-clients rsync\n#   hadoop\nRUN curl -s https://archive.apache.org/dist/hadoop/core/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz | tar -xz -C /usr/local/\nRUN cd /usr/local \\\n && ln -s ./hadoop-$HADOOP_VERSION hadoop\nENV HADOOP_PREFIX=\"/usr/local/hadoop\"\nENV HADOOP_COMMON_HOME=\"/usr/local/hadoop\"\nENV HADOOP_HDFS_HOME=\"/usr/local/hadoop\"\nENV HADOOP_MAPRED_HOME=\"/usr/local/hadoop\"\nENV HADOOP_YARN_HOME=\"/usr/local/hadoop\"\nENV HADOOP_CONF_DIR=\"/usr/local/hadoop/etc/hadoop\"\nRUN sed -i '/^export JAVA_HOME/ s:.*:export JAVA_HOME=/usr/lib/jvm/jre-1.7.0-openjdk.x86_64\\nexport HADOOP_PREFIX=/usr/local/hadoop\\nexport HADOOP_HOME=/usr/local/hadoop\\n:' $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\nRUN sed -i '/^export HADOOP_CONF_DIR/ s:.*:export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop/:' $HADOOP_PREFIX/etc/hadoop/hadoop-env.sh\nRUN mkdir $HADOOP_PREFIX/input\nRUN cp $HADOOP_PREFIX/etc/hadoop/*.xml $HADOOP_PREFIX/input\n#   hadoop configurations\nADD hdfs_conf/core-site.xml $HADOOP_PREFIX/etc/hadoop/core-site.xml\nADD hdfs_conf/hdfs-site.xml $HADOOP_PREFIX/etc/hadoop/hdfs-site.xml\nADD hdfs_conf/mapred-site.xml $HADOOP_PREFIX/etc/hadoop/mapred-site.xml\nADD hdfs_conf/yarn-site.xml $HADOOP_PREFIX/etc/hadoop/yarn-site.xml\nRUN mkdir /data/\nRUN chmod 777 /data/\nRUN $HADOOP_PREFIX/bin/hdfs namenode -format\nRUN rm /usr/local/hadoop/lib/native/*\nRUN curl -Ls http://dl.bintray.com/sequenceiq/sequenceiq-bin/hadoop-native-64-$HADOOP_VERSION.tar | tar -x -C /usr/local/hadoop/lib/native/\n#   install spark\nRUN curl -s http://archive.apache.org/dist/spark/spark-$SPARK_VERSION/spark-$SPARK_VERSION-bin-hadoop$HADOOP_PROFILE.tgz | tar -xz -C /usr/local/\nRUN cd /usr/local \\\n && ln -s spark-$SPARK_VERSION-bin-hadoop$HADOOP_PROFILE spark\nENV SPARK_HOME=\"/usr/local/spark\"\nENV YARN_CONF_DIR=\"$HADOOP_PREFIX/etc/hadoop\"\nENV PATH=\"$PATH:$SPARK_HOME/bin:$HADOOP_PREFIX/bin\"\n#   passwordless ssh\nRUN ssh-keygen -q -N \"\" -t dsa -f /etc/ssh/ssh_host_dsa_key\nRUN ssh-keygen -q -N \"\" -t rsa -f /etc/ssh/ssh_host_rsa_key\nRUN ssh-keygen -q -N \"\" -t rsa -f /root/.ssh/id_rsa\nRUN cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys\nADD ssh_config /root/.ssh/config\nRUN chmod 600 /root/.ssh/config\nRUN chown root:root /root/.ssh/config\nRUN chmod +x /usr/local/hadoop/etc/hadoop/*-env.sh\n#   update boot script\nCOPY entrypoint.sh /etc/entrypoint.sh\nRUN chown root.root /etc/entrypoint.sh\nRUN chmod 700 /etc/entrypoint.sh\n#   Hdfs ports\nEXPOSE 50010/tcp 50020/tcp 50070/tcp 50075/tcp 50090/tcp\n#   Mapred ports\nEXPOSE 9000/tcp 9001/tcp\n#  Yarn ports\nEXPOSE 8030/tcp 8031/tcp 8032/tcp 8033/tcp 8040/tcp 8042/tcp 8088/tcp\n#  spark\nEXPOSE 8080/tcp 7077/tcp 8888/tcp 8081/tcp\nENTRYPOINT [\"/etc/entrypoint.sh\"]\n","originalDockerfileUglifiedHash":"69d0163a09cd3fe8b6356f389a362ecd","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/712c5b270f951168d9f55b708402990e7e799877.dockerfile"}