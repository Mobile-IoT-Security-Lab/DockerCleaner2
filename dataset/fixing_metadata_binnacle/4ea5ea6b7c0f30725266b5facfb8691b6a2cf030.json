{"seed":14691709,"processedDockerfileHash":"016fd5c54210118cf5f392e6364f4e5b","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["pin-package-manager-versions-apt-get","use-copy-instead-of-add","have-a-healthcheck"],"processedDockerfile":"#\n#   Licensed to the Apache Software Foundation (ASF) under one or more\n#   contributor license agreements.  See the NOTICE file distributed with\n#   this work for additional information regarding copyright ownership.\n#   The ASF licenses this file to You under the Apache License, Version 2.0\n#   (the \"License\"); you may not use this file except in compliance with\n#   the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#\n#   WARNING: THIS DOCKERFILE IS NOT INTENDED FOR PRODUCTION USE OR DEPLOYMENT. AT\n#            THIS POINT, THIS IS ONLY INTENDED FOR USE IN AUTOMATED TESTS.\nFROM ubuntu:xenial\nUSER root\nENV DEBIAN_FRONTEND=\"noninteractive\"\nENV LANGUAGE=\"en_US.UTF-8\"\nENV LANG=\"en_US.UTF-8\"\nENV LC_ALL=\"en_US.UTF-8\"\nENV LC_CTYPE=\"en_US.UTF-8\"\nENV LC_MESSAGES=\"en_US.UTF-8\"\nENV HADOOP_VERSION=\"2.6.0\"\nENV HADOOP_DISTRO=\"cdh\"\nENV HADOOP_HOME=\"/tmp/hadoop-${HADOOP_DISTRO}\"\nENV HIVE_HOME=\"/tmp/hive\"\nENV JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64/\"\nRUN mkdir ${HADOOP_HOME} \\\n && mkdir ${HIVE_HOME} \\\n && mkdir /tmp/minicluster \\\n && mkdir -p /user/hive/warehouse \\\n && chmod -R 777 ${HIVE_HOME} \\\n && chmod -R 777 /user/\n#   Add nodejs repo and key\nCOPY nodesource.gpg.key /tmp/nodesource.gpg.key\nRUN apt-key add /tmp/nodesource.gpg.key\nRUN echo 'deb http://deb.nodesource.com/node_8.x xenial main' > /etc/apt/sources.list.d/nodesource.list\nRUN echo 'deb-src http://deb.nodesource.com/node_8.x xenial main' >> /etc/apt/sources.list.d/nodesource.list\nRUN apt-get update \\\n && apt-get install --no-install-recommends openjdk-8-jdk=8u292-b10-0ubuntu1~16.04.1 wget=1.17.1-1ubuntu1.5 curl=7.47.0-1ubuntu2.19 gcc=4:5.3.1-1ubuntu1 g++=4:5.3.1-1ubuntu1 python-dev=2.7.12-1~16.04 python3-dev=3.5.1-3 python-pip=8.1.1-2ubuntu0.6 python3-pip=8.1.1-2ubuntu0.6 python-virtualenv=15.0.1+ds-3ubuntu1.1 python3-venv=3.5.1-3 python-setuptools=20.7.0-1 python-pkg-resources=20.7.0-1 python3-setuptools=20.7.0-1 python3-pkg-resources=20.7.0-1 make=4.1-6 nodejs=4.2.6~dfsg-1ubuntu4.2 vim=2:7.4.1689-3ubuntu1.5 less=481-2.1ubuntu0.2 git=1:2.7.4-0ubuntu1.10 unzip=6.0-20ubuntu1.1 sudo=1.8.16-0ubuntu1.10 ldap-utils=2.4.42+dfsg-2ubuntu3.13 mysql-client-core-5.7=5.7.33-0ubuntu0.16.04.1 mysql-client-5.7=5.7.33-0ubuntu0.16.04.1 libmysqlclient-dev=5.7.33-0ubuntu0.16.04.1 postgresql-client=9.5+173ubuntu0.3 sqlite3=3.11.0-1ubuntu1.5 libkrb5-dev=1.13.2+dfsg-5ubuntu2.2 libsasl2-dev=2.1.26.dfsg1-14ubuntu0.2 krb5-user=1.13.2+dfsg-5ubuntu2.2 openssh-client=1:7.2p2-4ubuntu2.10 openssh-server=1:7.2p2-4ubuntu2.10 python-selinux=2.4-3build2 sasl2-bin=2.1.26.dfsg1-14ubuntu0.2 libsasl2-2=2.1.26.dfsg1-14ubuntu0.2 libsasl2-dev=2.1.26.dfsg1-14ubuntu0.2 libsasl2-modules=2.1.26.dfsg1-14ubuntu0.2 locales=2.23-0ubuntu11.3 -y \\\n && rm -rf /var/lib/apt/lists/*\nRUN sed -i 's/^# en_US.UTF-8 UTF-8$/en_US.UTF-8 UTF-8/g' /etc/locale.gen \\\n && locale-gen \\\n && update-locale LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8\n#   Install Hadoop\n#   --absolute-names is a work around to avoid this issue https://github.com/docker/hub-feedback/issues/727\nRUN cd /tmp \\\n && wget -q https://archive.cloudera.com/cdh5/cdh/5/hadoop-${HADOOP_VERSION}-cdh5.11.0.tar.gz \\\n && tar xzf hadoop-${HADOOP_VERSION}-cdh5.11.0.tar.gz --absolute-names --strip-components 1 -C $HADOOP_HOME \\\n && rm hadoop-${HADOOP_VERSION}-cdh5.11.0.tar.gz\n#   Install Hive\nRUN cd /tmp \\\n && wget -q https://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.11.0.tar.gz \\\n && tar xzf hive-1.1.0-cdh5.11.0.tar.gz --strip-components 1 -C $HIVE_HOME \\\n && rm hive-1.1.0-cdh5.11.0.tar.gz\n#   Install MiniCluster\nRUN cd /tmp \\\n && wget -q https://github.com/bolkedebruin/minicluster/releases/download/1.1/minicluster-1.1-SNAPSHOT-bin.zip \\\n && unzip minicluster-1.1-SNAPSHOT-bin.zip -d /tmp \\\n && rm minicluster-1.1-SNAPSHOT-bin.zip\nRUN adduser airflow \\\n && echo \"airflow ALL=(ALL) NOPASSWD: ALL\" > /etc/sudoers.d/airflow \\\n && chmod 0440 /etc/sudoers.d/airflow\n#   Install Python requirements\nRUN sudo -H pip install --upgrade pip \\\n && sudo -H pip install wheel tox \\\n && sudo -H pip3 install --upgrade pip \\\n && sudo -H pip3 install wheel tox \\\n && rm -rf ~/.cache\nEXPOSE 8080/tcp\nWORKDIR /home/airflow\nENV PATH=\"\\\"$PATH:/tmp/hive/bin:$ADDITIONAL_PATH\\\"\"\nUSER airflow\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"#\n#  Licensed to the Apache Software Foundation (ASF) under one or more\n#  contributor license agreements.  See the NOTICE file distributed with\n#  this work for additional information regarding copyright ownership.\n#  The ASF licenses this file to You under the Apache License, Version 2.0\n#  (the \"License\"); you may not use this file except in compliance with\n#  the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n#\n#  WARNING: THIS DOCKERFILE IS NOT INTENDED FOR PRODUCTION USE OR DEPLOYMENT. AT\n#           THIS POINT, THIS IS ONLY INTENDED FOR USE IN AUTOMATED TESTS.\nFROM ubuntu:xenial\nUSER root\nENV DEBIAN_FRONTEND=\"noninteractive\"\nENV LANGUAGE=\"en_US.UTF-8\"\nENV LANG=\"en_US.UTF-8\"\nENV LC_ALL=\"en_US.UTF-8\"\nENV LC_CTYPE=\"en_US.UTF-8\"\nENV LC_MESSAGES=\"en_US.UTF-8\"\nENV HADOOP_VERSION=\"2.6.0\"\nENV HADOOP_DISTRO=\"cdh\"\nENV HADOOP_HOME=\"/tmp/hadoop-${HADOOP_DISTRO}\"\nENV HIVE_HOME=\"/tmp/hive\"\nENV JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64/\"\nRUN mkdir ${HADOOP_HOME} \\\n && mkdir ${HIVE_HOME} \\\n && mkdir /tmp/minicluster \\\n && mkdir -p /user/hive/warehouse \\\n && chmod -R 777 ${HIVE_HOME} \\\n && chmod -R 777 /user/\n#  Add nodejs repo and key\nADD nodesource.gpg.key /tmp/nodesource.gpg.key\nRUN apt-key add /tmp/nodesource.gpg.key\nRUN echo 'deb http://deb.nodesource.com/node_8.x xenial main' > /etc/apt/sources.list.d/nodesource.list\nRUN echo 'deb-src http://deb.nodesource.com/node_8.x xenial main' >> /etc/apt/sources.list.d/nodesource.list\nRUN apt-get update \\\n && apt-get install --no-install-recommends openjdk-8-jdk wget curl gcc g++ python-dev python3-dev python-pip python3-pip python-virtualenv python3-venv python-setuptools python-pkg-resources python3-setuptools python3-pkg-resources make nodejs vim less git unzip sudo ldap-utils mysql-client-core-5.7 mysql-client-5.7 libmysqlclient-dev postgresql-client sqlite3 libkrb5-dev libsasl2-dev krb5-user openssh-client openssh-server python-selinux sasl2-bin libsasl2-2 libsasl2-dev libsasl2-modules locales -y \\\n && rm -rf /var/lib/apt/lists/*\nRUN sed -i 's/^# en_US.UTF-8 UTF-8$/en_US.UTF-8 UTF-8/g' /etc/locale.gen \\\n && locale-gen \\\n && update-locale LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8\n#  Install Hadoop\n#  --absolute-names is a work around to avoid this issue https://github.com/docker/hub-feedback/issues/727\nRUN cd /tmp \\\n && wget -q https://archive.cloudera.com/cdh5/cdh/5/hadoop-${HADOOP_VERSION}-cdh5.11.0.tar.gz \\\n && tar xzf hadoop-${HADOOP_VERSION}-cdh5.11.0.tar.gz --absolute-names --strip-components 1 -C $HADOOP_HOME \\\n && rm hadoop-${HADOOP_VERSION}-cdh5.11.0.tar.gz\n#  Install Hive\nRUN cd /tmp \\\n && wget -q https://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.11.0.tar.gz \\\n && tar xzf hive-1.1.0-cdh5.11.0.tar.gz --strip-components 1 -C $HIVE_HOME \\\n && rm hive-1.1.0-cdh5.11.0.tar.gz\n#  Install MiniCluster\nRUN cd /tmp \\\n && wget -q https://github.com/bolkedebruin/minicluster/releases/download/1.1/minicluster-1.1-SNAPSHOT-bin.zip \\\n && unzip minicluster-1.1-SNAPSHOT-bin.zip -d /tmp \\\n && rm minicluster-1.1-SNAPSHOT-bin.zip\nRUN adduser airflow \\\n && echo \"airflow ALL=(ALL) NOPASSWD: ALL\" > /etc/sudoers.d/airflow \\\n && chmod 0440 /etc/sudoers.d/airflow\n#  Install Python requirements\nRUN sudo -H pip install --upgrade pip \\\n && sudo -H pip install wheel tox \\\n && sudo -H pip3 install --upgrade pip \\\n && sudo -H pip3 install wheel tox \\\n && rm -rf ~/.cache\nEXPOSE 8080/tcp\nWORKDIR /home/airflow\nENV PATH=\"\\\"$PATH:/tmp/hive/bin:$ADDITIONAL_PATH\\\"\"\nUSER airflow\n","injectedSmells":[],"originalDockerfileHash":"c6dda4fbc1d0ecf9aaacf21200e02d7d","successfullyInjectedSmells":[],"originalDockerfileUglified":"#\n#   Licensed to the Apache Software Foundation (ASF) under one or more\n#   contributor license agreements.  See the NOTICE file distributed with\n#   this work for additional information regarding copyright ownership.\n#   The ASF licenses this file to You under the Apache License, Version 2.0\n#   (the \"License\"); you may not use this file except in compliance with\n#   the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#\n#   WARNING: THIS DOCKERFILE IS NOT INTENDED FOR PRODUCTION USE OR DEPLOYMENT. AT\n#            THIS POINT, THIS IS ONLY INTENDED FOR USE IN AUTOMATED TESTS.\nFROM ubuntu:xenial\nUSER root\nENV DEBIAN_FRONTEND=\"noninteractive\"\nENV LANGUAGE=\"en_US.UTF-8\"\nENV LANG=\"en_US.UTF-8\"\nENV LC_ALL=\"en_US.UTF-8\"\nENV LC_CTYPE=\"en_US.UTF-8\"\nENV LC_MESSAGES=\"en_US.UTF-8\"\nENV HADOOP_VERSION=\"2.6.0\"\nENV HADOOP_DISTRO=\"cdh\"\nENV HADOOP_HOME=\"/tmp/hadoop-${HADOOP_DISTRO}\"\nENV HIVE_HOME=\"/tmp/hive\"\nENV JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64/\"\nRUN mkdir ${HADOOP_HOME} \\\n && mkdir ${HIVE_HOME} \\\n && mkdir /tmp/minicluster \\\n && mkdir -p /user/hive/warehouse \\\n && chmod -R 777 ${HIVE_HOME} \\\n && chmod -R 777 /user/\n#   Add nodejs repo and key\nADD nodesource.gpg.key /tmp/nodesource.gpg.key\nRUN apt-key add /tmp/nodesource.gpg.key\nRUN echo 'deb http://deb.nodesource.com/node_8.x xenial main' > /etc/apt/sources.list.d/nodesource.list\nRUN echo 'deb-src http://deb.nodesource.com/node_8.x xenial main' >> /etc/apt/sources.list.d/nodesource.list\nRUN apt-get update \\\n && apt-get install --no-install-recommends openjdk-8-jdk wget curl gcc g++ python-dev python3-dev python-pip python3-pip python-virtualenv python3-venv python-setuptools python-pkg-resources python3-setuptools python3-pkg-resources make nodejs vim less git unzip sudo ldap-utils mysql-client-core-5.7 mysql-client-5.7 libmysqlclient-dev postgresql-client sqlite3 libkrb5-dev libsasl2-dev krb5-user openssh-client openssh-server python-selinux sasl2-bin libsasl2-2 libsasl2-dev libsasl2-modules locales -y \\\n && rm -rf /var/lib/apt/lists/*\nRUN sed -i 's/^# en_US.UTF-8 UTF-8$/en_US.UTF-8 UTF-8/g' /etc/locale.gen \\\n && locale-gen \\\n && update-locale LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8\n#   Install Hadoop\n#   --absolute-names is a work around to avoid this issue https://github.com/docker/hub-feedback/issues/727\nRUN cd /tmp \\\n && wget -q https://archive.cloudera.com/cdh5/cdh/5/hadoop-${HADOOP_VERSION}-cdh5.11.0.tar.gz \\\n && tar xzf hadoop-${HADOOP_VERSION}-cdh5.11.0.tar.gz --absolute-names --strip-components 1 -C $HADOOP_HOME \\\n && rm hadoop-${HADOOP_VERSION}-cdh5.11.0.tar.gz\n#   Install Hive\nRUN cd /tmp \\\n && wget -q https://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.11.0.tar.gz \\\n && tar xzf hive-1.1.0-cdh5.11.0.tar.gz --strip-components 1 -C $HIVE_HOME \\\n && rm hive-1.1.0-cdh5.11.0.tar.gz\n#   Install MiniCluster\nRUN cd /tmp \\\n && wget -q https://github.com/bolkedebruin/minicluster/releases/download/1.1/minicluster-1.1-SNAPSHOT-bin.zip \\\n && unzip minicluster-1.1-SNAPSHOT-bin.zip -d /tmp \\\n && rm minicluster-1.1-SNAPSHOT-bin.zip\nRUN adduser airflow \\\n && echo \"airflow ALL=(ALL) NOPASSWD: ALL\" > /etc/sudoers.d/airflow \\\n && chmod 0440 /etc/sudoers.d/airflow\n#   Install Python requirements\nRUN sudo -H pip install --upgrade pip \\\n && sudo -H pip install wheel tox \\\n && sudo -H pip3 install --upgrade pip \\\n && sudo -H pip3 install wheel tox \\\n && rm -rf ~/.cache\nEXPOSE 8080/tcp\nWORKDIR /home/airflow\nENV PATH=\"\\\"$PATH:/tmp/hive/bin:$ADDITIONAL_PATH\\\"\"\nUSER airflow\n","originalDockerfileUglifiedHash":"5eb7b6887b63cf75d1b4cabe1126f8ae","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/4ea5ea6b7c0f30725266b5facfb8691b6a2cf030.dockerfile"}