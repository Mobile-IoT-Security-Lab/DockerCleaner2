{"seed":176037645,"processedDockerfileHash":"b7c587338be76341b492d1daa9c80942","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","use-copy-instead-of-add","have-a-healthcheck","have-a-user"],"processedDockerfile":"#   Licensed under the Apache License, Version 2.0 (the \"License\");\n#   you may not use this file except in compliance with the License.\n#   You may obtain a copy of the License at\n#\n#       https://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\nARG base_image=nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04\nFROM $base_image\nARG tf_version=1.6.0\nARG cuda_version=8.0\nARG cudnn_version=6\nARG bazel_version=0.5.4\nARG tf_cuda_compatibility=3.5,5.2,6.1\nARG cuda_config_version=8-0\nMAINTAINER Jingtian Peng <pjt73651@gmail.com>\nRUN apt-get update \\\n && apt-get install --no-install-recommends software-properties-common=0.99.35 -y \\\n && add-apt-repository ppa:ubuntu-toolchain-r/test -y \\\n && apt-get update \\\n && apt-get install --no-install-recommends build-essential=12.9ubuntu3 curl=7.88.1-7ubuntu1 libcurl3-dev git=1:2.39.2-1ubuntu1 libfreetype6-dev=2.12.1+dfsg-4 libpng12-dev libzmq3-dev=4.3.4-6 pkg-config=1.8.1-1ubuntu2 python-dev python-numpy python-pip swig=4.1.0-0.2 zip=3.0-13 zlib1g-dev=1:1.2.13.dfsg-1ubuntu4 -y \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   Set up grpc\nRUN pip install mock==5.0.1 grpcio==1.53.0\n#   Set up all envs\nENV BAZELRC=\"/root/.bazelrc\" \\\n    TF_SERVING_VERSION=\"tags/$tf_version\" \\\n    TF_CUDA_VERSION=\"$cuda_version\" \\\n    TF_CUDNN_VERSION=\"$cudnn_version\" \\\n    BAZEL_VERSION=\"$bazel_version\" \\\n    TF_NEED_CUDA=\"1\" \\\n    TF_NEED_S3=\"1\" \\\n    TF_CUDA_COMPUTE_CAPABILITIES=\"$tf_cuda_compatibility\" \\\n    TF_NEED_GCP=\"1\" \\\n    TF_NEED_JEMALLOC=\"0\" \\\n    TF_NEED_HDFS=\"1\" \\\n    TF_NEED_OPENCL=\"0\" \\\n    TF_NEED_MKL=\"0\" \\\n    TF_NEED_VERBS=\"0\" \\\n    TF_NEED_MPI=\"0\" \\\n    TF_NEED_GDR=\"0\" \\\n    TF_ENABLE_XLA=\"1\" \\\n    TF_CUDA_CLANG=\"0\" \\\n    TF_NEED_OPENCL_SYCL=\"0\" \\\n    CUDA_TOOLKIT_PATH=\"/usr/local/cuda\" \\\n    CUDNN_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\" \\\n    GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\" \\\n    PYTHON_BIN_PATH=\"/usr/bin/python\" \\\n    CC_OPT_FLAGS=\"-march=native\" \\\n    PYTHON_LIB_PATH=\"/usr/local/lib/python2.7/dist-packages\"\n#   Install the most recent bazel release.\nRUN mkdir /bazel \\\n && cd /bazel \\\n && curl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && curl -fSsL -o /bazel/LICENSE.txt https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE \\\n && chmod +x bazel-*.sh \\\n && ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && rm -f /bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh\n#   Clone TensorFlow Serving repo and get submodules\nRUN cd /root \\\n && git clone --recurse-submodules https://github.com/tensorflow/serving \\\n && cd serving \\\n && git checkout $TF_SERVING_VERSION \\\n && git submodule init \\\n && git submodule update --recursive\n#   Compile TF serving with CUDA support\nRUN cd /root/serving \\\n && bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda -k --verbose_failures --crosstool_top=@local_config_cuda//crosstool:toolchain tensorflow_serving/model_servers:tensorflow_model_server\n#   Make a copy to /usr/bin instead of making softlinks because /root has 700 permissions\nRUN cp /root/serving/bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server /usr/bin/tensorflow_model_server\n#   This seems to be some magic provided by nvidia-docker but we must be explicit\n#   There didn't seem to be any special flags in the TF Dockerfile.devel-gpu to cover this either\nRUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 \\\n && sed -i '$ a /usr/local/cuda/lib64/stubs' /etc/ld.so.conf.d/cuda-$cuda_config_version.conf \\\n && ldconfig\nWORKDIR /root\nCMD [\"/bin/bash\"]\nENV MS_USER=\"model-server\"\nRUN set -x \\\n && useradd $MS_USER \\\n && [ `id -u $MS_USER ` -eq 1000 ] \\\n && [ `id -g $MS_USER ` -eq 1000 ]\nENV TINI_VERSION=\"v0.18.0\"\nRUN which wget &> /dev/null || apt-get install --no-install-recommends wget=1.20.3 ; wget --no-verbose --output-document /tini https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini\nRUN chmod +x /tini\nENTRYPOINT [\"/tini\", \"--\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#      https://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\nARG base_image=nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04\nFROM $base_image\nARG tf_version=1.6.0\nARG cuda_version=8.0\nARG cudnn_version=6\nARG bazel_version=0.5.4\nARG tf_cuda_compatibility=3.5,5.2,6.1\nARG cuda_config_version=8-0\nMAINTAINER Jingtian Peng <pjt73651@gmail.com>\nRUN apt-get update \\\n && apt-get install software-properties-common -y \\\n && add-apt-repository ppa:ubuntu-toolchain-r/test -y \\\n && apt-get update \\\n && apt-get install build-essential curl libcurl3-dev git libfreetype6-dev libpng12-dev libzmq3-dev pkg-config python-dev python-numpy python-pip swig zip zlib1g-dev -y \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#  Set up grpc\nRUN pip install mock grpcio\n#  Set up all envs\nENV BAZELRC=\"/root/.bazelrc\" \\\n    TF_SERVING_VERSION=\"tags/$tf_version\" \\\n    TF_CUDA_VERSION=\"$cuda_version\" \\\n    TF_CUDNN_VERSION=\"$cudnn_version\" \\\n    BAZEL_VERSION=\"$bazel_version\" \\\n    TF_NEED_CUDA=\"1\" \\\n    TF_NEED_S3=\"1\" \\\n    TF_CUDA_COMPUTE_CAPABILITIES=\"$tf_cuda_compatibility\" \\\n    TF_NEED_GCP=\"1\" \\\n    TF_NEED_JEMALLOC=\"0\" \\\n    TF_NEED_HDFS=\"1\" \\\n    TF_NEED_OPENCL=\"0\" \\\n    TF_NEED_MKL=\"0\" \\\n    TF_NEED_VERBS=\"0\" \\\n    TF_NEED_MPI=\"0\" \\\n    TF_NEED_GDR=\"0\" \\\n    TF_ENABLE_XLA=\"1\" \\\n    TF_CUDA_CLANG=\"0\" \\\n    TF_NEED_OPENCL_SYCL=\"0\" \\\n    CUDA_TOOLKIT_PATH=\"/usr/local/cuda\" \\\n    CUDNN_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\" \\\n    GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\" \\\n    PYTHON_BIN_PATH=\"/usr/bin/python\" \\\n    CC_OPT_FLAGS=\"-march=native\" \\\n    PYTHON_LIB_PATH=\"/usr/local/lib/python2.7/dist-packages\"\n#  Install the most recent bazel release.\nRUN mkdir /bazel \\\n && cd /bazel \\\n && curl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && curl -fSsL -o /bazel/LICENSE.txt https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE \\\n && chmod +x bazel-*.sh \\\n && ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && rm -f /bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh\n#  Clone TensorFlow Serving repo and get submodules\nRUN cd /root \\\n && git clone --recurse-submodules https://github.com/tensorflow/serving \\\n && cd serving \\\n && git checkout $TF_SERVING_VERSION \\\n && git submodule init \\\n && git submodule update --recursive\n#  Compile TF serving with CUDA support\nRUN cd /root/serving \\\n && bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda -k --verbose_failures --crosstool_top=@local_config_cuda//crosstool:toolchain tensorflow_serving/model_servers:tensorflow_model_server\n#  Make a copy to /usr/bin instead of making softlinks because /root has 700 permissions\nRUN cp /root/serving/bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server /usr/bin/tensorflow_model_server\n#  This seems to be some magic provided by nvidia-docker but we must be explicit\n#  There didn't seem to be any special flags in the TF Dockerfile.devel-gpu to cover this either\nRUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 \\\n && sed -i '$ a /usr/local/cuda/lib64/stubs' /etc/ld.so.conf.d/cuda-$cuda_config_version.conf \\\n && ldconfig\nWORKDIR /root\nCMD [\"/bin/bash\"]\nENV MS_USER=\"model-server\"\nRUN set -x \\\n && useradd $MS_USER \\\n && [ `id -u $MS_USER ` -eq 1000 ] \\\n && [ `id -g $MS_USER ` -eq 1000 ]\nENV TINI_VERSION=\"v0.18.0\"\nADD https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini /tini\nRUN chmod +x /tini\nENTRYPOINT [\"/tini\", \"--\"]\n","injectedSmells":[],"originalDockerfileHash":"ea3cbc67d09c6589042a1c420a7e1f0d","successfullyInjectedSmells":[],"originalDockerfileUglified":"#   Licensed under the Apache License, Version 2.0 (the \"License\");\n#   you may not use this file except in compliance with the License.\n#   You may obtain a copy of the License at\n#\n#       https://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\nARG base_image=nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04\nFROM $base_image\nARG tf_version=1.6.0\nARG cuda_version=8.0\nARG cudnn_version=6\nARG bazel_version=0.5.4\nARG tf_cuda_compatibility=3.5,5.2,6.1\nARG cuda_config_version=8-0\nMAINTAINER Jingtian Peng <pjt73651@gmail.com>\nRUN apt-get update \\\n && apt-get install software-properties-common -y \\\n && add-apt-repository ppa:ubuntu-toolchain-r/test -y \\\n && apt-get update \\\n && apt-get install build-essential curl libcurl3-dev git libfreetype6-dev libpng12-dev libzmq3-dev pkg-config python-dev python-numpy python-pip swig zip zlib1g-dev -y \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   Set up grpc\nRUN pip install mock grpcio\n#   Set up all envs\nENV BAZELRC=\"/root/.bazelrc\" \\\n    TF_SERVING_VERSION=\"tags/$tf_version\" \\\n    TF_CUDA_VERSION=\"$cuda_version\" \\\n    TF_CUDNN_VERSION=\"$cudnn_version\" \\\n    BAZEL_VERSION=\"$bazel_version\" \\\n    TF_NEED_CUDA=\"1\" \\\n    TF_NEED_S3=\"1\" \\\n    TF_CUDA_COMPUTE_CAPABILITIES=\"$tf_cuda_compatibility\" \\\n    TF_NEED_GCP=\"1\" \\\n    TF_NEED_JEMALLOC=\"0\" \\\n    TF_NEED_HDFS=\"1\" \\\n    TF_NEED_OPENCL=\"0\" \\\n    TF_NEED_MKL=\"0\" \\\n    TF_NEED_VERBS=\"0\" \\\n    TF_NEED_MPI=\"0\" \\\n    TF_NEED_GDR=\"0\" \\\n    TF_ENABLE_XLA=\"1\" \\\n    TF_CUDA_CLANG=\"0\" \\\n    TF_NEED_OPENCL_SYCL=\"0\" \\\n    CUDA_TOOLKIT_PATH=\"/usr/local/cuda\" \\\n    CUDNN_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\" \\\n    GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\" \\\n    PYTHON_BIN_PATH=\"/usr/bin/python\" \\\n    CC_OPT_FLAGS=\"-march=native\" \\\n    PYTHON_LIB_PATH=\"/usr/local/lib/python2.7/dist-packages\"\n#   Install the most recent bazel release.\nRUN mkdir /bazel \\\n && cd /bazel \\\n && curl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && curl -fSsL -o /bazel/LICENSE.txt https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE \\\n && chmod +x bazel-*.sh \\\n && ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && rm -f /bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh\n#   Clone TensorFlow Serving repo and get submodules\nRUN cd /root \\\n && git clone --recurse-submodules https://github.com/tensorflow/serving \\\n && cd serving \\\n && git checkout $TF_SERVING_VERSION \\\n && git submodule init \\\n && git submodule update --recursive\n#   Compile TF serving with CUDA support\nRUN cd /root/serving \\\n && bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda -k --verbose_failures --crosstool_top=@local_config_cuda//crosstool:toolchain tensorflow_serving/model_servers:tensorflow_model_server\n#   Make a copy to /usr/bin instead of making softlinks because /root has 700 permissions\nRUN cp /root/serving/bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server /usr/bin/tensorflow_model_server\n#   This seems to be some magic provided by nvidia-docker but we must be explicit\n#   There didn't seem to be any special flags in the TF Dockerfile.devel-gpu to cover this either\nRUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 \\\n && sed -i '$ a /usr/local/cuda/lib64/stubs' /etc/ld.so.conf.d/cuda-$cuda_config_version.conf \\\n && ldconfig\nWORKDIR /root\nCMD [\"/bin/bash\"]\nENV MS_USER=\"model-server\"\nRUN set -x \\\n && useradd $MS_USER \\\n && [ `id -u $MS_USER ` -eq 1000 ] \\\n && [ `id -g $MS_USER ` -eq 1000 ]\nENV TINI_VERSION=\"v0.18.0\"\nADD https://github.com/krallin/tini/releases/download/${TINI_VERSION}/tini /tini\nRUN chmod +x /tini\nENTRYPOINT [\"/tini\", \"--\"]\n","originalDockerfileUglifiedHash":"1f41b98dc30342d0c2ccdd9aa7153855","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/0a2260b137f9c1d1f162d842da40724282092b29.dockerfile"}