{"seed":3447828553,"processedDockerfileHash":"8fd0aafde887053eec21dcc939d5f155","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["have-a-healthcheck","have-a-user"],"processedDockerfile":"FROM nvidia/cuda:8.0-devel-centos7\n#   MKL\nRUN mkdir -p /opt/intel/lib\nCOPY mkl_libs/libmkl_core.a /opt/intel/lib/libmkl_core.a\nCOPY mkl_libs/libmkl_gnu_thread.a /opt/intel/lib/libmkl_gnu_thread.a\nCOPY mkl_libs/libmkl_intel_lp64.a /opt/intel/lib/libmkl_intel_lp64.a\nCOPY mkl_libs/include /opt/intel/\nENV LC_ALL=\"en_US.UTF-8\"\nENV LANG=\"en_US.UTF-8\"\nENV LANGUAGE=\"en_US.UTF-8\"\nRUN yum install -y wget curl perl util-linux xz bzip2 git patch which perl\nRUN yum install -y yum-utils centos-release-scl\nRUN yum-config-manager --enable rhel-server-rhscl-7-rpms\nRUN yum install -y devtoolset-3-gcc devtoolset-3-gcc-c++ devtoolset-3-gcc-gfortran devtoolset-3-binutils\nENV PATH=\"/opt/rh/devtoolset-3/root/usr/bin:$PATH\"\nENV LD_LIBRARY_PATH=\"/opt/rh/devtoolset-3/root/usr/lib64:/opt/rh/devtoolset-3/root/usr/lib:$LD_LIBRARY_PATH\"\n#   EPEL for cmake\nRUN wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm \\\n && rpm -ivh epel-release-latest-7.noarch.rpm \\\n && rm -f epel-release-latest-7.noarch.rpm\n#   cmake\nRUN yum install -y cmake3 \\\n && ln -s /usr/bin/cmake3 /usr/bin/cmake\n#   build python\nCOPY build_scripts /build_scripts\nRUN bash build_scripts/build.sh \\\n && rm -r build_scripts\nENV SSL_CERT_FILE=\"/opt/_internal/certs.pem\"\nRUN wget -q https://developer.nvidia.com/compute/cuda/8.0/Prod2/patches/2/cuda_8.0.61.2_linux-run \\\n && chmod +x cuda_8.0.61.2_linux-run \\\n && cp /usr/local/cuda/version.txt /tmp/ \\\n && ./cuda_8.0.61.2_linux-run --silent --accept-eula --installdir=/tmp \\\n && yes | cp -P /tmp/lib64/* /usr/local/cuda/lib64/ \\\n && rm -rf /usr/local/cuda/lib64/lib*blas.so.8.0.61 \\\n && rm -r cuda_8.0.61.2_linux-run\n#   cuDNN license: https://developer.nvidia.com/cudnn/license_agreement\nRUN curl -fsSL http://developer.download.nvidia.com/compute/redist/cudnn/v7.1.2/cudnn-8.0-linux-x64-v7.1.tgz -O \\\n && tar --no-same-owner -xzf cudnn-8.0-linux-x64-v7.1.tgz -C /usr/local \\\n && rm cudnn-8.0-linux-x64-v7.1.tgz \\\n && ldconfig\n#   NCCL2 license: https://docs.nvidia.com/deeplearning/sdk/nccl-sla/index.html\nRUN wget -q https://s3.amazonaws.com/pytorch/nccl_2.2.13-1%2Bcuda8.0_x86_64.txz \\\n && ls \\\n && ls -alh nccl_2.2.13-1+cuda8.0_x86_64.txz \\\n && tar --no-same-owner -xvf nccl_2.2.13-1+cuda8.0_x86_64.txz \\\n && mv nccl_2.2.13-1+cuda8.0_x86_64/include/* /usr/local/cuda/include/ \\\n && cp -P nccl_2.2.13-1+cuda8.0_x86_64/lib/libnccl* /usr/local/cuda/lib64/ \\\n && rm -rf nccl_2.2.13-1+cuda8.0_x86_64* \\\n && ldconfig\n#   magma\nRUN wget http://icl.cs.utk.edu/projectsfiles/magma/downloads/magma-2.3.0.tar.gz \\\n && tar -xvf magma-2.3.0.tar.gz \\\n && cd magma-2.3.0 \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/cmakelists.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/thread_queue.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_cparict_tools.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_dparict_tools.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_sparict_tools.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_zparict_tools.patch \\\n && patch < cmakelists.patch \\\n && patch -p0 < thread_queue.patch \\\n && patch -p0 < magma_cparict_tools.patch \\\n && patch -p0 < magma_dparict_tools.patch \\\n && patch -p0 < magma_sparict_tools.patch \\\n && patch -p0 < magma_zparict_tools.patch \\\n && mkdir build \\\n && cd build \\\n && cmake .. -DUSE_FORTRAN=OFF -DGPU_TARGET=\"All\" -DCMAKE_INSTALL_PREFIX=$PREFIX \\\n && make -j$( getconf _NPROCESSORS_CONF ;) \\\n && make install \\\n && cd ..\nRUN rm -f /usr/local/bin/patchelf\nRUN git clone https://github.com/NixOS/patchelf \\\n && cd patchelf \\\n && sed -i 's/serial/parallel/g' configure.ac \\\n && ./bootstrap.sh \\\n && ./configure \\\n && make \\\n && make install \\\n && cd .. \\\n && rm -rf patchelf\n#  ####################################################################################\n#   CUDA 8.0 prune static libs\n#  ####################################################################################\nARG NVPRUNE=\"/usr/local/cuda-8.0/bin/nvprune\"\nARG CUDA_LIB_DIR=\"/usr/local/cuda-8.0/lib64\"\nARG GENCODE=\"-gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61\"\nARG GENCODE_CUDNN=\"-gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61\"\n#   all CUDA libs except CuDNN and CuBLAS (cudnn and cublas need arch 3.7 included)\nRUN ls $CUDA_LIB_DIR/ | grep \"\\.a\" | grep -v \"culibos\" | grep -v \"cudart\" | grep -v \"cudnn\" | grep -v \"cublas\" | xargs -I {} bash -c \"echo {} \\\n && $NVPRUNE $GENCODE $CUDA_LIB_DIR/{} -o $CUDA_LIB_DIR/{}\"\n#   prune CuDNN and CuBLAS\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcudnn_static.a -o $CUDA_LIB_DIR/libcudnn_static.a\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcublas_static.a -o $CUDA_LIB_DIR/libcublas_static.a\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcublas_device.a -o $CUDA_LIB_DIR/libcublas_device.a\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"FROM nvidia/cuda:8.0-devel-centos7\n#  MKL\nRUN mkdir -p /opt/intel/lib\nCOPY mkl_libs/libmkl_core.a /opt/intel/lib/libmkl_core.a\nCOPY mkl_libs/libmkl_gnu_thread.a /opt/intel/lib/libmkl_gnu_thread.a\nCOPY mkl_libs/libmkl_intel_lp64.a /opt/intel/lib/libmkl_intel_lp64.a\nCOPY mkl_libs/include /opt/intel/\nENV LC_ALL=\"en_US.UTF-8\"\nENV LANG=\"en_US.UTF-8\"\nENV LANGUAGE=\"en_US.UTF-8\"\nRUN yum install -y wget curl perl util-linux xz bzip2 git patch which perl\nRUN yum install -y yum-utils centos-release-scl\nRUN yum-config-manager --enable rhel-server-rhscl-7-rpms\nRUN yum install -y devtoolset-3-gcc devtoolset-3-gcc-c++ devtoolset-3-gcc-gfortran devtoolset-3-binutils\nENV PATH=\"/opt/rh/devtoolset-3/root/usr/bin:$PATH\"\nENV LD_LIBRARY_PATH=\"/opt/rh/devtoolset-3/root/usr/lib64:/opt/rh/devtoolset-3/root/usr/lib:$LD_LIBRARY_PATH\"\n#  EPEL for cmake\nRUN wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm \\\n && rpm -ivh epel-release-latest-7.noarch.rpm \\\n && rm -f epel-release-latest-7.noarch.rpm\n#  cmake\nRUN yum install -y cmake3 \\\n && ln -s /usr/bin/cmake3 /usr/bin/cmake\n#  build python\nCOPY build_scripts /build_scripts\nRUN bash build_scripts/build.sh \\\n && rm -r build_scripts\nENV SSL_CERT_FILE=\"/opt/_internal/certs.pem\"\nRUN wget -q https://developer.nvidia.com/compute/cuda/8.0/Prod2/patches/2/cuda_8.0.61.2_linux-run \\\n && chmod +x cuda_8.0.61.2_linux-run \\\n && cp /usr/local/cuda/version.txt /tmp/ \\\n && ./cuda_8.0.61.2_linux-run --silent --accept-eula --installdir=/tmp \\\n && yes | cp -P /tmp/lib64/* /usr/local/cuda/lib64/ \\\n && rm -rf /usr/local/cuda/lib64/lib*blas.so.8.0.61 \\\n && rm -r cuda_8.0.61.2_linux-run\n#  cuDNN license: https://developer.nvidia.com/cudnn/license_agreement\nRUN curl -fsSL http://developer.download.nvidia.com/compute/redist/cudnn/v7.1.2/cudnn-8.0-linux-x64-v7.1.tgz -O \\\n && tar --no-same-owner -xzf cudnn-8.0-linux-x64-v7.1.tgz -C /usr/local \\\n && rm cudnn-8.0-linux-x64-v7.1.tgz \\\n && ldconfig\n#  NCCL2 license: https://docs.nvidia.com/deeplearning/sdk/nccl-sla/index.html\nRUN wget -q https://s3.amazonaws.com/pytorch/nccl_2.2.13-1%2Bcuda8.0_x86_64.txz \\\n && ls \\\n && ls -alh nccl_2.2.13-1+cuda8.0_x86_64.txz \\\n && tar --no-same-owner -xvf nccl_2.2.13-1+cuda8.0_x86_64.txz \\\n && mv nccl_2.2.13-1+cuda8.0_x86_64/include/* /usr/local/cuda/include/ \\\n && cp -P nccl_2.2.13-1+cuda8.0_x86_64/lib/libnccl* /usr/local/cuda/lib64/ \\\n && rm -rf nccl_2.2.13-1+cuda8.0_x86_64* \\\n && ldconfig\n#  magma\nRUN wget http://icl.cs.utk.edu/projectsfiles/magma/downloads/magma-2.3.0.tar.gz \\\n && tar -xvf magma-2.3.0.tar.gz \\\n && cd magma-2.3.0 \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/cmakelists.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/thread_queue.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_cparict_tools.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_dparict_tools.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_sparict_tools.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_zparict_tools.patch \\\n && patch < cmakelists.patch \\\n && patch -p0 < thread_queue.patch \\\n && patch -p0 < magma_cparict_tools.patch \\\n && patch -p0 < magma_dparict_tools.patch \\\n && patch -p0 < magma_sparict_tools.patch \\\n && patch -p0 < magma_zparict_tools.patch \\\n && mkdir build \\\n && cd build \\\n && cmake .. -DUSE_FORTRAN=OFF -DGPU_TARGET=\"All\" -DCMAKE_INSTALL_PREFIX=$PREFIX \\\n && make -j$( getconf _NPROCESSORS_CONF ;) \\\n && make install \\\n && cd ..\nRUN rm -f /usr/local/bin/patchelf\nRUN git clone https://github.com/NixOS/patchelf \\\n && cd patchelf \\\n && sed -i 's/serial/parallel/g' configure.ac \\\n && ./bootstrap.sh \\\n && ./configure \\\n && make \\\n && make install \\\n && cd .. \\\n && rm -rf patchelf\n# ####################################################################################\n#  CUDA 8.0 prune static libs\n# ####################################################################################\nARG NVPRUNE=\"/usr/local/cuda-8.0/bin/nvprune\"\nARG CUDA_LIB_DIR=\"/usr/local/cuda-8.0/lib64\"\nARG GENCODE=\"-gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61\"\nARG GENCODE_CUDNN=\"-gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61\"\n#  all CUDA libs except CuDNN and CuBLAS (cudnn and cublas need arch 3.7 included)\nRUN ls $CUDA_LIB_DIR/ | grep \"\\.a\" | grep -v \"culibos\" | grep -v \"cudart\" | grep -v \"cudnn\" | grep -v \"cublas\" | xargs -I {} bash -c \"echo {} \\\n && $NVPRUNE $GENCODE $CUDA_LIB_DIR/{} -o $CUDA_LIB_DIR/{}\"\n#  prune CuDNN and CuBLAS\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcudnn_static.a -o $CUDA_LIB_DIR/libcudnn_static.a\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcublas_static.a -o $CUDA_LIB_DIR/libcublas_static.a\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcublas_device.a -o $CUDA_LIB_DIR/libcublas_device.a\n","injectedSmells":[],"originalDockerfileHash":"26b39cb122729ca6b5c3c4bccd81b049","successfullyInjectedSmells":[],"originalDockerfileUglified":"FROM nvidia/cuda:8.0-devel-centos7\n#   MKL\nRUN mkdir -p /opt/intel/lib\nCOPY mkl_libs/libmkl_core.a /opt/intel/lib/libmkl_core.a\nCOPY mkl_libs/libmkl_gnu_thread.a /opt/intel/lib/libmkl_gnu_thread.a\nCOPY mkl_libs/libmkl_intel_lp64.a /opt/intel/lib/libmkl_intel_lp64.a\nCOPY mkl_libs/include /opt/intel/\nENV LC_ALL=\"en_US.UTF-8\"\nENV LANG=\"en_US.UTF-8\"\nENV LANGUAGE=\"en_US.UTF-8\"\nRUN yum install -y wget curl perl util-linux xz bzip2 git patch which perl\nRUN yum install -y yum-utils centos-release-scl\nRUN yum-config-manager --enable rhel-server-rhscl-7-rpms\nRUN yum install -y devtoolset-3-gcc devtoolset-3-gcc-c++ devtoolset-3-gcc-gfortran devtoolset-3-binutils\nENV PATH=\"/opt/rh/devtoolset-3/root/usr/bin:$PATH\"\nENV LD_LIBRARY_PATH=\"/opt/rh/devtoolset-3/root/usr/lib64:/opt/rh/devtoolset-3/root/usr/lib:$LD_LIBRARY_PATH\"\n#   EPEL for cmake\nRUN wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm \\\n && rpm -ivh epel-release-latest-7.noarch.rpm \\\n && rm -f epel-release-latest-7.noarch.rpm\n#   cmake\nRUN yum install -y cmake3 \\\n && ln -s /usr/bin/cmake3 /usr/bin/cmake\n#   build python\nCOPY build_scripts /build_scripts\nRUN bash build_scripts/build.sh \\\n && rm -r build_scripts\nENV SSL_CERT_FILE=\"/opt/_internal/certs.pem\"\nRUN wget -q https://developer.nvidia.com/compute/cuda/8.0/Prod2/patches/2/cuda_8.0.61.2_linux-run \\\n && chmod +x cuda_8.0.61.2_linux-run \\\n && cp /usr/local/cuda/version.txt /tmp/ \\\n && ./cuda_8.0.61.2_linux-run --silent --accept-eula --installdir=/tmp \\\n && yes | cp -P /tmp/lib64/* /usr/local/cuda/lib64/ \\\n && rm -rf /usr/local/cuda/lib64/lib*blas.so.8.0.61 \\\n && rm -r cuda_8.0.61.2_linux-run\n#   cuDNN license: https://developer.nvidia.com/cudnn/license_agreement\nRUN curl -fsSL http://developer.download.nvidia.com/compute/redist/cudnn/v7.1.2/cudnn-8.0-linux-x64-v7.1.tgz -O \\\n && tar --no-same-owner -xzf cudnn-8.0-linux-x64-v7.1.tgz -C /usr/local \\\n && rm cudnn-8.0-linux-x64-v7.1.tgz \\\n && ldconfig\n#   NCCL2 license: https://docs.nvidia.com/deeplearning/sdk/nccl-sla/index.html\nRUN wget -q https://s3.amazonaws.com/pytorch/nccl_2.2.13-1%2Bcuda8.0_x86_64.txz \\\n && ls \\\n && ls -alh nccl_2.2.13-1+cuda8.0_x86_64.txz \\\n && tar --no-same-owner -xvf nccl_2.2.13-1+cuda8.0_x86_64.txz \\\n && mv nccl_2.2.13-1+cuda8.0_x86_64/include/* /usr/local/cuda/include/ \\\n && cp -P nccl_2.2.13-1+cuda8.0_x86_64/lib/libnccl* /usr/local/cuda/lib64/ \\\n && rm -rf nccl_2.2.13-1+cuda8.0_x86_64* \\\n && ldconfig\n#   magma\nRUN wget http://icl.cs.utk.edu/projectsfiles/magma/downloads/magma-2.3.0.tar.gz \\\n && tar -xvf magma-2.3.0.tar.gz \\\n && cd magma-2.3.0 \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/cmakelists.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/thread_queue.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_cparict_tools.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_dparict_tools.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_sparict_tools.patch \\\n && wget https://raw.githubusercontent.com/pytorch/builder/master/conda/old/magma-cuda80-2.3.0/magma_zparict_tools.patch \\\n && patch < cmakelists.patch \\\n && patch -p0 < thread_queue.patch \\\n && patch -p0 < magma_cparict_tools.patch \\\n && patch -p0 < magma_dparict_tools.patch \\\n && patch -p0 < magma_sparict_tools.patch \\\n && patch -p0 < magma_zparict_tools.patch \\\n && mkdir build \\\n && cd build \\\n && cmake .. -DUSE_FORTRAN=OFF -DGPU_TARGET=\"All\" -DCMAKE_INSTALL_PREFIX=$PREFIX \\\n && make -j$( getconf _NPROCESSORS_CONF ;) \\\n && make install \\\n && cd ..\nRUN rm -f /usr/local/bin/patchelf\nRUN git clone https://github.com/NixOS/patchelf \\\n && cd patchelf \\\n && sed -i 's/serial/parallel/g' configure.ac \\\n && ./bootstrap.sh \\\n && ./configure \\\n && make \\\n && make install \\\n && cd .. \\\n && rm -rf patchelf\n#  ####################################################################################\n#   CUDA 8.0 prune static libs\n#  ####################################################################################\nARG NVPRUNE=\"/usr/local/cuda-8.0/bin/nvprune\"\nARG CUDA_LIB_DIR=\"/usr/local/cuda-8.0/lib64\"\nARG GENCODE=\"-gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61\"\nARG GENCODE_CUDNN=\"-gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61\"\n#   all CUDA libs except CuDNN and CuBLAS (cudnn and cublas need arch 3.7 included)\nRUN ls $CUDA_LIB_DIR/ | grep \"\\.a\" | grep -v \"culibos\" | grep -v \"cudart\" | grep -v \"cudnn\" | grep -v \"cublas\" | xargs -I {} bash -c \"echo {} \\\n && $NVPRUNE $GENCODE $CUDA_LIB_DIR/{} -o $CUDA_LIB_DIR/{}\"\n#   prune CuDNN and CuBLAS\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcudnn_static.a -o $CUDA_LIB_DIR/libcudnn_static.a\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcublas_static.a -o $CUDA_LIB_DIR/libcublas_static.a\nRUN $NVPRUNE $GENCODE_CUDNN $CUDA_LIB_DIR/libcublas_device.a -o $CUDA_LIB_DIR/libcublas_device.a\n","originalDockerfileUglifiedHash":"46444f02de0558ca6dd4c29c3fbdf96a","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/0503e242a59bde770a482ddd2eda57823977eac7.dockerfile"}