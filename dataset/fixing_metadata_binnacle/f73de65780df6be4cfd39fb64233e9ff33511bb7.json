{"seed":997552805,"processedDockerfileHash":"cbcdea5262b715f062da04c2c7b85847","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","have-a-healthcheck","have-a-user"],"processedDockerfile":"#   Copyright 2015 Google Inc. All rights reserved.\n#\n#   Licensed under the Apache License, Version 2.0 (the \"License\");\n#   you may not use this file except in compliance with the License.\n#   You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#   We use different base images for GPU vs CPU Dockerfiles, so we expect\n#   that the appropriate image is pulled and tagged locally.\n#   CPU should use ubuntu:16.04\n#   and GPU uses nvidia/cuda:9.1-cudnn7-devel-ubuntu16.04\nFROM datalab-external-base-image\nMAINTAINER Google Cloud DataLab\n#   Container configuration\nEXPOSE 8080/tcp\n#   Path configuration\nENV DATALAB_CONDA_DIR=\"/usr/local\"\nENV PATH=\"$PATH:/tools/node/bin:/tools/google-cloud-sdk/bin:$DATALAB_CONDA_DIR/bin\"\nENV PYTHON_2_ENV=\"py2env\"\nENV PYTHON_3_ENV=\"py3env\"\n#   Needed to run \"source\" for switching Conda environments.\nSHELL [\"/bin/bash\", \"-c\"]\n#   Setup OS and core packages\nRUN echo \"deb-src http://ftp.us.debian.org/debian testing main\" >> /etc/apt/sources.list \\\n && apt-get update -y \\\n && apt-get install --no-install-recommends debian-archive-keyring=2021.1.1ubuntu2 debian-keyring=2022.12.24 -y -q \\\n && apt-get update -y \\\n && apt-get install --no-install-recommends build-essential=12.9ubuntu3 ca-certificates=20230311 curl=7.88.1-7ubuntu1 git=1:2.39.2-1ubuntu1 locales=2.37-0ubuntu2 openssh-client=1:9.0p1-1ubuntu8 pkg-config=1.8.1-1ubuntu2 unzip=6.0-27ubuntu1 wget=1.21.3-1ubuntu1 zip=3.0-13 -y -q \\\n && mkdir -p /tools \\\n && mkdir -p /srcs \\\n && cd /srcs \\\n && apt-get source -d wget git python-zmq ca-certificates pkg-config libpng-dev \\\n && cd / \\\n && locale-gen en_US.UTF-8 \\\n && update-locale LANG=en_US.UTF-8 \\\n && wget --quiet -O ~/miniconda.sh http://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh \\\n && chmod +x ~/miniconda.sh \\\n && ~/miniconda.sh -b -f -p $DATALAB_CONDA_DIR \\\n && rm ~/miniconda.sh \\\n && conda update conda --quiet --yes \\\n && conda config --system --append channels conda-forge \\\n && conda config --system --set show_channel_urls true \\\n && conda update --all --quiet --yes \\\n && conda create --yes --quiet --name $PYTHON_2_ENV python=2.7 crcmod==1.7 dask==0.17.1 dill==0.2.6 future==0.16.0 futures==3.2.0 google-api-python-client==1.6.2 httplib2==0.10.3 h5py==2.7.1 ipykernel==4.8.2 ipywidgets==7.2.1 jinja2==2.8 jsonschema==2.6.0 matplotlib==2.1.2 mock==2.0.0 nltk==3.2.1 numpy==1.14.0 oauth2client==2.2.0 pandas-gbq==0.3.0 pandas==0.22.0 pandas-profiling==1.4.2 pandocfilters==1.4.2 pillow==5.0.0 pip==18.1 plotly==1.12.5 psutil==4.3.0 pygments==2.1.3 python-dateutil==2.5.0 python-snappy==0.5.1 pytz==2018.4 pyyaml==3.13 pyzmq==17.1.0 requests==2.18.4 scikit-image==0.13.0 scikit-learn==0.19.1 scipy==1.0.0 seaborn==0.7.0 six==1.11.0 statsmodels==0.8.0 sympy==0.7.6.1 tornado==4.5.1 widgetsnbextension==3.2.1 xgboost==0.6a2 \\\n && source activate $PYTHON_2_ENV \\\n && pip install only-if-needed==null apache-airflow==1.9.0 bs4==0.0.1 ggplot==0.6.8 google-cloud-dataflow==2.0.0 google-cloud-monitoring==0.28.0 lime==0.1.1.23 protobuf==3.6.1 tensorflow==1.8.0 --quiet -U --upgrade-strategy --no-cache-dir \\\n && source deactivate \\\n && conda clean -tipsy \\\n && unset OLDPWD \\\n && conda create --yes --quiet --name $PYTHON_3_ENV python=3.5 crcmod==1.7 dask==0.17.1 dill==0.2.6 google-api-python-client==1.6.2 httplib2==0.10.3 h5py==2.7.1 ipykernel==4.8.2 ipywidgets==7.2.1 jinja2==2.8 jsonschema==2.6.0 matplotlib==2.1.2 mock==2.0.0 nltk==3.2.1 notebook==5.6.0 numpy==1.14.0 oauth2client==2.2.0 pandas-gbq==0.3.0 pandas==0.22.0 pandocfilters==1.4.2 pillow==5.0.0 pip==18.0 plotly==1.12.5 psutil==4.3.0 pygments==2.1.3 python-dateutil==2.5.0 python-snappy==0.5.1 pytz==2018.4 pyzmq==17.1.0 requests==2.18.4 scikit-image==0.13.0 scikit-learn==0.19.1 scipy==1.0.0 seaborn==0.7.0 six==1.11.0 statsmodels==0.8.0 sympy==0.7.6.1 tornado==4.5.1 widgetsnbextension==3.2.1 xgboost==0.6a2 \\\n && cp /usr/local/envs/py3env/bin/pip /usr/local/envs/py3env/bin/pip3 \\\n && source deactivate \\\n && source activate $PYTHON_2_ENV \\\n && python -m ipykernel install --prefix=/usr/local/envs/py3env \\\n && source deactivate \\\n && conda clean -tipsy \\\n && find $DATALAB_CONDA_DIR/envs/*/lib -type d -name tests | grep -v h5py | xargs rm -rf \\\n && cd / \\\n && mkdir -p /tools/node \\\n && wget -nv https://nodejs.org/dist/v6.10.0/node-v6.10.0-linux-x64.tar.gz -O node.tar.gz \\\n && tar xzf node.tar.gz -C /tools/node --strip-components=1 \\\n && rm node.tar.gz \\\n && wget -nv https://dl.google.com/dl/cloudsdk/release/google-cloud-sdk.zip \\\n && unzip -qq google-cloud-sdk.zip -d tools \\\n && rm google-cloud-sdk.zip \\\n && tools/google-cloud-sdk/install.sh --usage-reporting=false --path-update=false --bash-completion=false --disable-installation-options \\\n && tools/google-cloud-sdk/bin/gcloud -q components update gcloud core bq gsutil compute preview alpha beta \\\n && tools/google-cloud-sdk/bin/gcloud config set component_manager/disable_update_check true \\\n && touch /tools/google-cloud-sdk/lib/third_party/google.py \\\n && /tools/node/bin/npm install bunyan@1.7.1 http-proxy@1.13.2 mkdirp@0.5.1 node-cache@3.2.0 node-uuid@1.4.7 tcp-port-used@0.1.2 ws@1.1.4 \\\n && cd / \\\n && /tools/node/bin/npm install -g forever \\\n && apt-get autoremove -y \\\n && rm -rf /var/lib/apt/lists/* \\\n && rm -rf /tmp/* \\\n && rm -rf /root/.cache/* \\\n && rm -rf /usr/share/locale/* \\\n && rm -rf /usr/share/i18n/locales/*\n#   Install Python3 packages that aren't available or up-to-date in Conda.\n#   For some reasons, merging it with the commands above does not work so creating a separate one.\nRUN source activate $PYTHON_3_ENV \\\n && pip install only-if-needed==null apache-airflow==1.9.0 bs4==0.0.1 ggplot==0.6.8 google-cloud-monitoring==0.28.0 lime==0.1.1.23 protobuf==3.6.1 tensorflow==1.8.0 --quiet -U --upgrade-strategy --no-cache-dir\nENV LANG=\"en_US.UTF-8\"\n#   Copy local configuration files\nCOPY config/ipython.py /etc/ipython/ipython_config.py\nCOPY config/nbconvert.py /etc/jupyter/jupyter_notebook_config.py\n#   Directory \"py\" may be empty and in that case it will git clone pydatalab from repo\nCOPY pydatalab /datalab/lib/pydatalab\nCOPY nbconvert /datalab/nbconvert\nRUN if [ -d /datalab/lib/pydatalab/.git ] ; then echo \"use local lib\" ; else git clone https://github.com/googledatalab/pydatalab.git /datalab/lib/pydatalab ; fi \\\n && cd /datalab/lib/pydatalab \\\n && /tools/node/bin/npm install -g typescript@3.0.3 \\\n && tsc --module amd --noImplicitAny --outdir datalab/notebook/static datalab/notebook/static/*.ts \\\n && tsc --module amd --noImplicitAny --outdir google/datalab/notebook/static google/datalab/notebook/static/*.ts \\\n && /tools/node/bin/npm uninstall -g typescript \\\n && cd /datalab/lib/pydatalab \\\n && source activate $PYTHON_2_ENV \\\n && pip install only-if-needed==null . --upgrade-strategy --no-cache-dir \\\n && pip install only-if-needed==null /datalab/lib/pydatalab/solutionbox/image_classification/. --upgrade-strategy \\\n && pip install only-if-needed==null /datalab/lib/pydatalab/solutionbox/structured_data/. --upgrade-strategy \\\n && source deactivate \\\n && source activate $PYTHON_3_ENV \\\n && pip install only-if-needed==null . --upgrade-strategy --no-cache-dir \\\n && pip install only-if-needed==null /datalab/lib/pydatalab/solutionbox/image_classification/. --upgrade-strategy \\\n && pip install only-if-needed==null /datalab/lib/pydatalab/solutionbox/structured_data/. --upgrade-strategy \\\n && pip install only-if-needed==null jupyter_highlight_selected_word==0.2.0 --upgrade-strategy \\\n && jupyter nbextension install --py datalab.notebook \\\n && jupyter nbextension install --py google.datalab.notebook \\\n && jupyter nbextension install --py jupyter_highlight_selected_word \\\n && jupyter nbextension enable --sys-prefix --py jupyter_highlight_selected_word \\\n && jupyter nbextension enable --sys-prefix --py widgetsnbextension \\\n && source deactivate \\\n && rm datalab/notebook/static/*.js google/datalab/notebook/static/*.js \\\n && mkdir -p /datalab/nbconvert \\\n && cp -R /usr/local/share/jupyter/nbextensions/gcpdatalab/* /datalab/nbconvert \\\n && ln -s $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/lib/python3.5/site-packages/notebook/static/custom/custom.css /datalab/nbconvert/custom.css\n#   Add third party license files\nRUN mkdir -p /tools/license\nCOPY license.sh /tools/license\nCOPY third_party_licenses.csv /tools/license\nRUN mkdir /usr/licenses \\\n && /tools/license/license.sh /tools/license/third_party_licenses.csv /usr/licenses\nCOPY config/py2-kernel.json $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python2/kernel.json\nCOPY config/py3-kernel.json $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python3/kernel.json\nCOPY config/py2-kernel-startup.sh $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python2/kernel-startup.sh\nCOPY config/py3-kernel-startup.sh $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python3/kernel-startup.sh\nRUN chmod 755 $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python2/kernel-startup.sh \\\n && chmod 755 $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python3/kernel-startup.sh\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"#  Copyright 2015 Google Inc. All rights reserved.\n#\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\n#  you may not use this file except in compliance with the License.\n#  You may obtain a copy of the License at\n#\n#  http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n#  We use different base images for GPU vs CPU Dockerfiles, so we expect\n#  that the appropriate image is pulled and tagged locally.\n#  CPU should use ubuntu:16.04\n#  and GPU uses nvidia/cuda:9.1-cudnn7-devel-ubuntu16.04\nFROM datalab-external-base-image\nMAINTAINER Google Cloud DataLab\n#  Container configuration\nEXPOSE 8080/tcp\n#  Path configuration\nENV DATALAB_CONDA_DIR=\"/usr/local\"\nENV PATH=\"$PATH:/tools/node/bin:/tools/google-cloud-sdk/bin:$DATALAB_CONDA_DIR/bin\"\nENV PYTHON_2_ENV=\"py2env\"\nENV PYTHON_3_ENV=\"py3env\"\n#  Needed to run \"source\" for switching Conda environments.\nSHELL [\"/bin/bash\", \"-c\"]\n#  Setup OS and core packages\nRUN echo \"deb-src http://ftp.us.debian.org/debian testing main\" >> /etc/apt/sources.list \\\n && apt-get update -y \\\n && apt-get install debian-archive-keyring debian-keyring -y -q \\\n && apt-get update -y \\\n && apt-get install --no-install-recommends build-essential ca-certificates curl git locales openssh-client pkg-config unzip wget zip -y -q \\\n && mkdir -p /tools \\\n && mkdir -p /srcs \\\n && cd /srcs \\\n && apt-get source -d wget git python-zmq ca-certificates pkg-config libpng-dev \\\n && cd / \\\n && locale-gen en_US.UTF-8 \\\n && update-locale LANG=en_US.UTF-8 \\\n && wget --quiet -O ~/miniconda.sh http://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh \\\n && chmod +x ~/miniconda.sh \\\n && ~/miniconda.sh -b -f -p $DATALAB_CONDA_DIR \\\n && rm ~/miniconda.sh \\\n && conda update conda --quiet --yes \\\n && conda config --system --append channels conda-forge \\\n && conda config --system --set show_channel_urls true \\\n && conda update --all --quiet --yes \\\n && conda create --yes --quiet --name $PYTHON_2_ENV python=2.7 crcmod==1.7 dask==0.17.1 dill==0.2.6 future==0.16.0 futures==3.2.0 google-api-python-client==1.6.2 httplib2==0.10.3 h5py==2.7.1 ipykernel==4.8.2 ipywidgets==7.2.1 jinja2==2.8 jsonschema==2.6.0 matplotlib==2.1.2 mock==2.0.0 nltk==3.2.1 numpy==1.14.0 oauth2client==2.2.0 pandas-gbq==0.3.0 pandas==0.22.0 pandas-profiling==1.4.2 pandocfilters==1.4.2 pillow==5.0.0 pip==18.1 plotly==1.12.5 psutil==4.3.0 pygments==2.1.3 python-dateutil==2.5.0 python-snappy==0.5.1 pytz==2018.4 pyyaml==3.13 pyzmq==17.1.0 requests==2.18.4 scikit-image==0.13.0 scikit-learn==0.19.1 scipy==1.0.0 seaborn==0.7.0 six==1.11.0 statsmodels==0.8.0 sympy==0.7.6.1 tornado==4.5.1 widgetsnbextension==3.2.1 xgboost==0.6a2 \\\n && source activate $PYTHON_2_ENV \\\n && pip install only-if-needed apache-airflow==1.9.0 bs4==0.0.1 ggplot==0.6.8 google-cloud-dataflow==2.0.0 google-cloud-monitoring==0.28.0 lime==0.1.1.23 protobuf==3.6.1 tensorflow==1.8.0 --quiet -U --upgrade-strategy --no-cache-dir \\\n && source deactivate \\\n && conda clean -tipsy \\\n && unset OLDPWD \\\n && conda create --yes --quiet --name $PYTHON_3_ENV python=3.5 crcmod==1.7 dask==0.17.1 dill==0.2.6 google-api-python-client==1.6.2 httplib2==0.10.3 h5py==2.7.1 ipykernel==4.8.2 ipywidgets==7.2.1 jinja2==2.8 jsonschema==2.6.0 matplotlib==2.1.2 mock==2.0.0 nltk==3.2.1 notebook==5.6.0 numpy==1.14.0 oauth2client==2.2.0 pandas-gbq==0.3.0 pandas==0.22.0 pandocfilters==1.4.2 pillow==5.0.0 pip==18.0 plotly==1.12.5 psutil==4.3.0 pygments==2.1.3 python-dateutil==2.5.0 python-snappy==0.5.1 pytz==2018.4 pyzmq==17.1.0 requests==2.18.4 scikit-image==0.13.0 scikit-learn==0.19.1 scipy==1.0.0 seaborn==0.7.0 six==1.11.0 statsmodels==0.8.0 sympy==0.7.6.1 tornado==4.5.1 widgetsnbextension==3.2.1 xgboost==0.6a2 \\\n && cp /usr/local/envs/py3env/bin/pip /usr/local/envs/py3env/bin/pip3 \\\n && source deactivate \\\n && source activate $PYTHON_2_ENV \\\n && python -m ipykernel install --prefix=/usr/local/envs/py3env \\\n && source deactivate \\\n && conda clean -tipsy \\\n && find $DATALAB_CONDA_DIR/envs/*/lib -type d -name tests | grep -v h5py | xargs rm -rf \\\n && cd / \\\n && mkdir -p /tools/node \\\n && wget -nv https://nodejs.org/dist/v6.10.0/node-v6.10.0-linux-x64.tar.gz -O node.tar.gz \\\n && tar xzf node.tar.gz -C /tools/node --strip-components=1 \\\n && rm node.tar.gz \\\n && wget -nv https://dl.google.com/dl/cloudsdk/release/google-cloud-sdk.zip \\\n && unzip -qq google-cloud-sdk.zip -d tools \\\n && rm google-cloud-sdk.zip \\\n && tools/google-cloud-sdk/install.sh --usage-reporting=false --path-update=false --bash-completion=false --disable-installation-options \\\n && tools/google-cloud-sdk/bin/gcloud -q components update gcloud core bq gsutil compute preview alpha beta \\\n && tools/google-cloud-sdk/bin/gcloud config set component_manager/disable_update_check true \\\n && touch /tools/google-cloud-sdk/lib/third_party/google.py \\\n && /tools/node/bin/npm install bunyan@1.7.1 http-proxy@1.13.2 mkdirp@0.5.1 node-cache@3.2.0 node-uuid@1.4.7 tcp-port-used@0.1.2 ws@1.1.4 \\\n && cd / \\\n && /tools/node/bin/npm install -g forever \\\n && apt-get autoremove -y \\\n && rm -rf /var/lib/apt/lists/* \\\n && rm -rf /tmp/* \\\n && rm -rf /root/.cache/* \\\n && rm -rf /usr/share/locale/* \\\n && rm -rf /usr/share/i18n/locales/*\n#  Install Python3 packages that aren't available or up-to-date in Conda.\n#  For some reasons, merging it with the commands above does not work so creating a separate one.\nRUN source activate $PYTHON_3_ENV \\\n && pip install only-if-needed apache-airflow==1.9.0 bs4==0.0.1 ggplot==0.6.8 google-cloud-monitoring==0.28.0 lime==0.1.1.23 protobuf==3.6.1 tensorflow==1.8.0 --quiet -U --upgrade-strategy --no-cache-dir\nENV LANG=\"en_US.UTF-8\"\n#  Copy local configuration files\nCOPY config/ipython.py /etc/ipython/ipython_config.py\nCOPY config/nbconvert.py /etc/jupyter/jupyter_notebook_config.py\n#  Directory \"py\" may be empty and in that case it will git clone pydatalab from repo\nCOPY pydatalab /datalab/lib/pydatalab\nCOPY nbconvert /datalab/nbconvert\nRUN if [ -d /datalab/lib/pydatalab/.git ] ; then echo \"use local lib\" ; else git clone https://github.com/googledatalab/pydatalab.git /datalab/lib/pydatalab ; fi \\\n && cd /datalab/lib/pydatalab \\\n && /tools/node/bin/npm install -g typescript@3.0.3 \\\n && tsc --module amd --noImplicitAny --outdir datalab/notebook/static datalab/notebook/static/*.ts \\\n && tsc --module amd --noImplicitAny --outdir google/datalab/notebook/static google/datalab/notebook/static/*.ts \\\n && /tools/node/bin/npm uninstall -g typescript \\\n && cd /datalab/lib/pydatalab \\\n && source activate $PYTHON_2_ENV \\\n && pip install only-if-needed . --upgrade-strategy --no-cache-dir \\\n && pip install only-if-needed /datalab/lib/pydatalab/solutionbox/image_classification/. --upgrade-strategy \\\n && pip install only-if-needed /datalab/lib/pydatalab/solutionbox/structured_data/. --upgrade-strategy \\\n && source deactivate \\\n && source activate $PYTHON_3_ENV \\\n && pip install only-if-needed . --upgrade-strategy --no-cache-dir \\\n && pip install only-if-needed /datalab/lib/pydatalab/solutionbox/image_classification/. --upgrade-strategy \\\n && pip install only-if-needed /datalab/lib/pydatalab/solutionbox/structured_data/. --upgrade-strategy \\\n && pip install only-if-needed jupyter_highlight_selected_word==0.2.0 --upgrade-strategy \\\n && jupyter nbextension install --py datalab.notebook \\\n && jupyter nbextension install --py google.datalab.notebook \\\n && jupyter nbextension install --py jupyter_highlight_selected_word \\\n && jupyter nbextension enable --sys-prefix --py jupyter_highlight_selected_word \\\n && jupyter nbextension enable --sys-prefix --py widgetsnbextension \\\n && source deactivate \\\n && rm datalab/notebook/static/*.js google/datalab/notebook/static/*.js \\\n && mkdir -p /datalab/nbconvert \\\n && cp -R /usr/local/share/jupyter/nbextensions/gcpdatalab/* /datalab/nbconvert \\\n && ln -s $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/lib/python3.5/site-packages/notebook/static/custom/custom.css /datalab/nbconvert/custom.css\n#  Add third party license files\nRUN mkdir -p /tools/license\nCOPY license.sh /tools/license\nCOPY third_party_licenses.csv /tools/license\nRUN mkdir /usr/licenses \\\n && /tools/license/license.sh /tools/license/third_party_licenses.csv /usr/licenses\nCOPY config/py2-kernel.json $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python2/kernel.json\nCOPY config/py3-kernel.json $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python3/kernel.json\nCOPY config/py2-kernel-startup.sh $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python2/kernel-startup.sh\nCOPY config/py3-kernel-startup.sh $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python3/kernel-startup.sh\nRUN chmod 755 $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python2/kernel-startup.sh \\\n && chmod 755 $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python3/kernel-startup.sh\n","injectedSmells":[],"originalDockerfileHash":"40819d91d4496932209416283b7572a5","successfullyInjectedSmells":[],"originalDockerfileUglified":"#   Copyright 2015 Google Inc. All rights reserved.\n#\n#   Licensed under the Apache License, Version 2.0 (the \"License\");\n#   you may not use this file except in compliance with the License.\n#   You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#   We use different base images for GPU vs CPU Dockerfiles, so we expect\n#   that the appropriate image is pulled and tagged locally.\n#   CPU should use ubuntu:16.04\n#   and GPU uses nvidia/cuda:9.1-cudnn7-devel-ubuntu16.04\nFROM datalab-external-base-image\nMAINTAINER Google Cloud DataLab\n#   Container configuration\nEXPOSE 8080/tcp\n#   Path configuration\nENV DATALAB_CONDA_DIR=\"/usr/local\"\nENV PATH=\"$PATH:/tools/node/bin:/tools/google-cloud-sdk/bin:$DATALAB_CONDA_DIR/bin\"\nENV PYTHON_2_ENV=\"py2env\"\nENV PYTHON_3_ENV=\"py3env\"\n#   Needed to run \"source\" for switching Conda environments.\nSHELL [\"/bin/bash\", \"-c\"]\n#   Setup OS and core packages\nRUN echo \"deb-src http://ftp.us.debian.org/debian testing main\" >> /etc/apt/sources.list \\\n && apt-get update -y \\\n && apt-get install debian-archive-keyring debian-keyring -y -q \\\n && apt-get update -y \\\n && apt-get install --no-install-recommends build-essential ca-certificates curl git locales openssh-client pkg-config unzip wget zip -y -q \\\n && mkdir -p /tools \\\n && mkdir -p /srcs \\\n && cd /srcs \\\n && apt-get source -d wget git python-zmq ca-certificates pkg-config libpng-dev \\\n && cd / \\\n && locale-gen en_US.UTF-8 \\\n && update-locale LANG=en_US.UTF-8 \\\n && wget --quiet -O ~/miniconda.sh http://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh \\\n && chmod +x ~/miniconda.sh \\\n && ~/miniconda.sh -b -f -p $DATALAB_CONDA_DIR \\\n && rm ~/miniconda.sh \\\n && conda update conda --quiet --yes \\\n && conda config --system --append channels conda-forge \\\n && conda config --system --set show_channel_urls true \\\n && conda update --all --quiet --yes \\\n && conda create --yes --quiet --name $PYTHON_2_ENV python=2.7 crcmod==1.7 dask==0.17.1 dill==0.2.6 future==0.16.0 futures==3.2.0 google-api-python-client==1.6.2 httplib2==0.10.3 h5py==2.7.1 ipykernel==4.8.2 ipywidgets==7.2.1 jinja2==2.8 jsonschema==2.6.0 matplotlib==2.1.2 mock==2.0.0 nltk==3.2.1 numpy==1.14.0 oauth2client==2.2.0 pandas-gbq==0.3.0 pandas==0.22.0 pandas-profiling==1.4.2 pandocfilters==1.4.2 pillow==5.0.0 pip==18.1 plotly==1.12.5 psutil==4.3.0 pygments==2.1.3 python-dateutil==2.5.0 python-snappy==0.5.1 pytz==2018.4 pyyaml==3.13 pyzmq==17.1.0 requests==2.18.4 scikit-image==0.13.0 scikit-learn==0.19.1 scipy==1.0.0 seaborn==0.7.0 six==1.11.0 statsmodels==0.8.0 sympy==0.7.6.1 tornado==4.5.1 widgetsnbextension==3.2.1 xgboost==0.6a2 \\\n && source activate $PYTHON_2_ENV \\\n && pip install only-if-needed apache-airflow==1.9.0 bs4==0.0.1 ggplot==0.6.8 google-cloud-dataflow==2.0.0 google-cloud-monitoring==0.28.0 lime==0.1.1.23 protobuf==3.6.1 tensorflow==1.8.0 --quiet -U --upgrade-strategy --no-cache-dir \\\n && source deactivate \\\n && conda clean -tipsy \\\n && unset OLDPWD \\\n && conda create --yes --quiet --name $PYTHON_3_ENV python=3.5 crcmod==1.7 dask==0.17.1 dill==0.2.6 google-api-python-client==1.6.2 httplib2==0.10.3 h5py==2.7.1 ipykernel==4.8.2 ipywidgets==7.2.1 jinja2==2.8 jsonschema==2.6.0 matplotlib==2.1.2 mock==2.0.0 nltk==3.2.1 notebook==5.6.0 numpy==1.14.0 oauth2client==2.2.0 pandas-gbq==0.3.0 pandas==0.22.0 pandocfilters==1.4.2 pillow==5.0.0 pip==18.0 plotly==1.12.5 psutil==4.3.0 pygments==2.1.3 python-dateutil==2.5.0 python-snappy==0.5.1 pytz==2018.4 pyzmq==17.1.0 requests==2.18.4 scikit-image==0.13.0 scikit-learn==0.19.1 scipy==1.0.0 seaborn==0.7.0 six==1.11.0 statsmodels==0.8.0 sympy==0.7.6.1 tornado==4.5.1 widgetsnbextension==3.2.1 xgboost==0.6a2 \\\n && cp /usr/local/envs/py3env/bin/pip /usr/local/envs/py3env/bin/pip3 \\\n && source deactivate \\\n && source activate $PYTHON_2_ENV \\\n && python -m ipykernel install --prefix=/usr/local/envs/py3env \\\n && source deactivate \\\n && conda clean -tipsy \\\n && find $DATALAB_CONDA_DIR/envs/*/lib -type d -name tests | grep -v h5py | xargs rm -rf \\\n && cd / \\\n && mkdir -p /tools/node \\\n && wget -nv https://nodejs.org/dist/v6.10.0/node-v6.10.0-linux-x64.tar.gz -O node.tar.gz \\\n && tar xzf node.tar.gz -C /tools/node --strip-components=1 \\\n && rm node.tar.gz \\\n && wget -nv https://dl.google.com/dl/cloudsdk/release/google-cloud-sdk.zip \\\n && unzip -qq google-cloud-sdk.zip -d tools \\\n && rm google-cloud-sdk.zip \\\n && tools/google-cloud-sdk/install.sh --usage-reporting=false --path-update=false --bash-completion=false --disable-installation-options \\\n && tools/google-cloud-sdk/bin/gcloud -q components update gcloud core bq gsutil compute preview alpha beta \\\n && tools/google-cloud-sdk/bin/gcloud config set component_manager/disable_update_check true \\\n && touch /tools/google-cloud-sdk/lib/third_party/google.py \\\n && /tools/node/bin/npm install bunyan@1.7.1 http-proxy@1.13.2 mkdirp@0.5.1 node-cache@3.2.0 node-uuid@1.4.7 tcp-port-used@0.1.2 ws@1.1.4 \\\n && cd / \\\n && /tools/node/bin/npm install -g forever \\\n && apt-get autoremove -y \\\n && rm -rf /var/lib/apt/lists/* \\\n && rm -rf /tmp/* \\\n && rm -rf /root/.cache/* \\\n && rm -rf /usr/share/locale/* \\\n && rm -rf /usr/share/i18n/locales/*\n#   Install Python3 packages that aren't available or up-to-date in Conda.\n#   For some reasons, merging it with the commands above does not work so creating a separate one.\nRUN source activate $PYTHON_3_ENV \\\n && pip install only-if-needed apache-airflow==1.9.0 bs4==0.0.1 ggplot==0.6.8 google-cloud-monitoring==0.28.0 lime==0.1.1.23 protobuf==3.6.1 tensorflow==1.8.0 --quiet -U --upgrade-strategy --no-cache-dir\nENV LANG=\"en_US.UTF-8\"\n#   Copy local configuration files\nCOPY config/ipython.py /etc/ipython/ipython_config.py\nCOPY config/nbconvert.py /etc/jupyter/jupyter_notebook_config.py\n#   Directory \"py\" may be empty and in that case it will git clone pydatalab from repo\nCOPY pydatalab /datalab/lib/pydatalab\nCOPY nbconvert /datalab/nbconvert\nRUN if [ -d /datalab/lib/pydatalab/.git ] ; then echo \"use local lib\" ; else git clone https://github.com/googledatalab/pydatalab.git /datalab/lib/pydatalab ; fi \\\n && cd /datalab/lib/pydatalab \\\n && /tools/node/bin/npm install -g typescript@3.0.3 \\\n && tsc --module amd --noImplicitAny --outdir datalab/notebook/static datalab/notebook/static/*.ts \\\n && tsc --module amd --noImplicitAny --outdir google/datalab/notebook/static google/datalab/notebook/static/*.ts \\\n && /tools/node/bin/npm uninstall -g typescript \\\n && cd /datalab/lib/pydatalab \\\n && source activate $PYTHON_2_ENV \\\n && pip install only-if-needed . --upgrade-strategy --no-cache-dir \\\n && pip install only-if-needed /datalab/lib/pydatalab/solutionbox/image_classification/. --upgrade-strategy \\\n && pip install only-if-needed /datalab/lib/pydatalab/solutionbox/structured_data/. --upgrade-strategy \\\n && source deactivate \\\n && source activate $PYTHON_3_ENV \\\n && pip install only-if-needed . --upgrade-strategy --no-cache-dir \\\n && pip install only-if-needed /datalab/lib/pydatalab/solutionbox/image_classification/. --upgrade-strategy \\\n && pip install only-if-needed /datalab/lib/pydatalab/solutionbox/structured_data/. --upgrade-strategy \\\n && pip install only-if-needed jupyter_highlight_selected_word==0.2.0 --upgrade-strategy \\\n && jupyter nbextension install --py datalab.notebook \\\n && jupyter nbextension install --py google.datalab.notebook \\\n && jupyter nbextension install --py jupyter_highlight_selected_word \\\n && jupyter nbextension enable --sys-prefix --py jupyter_highlight_selected_word \\\n && jupyter nbextension enable --sys-prefix --py widgetsnbextension \\\n && source deactivate \\\n && rm datalab/notebook/static/*.js google/datalab/notebook/static/*.js \\\n && mkdir -p /datalab/nbconvert \\\n && cp -R /usr/local/share/jupyter/nbextensions/gcpdatalab/* /datalab/nbconvert \\\n && ln -s $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/lib/python3.5/site-packages/notebook/static/custom/custom.css /datalab/nbconvert/custom.css\n#   Add third party license files\nRUN mkdir -p /tools/license\nCOPY license.sh /tools/license\nCOPY third_party_licenses.csv /tools/license\nRUN mkdir /usr/licenses \\\n && /tools/license/license.sh /tools/license/third_party_licenses.csv /usr/licenses\nCOPY config/py2-kernel.json $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python2/kernel.json\nCOPY config/py3-kernel.json $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python3/kernel.json\nCOPY config/py2-kernel-startup.sh $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python2/kernel-startup.sh\nCOPY config/py3-kernel-startup.sh $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python3/kernel-startup.sh\nRUN chmod 755 $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python2/kernel-startup.sh \\\n && chmod 755 $DATALAB_CONDA_DIR/envs/$PYTHON_3_ENV/share/jupyter/kernels/python3/kernel-startup.sh\n","originalDockerfileUglifiedHash":"f906b2977537e4ade1111bd53f79619d","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/f73de65780df6be4cfd39fb64233e9ff33511bb7.dockerfile"}