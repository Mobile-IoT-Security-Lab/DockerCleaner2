{"seed":1110380337,"processedDockerfileHash":"6df38c941d91f3df15fcb622527f56ec","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","have-a-healthcheck","have-a-user"],"processedDockerfile":"#   Licensed to the Apache Software Foundation (ASF) under one or more\n#   contributor license agreements.  See the NOTICE file distributed with\n#   this work for additional information regarding copyright ownership.\n#   The ASF licenses this file to You under the Apache License, Version 2.0\n#   (the \"License\"); you may not use this file except in compliance with\n#   the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#   Refer to https://github.com/SnappyDataInc/spark-on-k8s/tree/master/docs/building-images.md#zeppelin-image\n#   for instructions to build the Docker image.\n#   This Dockerfile expects spark-on-k8s distribution directory (spark-2.2.0-k8s-0.5.0-bin-2.7.3) and\n#   the script 'setSparkEnvVars.sh' to be in the same directory where this Dockerfile is kept.\nFROM ubuntu:16.04\nMAINTAINER Apache Software Foundation <dev@zeppelin.apache.org>\n#   `Z_VERSION` will be updated by `dev/change_zeppelin_version.sh`\nENV Z_VERSION=\"0.7.3\"\nENV LOG_TAG=\"[ZEPPELIN_${Z_VERSION}]:\" \\\n    Z_HOME=\"/zeppelin\" \\\n    LANG=\"en_US.UTF-8\" \\\n    LC_ALL=\"en_US.UTF-8\"\nRUN echo \"$LOG_TAG update and install basic packages\" \\\n && apt-get update -y \\\n && apt-get install --no-install-recommends locales=2.23-0ubuntu11.3 -y \\\n && locale-gen $LANG \\\n && apt-get install --no-install-recommends software-properties-common=0.96.20.10 -y \\\n && apt-get -y autoclean \\\n && apt-get -y dist-upgrade \\\n && apt-get install --no-install-recommends build-essential=12.1ubuntu2 -y\nRUN echo \"$LOG_TAG install tini related packages\" \\\n && apt-get install --no-install-recommends wget=1.17.1-1ubuntu1.5 curl=7.47.0-1ubuntu2.19 grep=2.25-1~16.04.1 sed=4.2.2-7 dpkg=1.18.4ubuntu1.7 -y \\\n && TINI_VERSION=`curl https://github.com/krallin/tini/releases/latest | grep -o \"/v.*\\\\\"\" | sed 's:^..\\\\(.*\\\\).$:\\\\1:' ` \\\n && curl -L \"https://github.com/krallin/tini/releases/download/v${TINI_VERSION}/tini_${TINI_VERSION}.deb\" > tini.deb \\\n && dpkg -i tini.deb \\\n && rm tini.deb\nENV JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\nRUN echo \"$LOG_TAG Install java8\" \\\n && apt-get update -y \\\n && apt-get install --no-install-recommends openjdk-8-jdk=8u292-b10-0ubuntu1~16.04.1 -y \\\n && rm -rf /var/lib/apt/lists/*\n#   Should install conda first before numpy, matploylib since pip and python will be installed by conda\nRUN echo \"$LOG_TAG Install miniconda2 related packages\" \\\n && apt-get update -y \\\n && apt-get install --no-install-recommends bzip2=1.0.6-8ubuntu0.2 ca-certificates=20210119~16.04.1 libglib2.0-0=2.48.2-0ubuntu4.8 libxext6=2:1.3.3-1 libsm6=2:1.2.2-1 libxrender1=1:0.9.9-0ubuntu1 git=1:2.7.4-0ubuntu1.10 mercurial=3.7.3-1ubuntu1.2 subversion=1.9.3-2ubuntu1.3 -y \\\n && echo 'export PATH=/opt/conda/bin:$PATH' > /etc/profile.d/conda.sh \\\n && wget --quiet https://repo.continuum.io/miniconda/Miniconda2-4.3.11-Linux-x86_64.sh -O ~/miniconda.sh \\\n && /bin/bash ~/miniconda.sh -b -p /opt/conda \\\n && rm ~/miniconda.sh\nENV PATH=\"/opt/conda/bin:$PATH\"\nRUN echo \"$LOG_TAG Install python related packages\" \\\n && apt-get update -y \\\n && apt-get install --no-install-recommends python-dev=2.7.12-1~16.04 python-pip=8.1.1-2ubuntu0.6 -y \\\n && apt-get install --no-install-recommends gfortran=4:5.3.1-1ubuntu1 -y \\\n && apt-get install --no-install-recommends libblas-dev=3.6.0-2ubuntu2 libatlas-dev=3.10.2-9 liblapack-dev=3.6.0-2ubuntu2 -y \\\n && apt-get install --no-install-recommends libpng-dev libfreetype6-dev=2.6.1-0.1ubuntu2.5 libxft-dev=2.3.2-1 -y \\\n && apt-get install --no-install-recommends python-tk=2.7.12-1~16.04 libxml2-dev=2.9.3+dfsg1-1ubuntu0.7 libxslt-dev zlib1g-dev=1:1.2.8.dfsg-2ubuntu4.3 -y \\\n && pip install numpy==1.24.2 \\\n && pip install matplotlib==3.7.1\nRUN echo \"$LOG_TAG Install R related packages\" \\\n && echo \"deb http://cran.rstudio.com/bin/linux/ubuntu xenial/\" | tee -a /etc/apt/sources.list \\\n && gpg --keyserver keyserver.ubuntu.com --recv-key E084DAB9 \\\n && gpg -a --export E084DAB9 | apt-key add - \\\n && apt-get update -y \\\n && apt-get install --no-install-recommends r-base=3.2.3-4 r-base-dev=3.2.3-4 -y \\\n && R -e \"install.packages('knitr', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('ggplot2', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('googleVis', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('data.table', repos='http://cran.us.r-project.org')\" \\\n && apt-get install --no-install-recommends libcurl4-gnutls-dev=7.47.0-1ubuntu2.19 libssl-dev=1.0.2g-1ubuntu4.20 -y \\\n && R -e \"install.packages('devtools', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('Rcpp', repos='http://cran.us.r-project.org')\" \\\n && Rscript -e \"library('devtools'); library('Rcpp'); install_github('ramnathv/rCharts')\"\nENV SEARCH_STRING=\"<name>zeppelin.interpreters<\\/name>\"\nENV INSERT_STRING=\"org.apache.zeppelin.interpreter.SnappyDataZeppelinInterpreter,org.apache.zeppelin.interpreter.SnappyDataSqlZeppelinInterpreter,\"\nENV LEAD_HOST=\"localhost\"\nENV LEAD_PORT=\"3768\"\nRUN echo \"$LOG_TAG Download Zeppelin binary and install interpreter for snappydata\" \\\n && wget -O /tmp/zeppelin-${Z_VERSION}-bin-all.tgz http://archive.apache.org/dist/zeppelin/zeppelin-${Z_VERSION}/zeppelin-${Z_VERSION}-bin-all.tgz \\\n && tar -zxvf /tmp/zeppelin-${Z_VERSION}-bin-all.tgz \\\n && rm -rf /tmp/zeppelin-${Z_VERSION}-bin-all.tgz \\\n && mv /zeppelin-${Z_VERSION}-bin-all ${Z_HOME} \\\n && cp ${Z_HOME}/conf/zeppelin-site.xml.template ${Z_HOME}/conf/zeppelin-site.xml \\\n && sed -i \"/${SEARCH_STRING}/{n;s/<value>/<value>${INSERT_STRING}/}\" ${Z_HOME}/conf/zeppelin-site.xml \\\n && ${Z_HOME}/bin/install-interpreter.sh --name snappydata --artifact io.snappydata:snappydata-zeppelin:0.7.3 \\\n && ${Z_HOME}/bin/zeppelin-daemon.sh start \\\n && while ! test -f ${Z_HOME}/conf/interpreter.json ; do sleep 3s ; done \\\n && ${Z_HOME}/bin/zeppelin-daemon.sh stop \\\n && sed -i \"/group\\\": \\\"snappydata\\\"/,/isExistingProcess\\\": false/{s/port\\\": -1/port\\\": ${LEAD_PORT}/}\" ${Z_HOME}/conf/interpreter.json \\\n && sed -i \"/group\\\": \\\"snappydata\\\"/,/isExistingProcess\\\": false/{s/isExistingProcess\\\": false/isExistingProcess\\\": snappydatainc_marker/}\" ${Z_HOME}/conf/interpreter.json \\\n && sed -i \"/snappydatainc_marker/a \\\"host\\\": \\\"${LEAD_HOST}\\\",\" ${Z_HOME}/conf/interpreter.json \\\n && sed -i \"s/snappydatainc_marker/true/\" ${Z_HOME}/conf/interpreter.json\nRUN echo \"$LOG_TAG Cleanup\" \\\n && apt-get autoclean \\\n && apt-get clean\nEXPOSE 8080/tcp\n#  ###### Begin changes for Spark-on-k8s #################\nRUN mkdir -p /opt/spark \\\n && mkdir -p /opt/spark/work-dir touch /opt/spark/RELEASE \\\n && rm -f /bin/sh \\\n && ln -sv /bin/bash /bin/sh \\\n && chgrp root /etc/passwd \\\n && chmod ug+rw /etc/passwd\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/jars /opt/spark/jars\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/bin /opt/spark/bin\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/sbin /opt/spark/sbin\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/conf /opt/spark/conf\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/dockerfiles/spark-base/entrypoint.sh /opt/\n#   Copy aws and gcp jars\n#   COPY aws_gcp_jars/hadoop-aws-2.6.0.jar /opt/spark/jars\n#   COPY aws_gcp_jars/aws-java-sdk-1.7.4.jar /opt/spark/jars\n#   COPY aws_gcp_jars/gcs-connector-latest-hadoop2.jar /opt/spark/jars\nCOPY setSparkEnvVars.sh /opt/\nENV SPARK_HOME=\"/opt/spark\"\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/examples /opt/spark/examples\nCMD SPARK_CLASSPATH=\"${SPARK_HOME}/jars/*\" \\\n && env | grep SPARK_JAVA_OPT_ | sed 's/[^=]*=\\(.*\\)/\\1/g' > /tmp/java_opts.txt \\\n && readarray -t SPARK_DRIVER_JAVA_OPTS < /tmp/java_opts.txt \\\n && if ! [ -z ${SPARK_MOUNTED_CLASSPATH+x} ] ; then SPARK_CLASSPATH=\"$SPARK_MOUNTED_CLASSPATH:$SPARK_CLASSPATH\" ; fi \\\n && if ! [ -z ${SPARK_SUBMIT_EXTRA_CLASSPATH+x} ] ; then SPARK_CLASSPATH=\"$SPARK_SUBMIT_EXTRA_CLASSPATH:$SPARK_CLASSPATH\" ; fi \\\n && if ! [ -z ${SPARK_EXTRA_CLASSPATH+x} ] ; then SPARK_CLASSPATH=\"$SPARK_EXTRA_CLASSPATH:$SPARK_CLASSPATH\" ; fi \\\n && if ! [ -z ${SPARK_MOUNTED_FILES_DIR+x} ] ; then cp -R \"$SPARK_MOUNTED_FILES_DIR/.\" . ; fi \\\n && if ! [ -z ${SPARK_MOUNTED_FILES_FROM_SECRET_DIR} ] ; then cp -R \"$SPARK_MOUNTED_FILES_FROM_SECRET_DIR/.\" . ; fi \\\n && ${JAVA_HOME}/bin/java \"${SPARK_DRIVER_JAVA_OPTS[@]}\" -cp \"$SPARK_CLASSPATH\" -Xms$SPARK_DRIVER_MEMORY -Xmx$SPARK_DRIVER_MEMORY -Dspark.driver.bindAddress=$SPARK_DRIVER_BIND_ADDRESS $SPARK_DRIVER_CLASS $SPARK_DRIVER_ARGS\n#  ENV MASTER k8s://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT\n#  ENV SPARK_SUBMIT_OPTIONS \"--kubernetes-namespace default --conf spark.kubernetes.driver.pod.name=$HOSTNAME --conf spark.kubernetes.driver.docker.image=shirishd/spark-driver:v2.2.0 --conf spark.kubernetes.executor.docker.image=shirishd/spark-executor:v2.2.0\"\n#  CMD [\"/opt/setSparkEnvVars.sh\"]\nCMD [\"bin/bash\", \"-c\", \"source\", \"/opt/setSparkEnvVars.sh\"]\n#  RUN /bin/bash -c \"source /opt/setSparkEnvVars.sh\"\n#  ###### End changes for Spark-on-k8s ##########################\nENTRYPOINT [\"/usr/bin/tini\", \"--\"]\nWORKDIR ${Z_HOME}\nCMD [\"bin/zeppelin.sh\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"#  Licensed to the Apache Software Foundation (ASF) under one or more\n#  contributor license agreements.  See the NOTICE file distributed with\n#  this work for additional information regarding copyright ownership.\n#  The ASF licenses this file to You under the Apache License, Version 2.0\n#  (the \"License\"); you may not use this file except in compliance with\n#  the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n#  Refer to https://github.com/SnappyDataInc/spark-on-k8s/tree/master/docs/building-images.md#zeppelin-image\n#  for instructions to build the Docker image.\n#  This Dockerfile expects spark-on-k8s distribution directory (spark-2.2.0-k8s-0.5.0-bin-2.7.3) and\n#  the script 'setSparkEnvVars.sh' to be in the same directory where this Dockerfile is kept.\nFROM ubuntu:16.04\nMAINTAINER Apache Software Foundation <dev@zeppelin.apache.org>\n#  `Z_VERSION` will be updated by `dev/change_zeppelin_version.sh`\nENV Z_VERSION=\"0.7.3\"\nENV LOG_TAG=\"[ZEPPELIN_${Z_VERSION}]:\" \\\n    Z_HOME=\"/zeppelin\" \\\n    LANG=\"en_US.UTF-8\" \\\n    LC_ALL=\"en_US.UTF-8\"\nRUN echo \"$LOG_TAG update and install basic packages\" \\\n && apt-get update -y \\\n && apt-get install locales -y \\\n && locale-gen $LANG \\\n && apt-get install software-properties-common -y \\\n && apt-get -y autoclean \\\n && apt-get -y dist-upgrade \\\n && apt-get install build-essential -y\nRUN echo \"$LOG_TAG install tini related packages\" \\\n && apt-get install wget curl grep sed dpkg -y \\\n && TINI_VERSION=`curl https://github.com/krallin/tini/releases/latest | grep -o \"/v.*\\\\\"\" | sed 's:^..\\\\(.*\\\\).$:\\\\1:' ` \\\n && curl -L \"https://github.com/krallin/tini/releases/download/v${TINI_VERSION}/tini_${TINI_VERSION}.deb\" > tini.deb \\\n && dpkg -i tini.deb \\\n && rm tini.deb\nENV JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\nRUN echo \"$LOG_TAG Install java8\" \\\n && apt-get update -y \\\n && apt-get install openjdk-8-jdk -y \\\n && rm -rf /var/lib/apt/lists/*\n#  Should install conda first before numpy, matploylib since pip and python will be installed by conda\nRUN echo \"$LOG_TAG Install miniconda2 related packages\" \\\n && apt-get update -y \\\n && apt-get install bzip2 ca-certificates libglib2.0-0 libxext6 libsm6 libxrender1 git mercurial subversion -y \\\n && echo 'export PATH=/opt/conda/bin:$PATH' > /etc/profile.d/conda.sh \\\n && wget --quiet https://repo.continuum.io/miniconda/Miniconda2-4.3.11-Linux-x86_64.sh -O ~/miniconda.sh \\\n && /bin/bash ~/miniconda.sh -b -p /opt/conda \\\n && rm ~/miniconda.sh\nENV PATH=\"/opt/conda/bin:$PATH\"\nRUN echo \"$LOG_TAG Install python related packages\" \\\n && apt-get update -y \\\n && apt-get install python-dev python-pip -y \\\n && apt-get install gfortran -y \\\n && apt-get install libblas-dev libatlas-dev liblapack-dev -y \\\n && apt-get install libpng-dev libfreetype6-dev libxft-dev -y \\\n && apt-get install python-tk libxml2-dev libxslt-dev zlib1g-dev -y \\\n && pip install numpy \\\n && pip install matplotlib\nRUN echo \"$LOG_TAG Install R related packages\" \\\n && echo \"deb http://cran.rstudio.com/bin/linux/ubuntu xenial/\" | tee -a /etc/apt/sources.list \\\n && gpg --keyserver keyserver.ubuntu.com --recv-key E084DAB9 \\\n && gpg -a --export E084DAB9 | apt-key add - \\\n && apt-get update -y \\\n && apt-get install r-base r-base-dev -y \\\n && R -e \"install.packages('knitr', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('ggplot2', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('googleVis', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('data.table', repos='http://cran.us.r-project.org')\" \\\n && apt-get install libcurl4-gnutls-dev libssl-dev -y \\\n && R -e \"install.packages('devtools', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('Rcpp', repos='http://cran.us.r-project.org')\" \\\n && Rscript -e \"library('devtools'); library('Rcpp'); install_github('ramnathv/rCharts')\"\nENV SEARCH_STRING=\"<name>zeppelin.interpreters<\\/name>\"\nENV INSERT_STRING=\"org.apache.zeppelin.interpreter.SnappyDataZeppelinInterpreter,org.apache.zeppelin.interpreter.SnappyDataSqlZeppelinInterpreter,\"\nENV LEAD_HOST=\"localhost\"\nENV LEAD_PORT=\"3768\"\nRUN echo \"$LOG_TAG Download Zeppelin binary and install interpreter for snappydata\" \\\n && wget -O /tmp/zeppelin-${Z_VERSION}-bin-all.tgz http://archive.apache.org/dist/zeppelin/zeppelin-${Z_VERSION}/zeppelin-${Z_VERSION}-bin-all.tgz \\\n && tar -zxvf /tmp/zeppelin-${Z_VERSION}-bin-all.tgz \\\n && rm -rf /tmp/zeppelin-${Z_VERSION}-bin-all.tgz \\\n && mv /zeppelin-${Z_VERSION}-bin-all ${Z_HOME} \\\n && cp ${Z_HOME}/conf/zeppelin-site.xml.template ${Z_HOME}/conf/zeppelin-site.xml \\\n && sed -i \"/${SEARCH_STRING}/{n;s/<value>/<value>${INSERT_STRING}/}\" ${Z_HOME}/conf/zeppelin-site.xml \\\n && ${Z_HOME}/bin/install-interpreter.sh --name snappydata --artifact io.snappydata:snappydata-zeppelin:0.7.3 \\\n && ${Z_HOME}/bin/zeppelin-daemon.sh start \\\n && while ! test -f ${Z_HOME}/conf/interpreter.json ; do sleep 3s ; done \\\n && ${Z_HOME}/bin/zeppelin-daemon.sh stop \\\n && sed -i \"/group\\\": \\\"snappydata\\\"/,/isExistingProcess\\\": false/{s/port\\\": -1/port\\\": ${LEAD_PORT}/}\" ${Z_HOME}/conf/interpreter.json \\\n && sed -i \"/group\\\": \\\"snappydata\\\"/,/isExistingProcess\\\": false/{s/isExistingProcess\\\": false/isExistingProcess\\\": snappydatainc_marker/}\" ${Z_HOME}/conf/interpreter.json \\\n && sed -i \"/snappydatainc_marker/a \\\"host\\\": \\\"${LEAD_HOST}\\\",\" ${Z_HOME}/conf/interpreter.json \\\n && sed -i \"s/snappydatainc_marker/true/\" ${Z_HOME}/conf/interpreter.json\nRUN echo \"$LOG_TAG Cleanup\" \\\n && apt-get autoclean \\\n && apt-get clean\nEXPOSE 8080/tcp\n# ###### Begin changes for Spark-on-k8s #################\nRUN mkdir -p /opt/spark \\\n && mkdir -p /opt/spark/work-dir touch /opt/spark/RELEASE \\\n && rm -f /bin/sh \\\n && ln -sv /bin/bash /bin/sh \\\n && chgrp root /etc/passwd \\\n && chmod ug+rw /etc/passwd\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/jars /opt/spark/jars\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/bin /opt/spark/bin\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/sbin /opt/spark/sbin\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/conf /opt/spark/conf\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/dockerfiles/spark-base/entrypoint.sh /opt/\n#  Copy aws and gcp jars\n#  COPY aws_gcp_jars/hadoop-aws-2.6.0.jar /opt/spark/jars\n#  COPY aws_gcp_jars/aws-java-sdk-1.7.4.jar /opt/spark/jars\n#  COPY aws_gcp_jars/gcs-connector-latest-hadoop2.jar /opt/spark/jars\nCOPY setSparkEnvVars.sh /opt/\nENV SPARK_HOME=\"/opt/spark\"\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/examples /opt/spark/examples\nCMD SPARK_CLASSPATH=\"${SPARK_HOME}/jars/*\" \\\n && env | grep SPARK_JAVA_OPT_ | sed 's/[^=]*=\\(.*\\)/\\1/g' > /tmp/java_opts.txt \\\n && readarray -t SPARK_DRIVER_JAVA_OPTS < /tmp/java_opts.txt \\\n && if ! [ -z ${SPARK_MOUNTED_CLASSPATH+x} ] ; then SPARK_CLASSPATH=\"$SPARK_MOUNTED_CLASSPATH:$SPARK_CLASSPATH\" ; fi \\\n && if ! [ -z ${SPARK_SUBMIT_EXTRA_CLASSPATH+x} ] ; then SPARK_CLASSPATH=\"$SPARK_SUBMIT_EXTRA_CLASSPATH:$SPARK_CLASSPATH\" ; fi \\\n && if ! [ -z ${SPARK_EXTRA_CLASSPATH+x} ] ; then SPARK_CLASSPATH=\"$SPARK_EXTRA_CLASSPATH:$SPARK_CLASSPATH\" ; fi \\\n && if ! [ -z ${SPARK_MOUNTED_FILES_DIR+x} ] ; then cp -R \"$SPARK_MOUNTED_FILES_DIR/.\" . ; fi \\\n && if ! [ -z ${SPARK_MOUNTED_FILES_FROM_SECRET_DIR} ] ; then cp -R \"$SPARK_MOUNTED_FILES_FROM_SECRET_DIR/.\" . ; fi \\\n && ${JAVA_HOME}/bin/java \"${SPARK_DRIVER_JAVA_OPTS[@]}\" -cp \"$SPARK_CLASSPATH\" -Xms$SPARK_DRIVER_MEMORY -Xmx$SPARK_DRIVER_MEMORY -Dspark.driver.bindAddress=$SPARK_DRIVER_BIND_ADDRESS $SPARK_DRIVER_CLASS $SPARK_DRIVER_ARGS\n# ENV MASTER k8s://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT\n# ENV SPARK_SUBMIT_OPTIONS \"--kubernetes-namespace default --conf spark.kubernetes.driver.pod.name=$HOSTNAME --conf spark.kubernetes.driver.docker.image=shirishd/spark-driver:v2.2.0 --conf spark.kubernetes.executor.docker.image=shirishd/spark-executor:v2.2.0\"\n# CMD [\"/opt/setSparkEnvVars.sh\"]\nCMD [\"bin/bash\", \"-c\", \"source\", \"/opt/setSparkEnvVars.sh\"]\n# RUN /bin/bash -c \"source /opt/setSparkEnvVars.sh\"\n# ###### End changes for Spark-on-k8s ##########################\nENTRYPOINT [\"/usr/bin/tini\", \"--\"]\nWORKDIR ${Z_HOME}\nCMD [\"bin/zeppelin.sh\"]\n","injectedSmells":[],"originalDockerfileHash":"f21ac72ef1103625f50314e2422f0f31","successfullyInjectedSmells":[],"originalDockerfileUglified":"#   Licensed to the Apache Software Foundation (ASF) under one or more\n#   contributor license agreements.  See the NOTICE file distributed with\n#   this work for additional information regarding copyright ownership.\n#   The ASF licenses this file to You under the Apache License, Version 2.0\n#   (the \"License\"); you may not use this file except in compliance with\n#   the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#   Refer to https://github.com/SnappyDataInc/spark-on-k8s/tree/master/docs/building-images.md#zeppelin-image\n#   for instructions to build the Docker image.\n#   This Dockerfile expects spark-on-k8s distribution directory (spark-2.2.0-k8s-0.5.0-bin-2.7.3) and\n#   the script 'setSparkEnvVars.sh' to be in the same directory where this Dockerfile is kept.\nFROM ubuntu:16.04\nMAINTAINER Apache Software Foundation <dev@zeppelin.apache.org>\n#   `Z_VERSION` will be updated by `dev/change_zeppelin_version.sh`\nENV Z_VERSION=\"0.7.3\"\nENV LOG_TAG=\"[ZEPPELIN_${Z_VERSION}]:\" \\\n    Z_HOME=\"/zeppelin\" \\\n    LANG=\"en_US.UTF-8\" \\\n    LC_ALL=\"en_US.UTF-8\"\nRUN echo \"$LOG_TAG update and install basic packages\" \\\n && apt-get update -y \\\n && apt-get install locales -y \\\n && locale-gen $LANG \\\n && apt-get install software-properties-common -y \\\n && apt-get -y autoclean \\\n && apt-get -y dist-upgrade \\\n && apt-get install build-essential -y\nRUN echo \"$LOG_TAG install tini related packages\" \\\n && apt-get install wget curl grep sed dpkg -y \\\n && TINI_VERSION=`curl https://github.com/krallin/tini/releases/latest | grep -o \"/v.*\\\\\"\" | sed 's:^..\\\\(.*\\\\).$:\\\\1:' ` \\\n && curl -L \"https://github.com/krallin/tini/releases/download/v${TINI_VERSION}/tini_${TINI_VERSION}.deb\" > tini.deb \\\n && dpkg -i tini.deb \\\n && rm tini.deb\nENV JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\nRUN echo \"$LOG_TAG Install java8\" \\\n && apt-get update -y \\\n && apt-get install openjdk-8-jdk -y \\\n && rm -rf /var/lib/apt/lists/*\n#   Should install conda first before numpy, matploylib since pip and python will be installed by conda\nRUN echo \"$LOG_TAG Install miniconda2 related packages\" \\\n && apt-get update -y \\\n && apt-get install bzip2 ca-certificates libglib2.0-0 libxext6 libsm6 libxrender1 git mercurial subversion -y \\\n && echo 'export PATH=/opt/conda/bin:$PATH' > /etc/profile.d/conda.sh \\\n && wget --quiet https://repo.continuum.io/miniconda/Miniconda2-4.3.11-Linux-x86_64.sh -O ~/miniconda.sh \\\n && /bin/bash ~/miniconda.sh -b -p /opt/conda \\\n && rm ~/miniconda.sh\nENV PATH=\"/opt/conda/bin:$PATH\"\nRUN echo \"$LOG_TAG Install python related packages\" \\\n && apt-get update -y \\\n && apt-get install python-dev python-pip -y \\\n && apt-get install gfortran -y \\\n && apt-get install libblas-dev libatlas-dev liblapack-dev -y \\\n && apt-get install libpng-dev libfreetype6-dev libxft-dev -y \\\n && apt-get install python-tk libxml2-dev libxslt-dev zlib1g-dev -y \\\n && pip install numpy \\\n && pip install matplotlib\nRUN echo \"$LOG_TAG Install R related packages\" \\\n && echo \"deb http://cran.rstudio.com/bin/linux/ubuntu xenial/\" | tee -a /etc/apt/sources.list \\\n && gpg --keyserver keyserver.ubuntu.com --recv-key E084DAB9 \\\n && gpg -a --export E084DAB9 | apt-key add - \\\n && apt-get update -y \\\n && apt-get install r-base r-base-dev -y \\\n && R -e \"install.packages('knitr', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('ggplot2', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('googleVis', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('data.table', repos='http://cran.us.r-project.org')\" \\\n && apt-get install libcurl4-gnutls-dev libssl-dev -y \\\n && R -e \"install.packages('devtools', repos='http://cran.us.r-project.org')\" \\\n && R -e \"install.packages('Rcpp', repos='http://cran.us.r-project.org')\" \\\n && Rscript -e \"library('devtools'); library('Rcpp'); install_github('ramnathv/rCharts')\"\nENV SEARCH_STRING=\"<name>zeppelin.interpreters<\\/name>\"\nENV INSERT_STRING=\"org.apache.zeppelin.interpreter.SnappyDataZeppelinInterpreter,org.apache.zeppelin.interpreter.SnappyDataSqlZeppelinInterpreter,\"\nENV LEAD_HOST=\"localhost\"\nENV LEAD_PORT=\"3768\"\nRUN echo \"$LOG_TAG Download Zeppelin binary and install interpreter for snappydata\" \\\n && wget -O /tmp/zeppelin-${Z_VERSION}-bin-all.tgz http://archive.apache.org/dist/zeppelin/zeppelin-${Z_VERSION}/zeppelin-${Z_VERSION}-bin-all.tgz \\\n && tar -zxvf /tmp/zeppelin-${Z_VERSION}-bin-all.tgz \\\n && rm -rf /tmp/zeppelin-${Z_VERSION}-bin-all.tgz \\\n && mv /zeppelin-${Z_VERSION}-bin-all ${Z_HOME} \\\n && cp ${Z_HOME}/conf/zeppelin-site.xml.template ${Z_HOME}/conf/zeppelin-site.xml \\\n && sed -i \"/${SEARCH_STRING}/{n;s/<value>/<value>${INSERT_STRING}/}\" ${Z_HOME}/conf/zeppelin-site.xml \\\n && ${Z_HOME}/bin/install-interpreter.sh --name snappydata --artifact io.snappydata:snappydata-zeppelin:0.7.3 \\\n && ${Z_HOME}/bin/zeppelin-daemon.sh start \\\n && while ! test -f ${Z_HOME}/conf/interpreter.json ; do sleep 3s ; done \\\n && ${Z_HOME}/bin/zeppelin-daemon.sh stop \\\n && sed -i \"/group\\\": \\\"snappydata\\\"/,/isExistingProcess\\\": false/{s/port\\\": -1/port\\\": ${LEAD_PORT}/}\" ${Z_HOME}/conf/interpreter.json \\\n && sed -i \"/group\\\": \\\"snappydata\\\"/,/isExistingProcess\\\": false/{s/isExistingProcess\\\": false/isExistingProcess\\\": snappydatainc_marker/}\" ${Z_HOME}/conf/interpreter.json \\\n && sed -i \"/snappydatainc_marker/a \\\"host\\\": \\\"${LEAD_HOST}\\\",\" ${Z_HOME}/conf/interpreter.json \\\n && sed -i \"s/snappydatainc_marker/true/\" ${Z_HOME}/conf/interpreter.json\nRUN echo \"$LOG_TAG Cleanup\" \\\n && apt-get autoclean \\\n && apt-get clean\nEXPOSE 8080/tcp\n#  ###### Begin changes for Spark-on-k8s #################\nRUN mkdir -p /opt/spark \\\n && mkdir -p /opt/spark/work-dir touch /opt/spark/RELEASE \\\n && rm -f /bin/sh \\\n && ln -sv /bin/bash /bin/sh \\\n && chgrp root /etc/passwd \\\n && chmod ug+rw /etc/passwd\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/jars /opt/spark/jars\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/bin /opt/spark/bin\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/sbin /opt/spark/sbin\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/conf /opt/spark/conf\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/dockerfiles/spark-base/entrypoint.sh /opt/\n#   Copy aws and gcp jars\n#   COPY aws_gcp_jars/hadoop-aws-2.6.0.jar /opt/spark/jars\n#   COPY aws_gcp_jars/aws-java-sdk-1.7.4.jar /opt/spark/jars\n#   COPY aws_gcp_jars/gcs-connector-latest-hadoop2.jar /opt/spark/jars\nCOPY setSparkEnvVars.sh /opt/\nENV SPARK_HOME=\"/opt/spark\"\nCOPY spark-2.2.0-k8s-0.5.0-bin-2.7.3/examples /opt/spark/examples\nCMD SPARK_CLASSPATH=\"${SPARK_HOME}/jars/*\" \\\n && env | grep SPARK_JAVA_OPT_ | sed 's/[^=]*=\\(.*\\)/\\1/g' > /tmp/java_opts.txt \\\n && readarray -t SPARK_DRIVER_JAVA_OPTS < /tmp/java_opts.txt \\\n && if ! [ -z ${SPARK_MOUNTED_CLASSPATH+x} ] ; then SPARK_CLASSPATH=\"$SPARK_MOUNTED_CLASSPATH:$SPARK_CLASSPATH\" ; fi \\\n && if ! [ -z ${SPARK_SUBMIT_EXTRA_CLASSPATH+x} ] ; then SPARK_CLASSPATH=\"$SPARK_SUBMIT_EXTRA_CLASSPATH:$SPARK_CLASSPATH\" ; fi \\\n && if ! [ -z ${SPARK_EXTRA_CLASSPATH+x} ] ; then SPARK_CLASSPATH=\"$SPARK_EXTRA_CLASSPATH:$SPARK_CLASSPATH\" ; fi \\\n && if ! [ -z ${SPARK_MOUNTED_FILES_DIR+x} ] ; then cp -R \"$SPARK_MOUNTED_FILES_DIR/.\" . ; fi \\\n && if ! [ -z ${SPARK_MOUNTED_FILES_FROM_SECRET_DIR} ] ; then cp -R \"$SPARK_MOUNTED_FILES_FROM_SECRET_DIR/.\" . ; fi \\\n && ${JAVA_HOME}/bin/java \"${SPARK_DRIVER_JAVA_OPTS[@]}\" -cp \"$SPARK_CLASSPATH\" -Xms$SPARK_DRIVER_MEMORY -Xmx$SPARK_DRIVER_MEMORY -Dspark.driver.bindAddress=$SPARK_DRIVER_BIND_ADDRESS $SPARK_DRIVER_CLASS $SPARK_DRIVER_ARGS\n#  ENV MASTER k8s://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT\n#  ENV SPARK_SUBMIT_OPTIONS \"--kubernetes-namespace default --conf spark.kubernetes.driver.pod.name=$HOSTNAME --conf spark.kubernetes.driver.docker.image=shirishd/spark-driver:v2.2.0 --conf spark.kubernetes.executor.docker.image=shirishd/spark-executor:v2.2.0\"\n#  CMD [\"/opt/setSparkEnvVars.sh\"]\nCMD [\"bin/bash\", \"-c\", \"source\", \"/opt/setSparkEnvVars.sh\"]\n#  RUN /bin/bash -c \"source /opt/setSparkEnvVars.sh\"\n#  ###### End changes for Spark-on-k8s ##########################\nENTRYPOINT [\"/usr/bin/tini\", \"--\"]\nWORKDIR ${Z_HOME}\nCMD [\"bin/zeppelin.sh\"]\n","originalDockerfileUglifiedHash":"fe0a163746f4aae29724f045d4cb4531","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/79c96e25efb3093126eb87c30761e90cb5361547.dockerfile"}