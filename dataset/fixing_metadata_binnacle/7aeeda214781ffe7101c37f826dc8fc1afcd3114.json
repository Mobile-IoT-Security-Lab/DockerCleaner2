{"seed":1151201059,"processedDockerfileHash":"018ec3c720a13e9fe722b23ffa3b66f0","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","have-a-healthcheck","have-a-user"],"processedDockerfile":"FROM nvidia/cuda:10.0-cudnn7-devel AS ngraph\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends build-essential cmake clang-3.9 git curl zlib1g zlib1g-dev libtinfo-dev unzip autoconf automake libtool python3-dev python3-pip python3-wheel python3-setuptools -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n#   nGraph build, referenced ngraph-onnx/BUILDING.md\n#   NOTE(disktnk): should use 'DPYTHON_EXECUTABLE' (currently not supported)\n#   NOTE(disktnk): failed with '-DNGRAPH_GPU_ENABLE=TRUE', stop using CUDA enabled\n#   NOTE(disktnk): cannot build python bind with multiprocess\nRUN ln -s /usr/bin/python3 /usr/bin/python\nARG NGRAPH_VERSION=\"0.19.0\"\nRUN git clone https://github.com/NervanaSystems/ngraph.git -b v${NGRAPH_VERSION} \\\n && mkdir ngraph/build \\\n && cd ngraph/build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/ngraph_dist -DNGRAPH_ONNX_IMPORT_ENABLE=TRUE -DNGRAPH_USE_PREBUILT_LLVM=TRUE -DNGRAPH_INTELGPU_ENABLE=TRUE -DNGRAPH_GPU_ENABLE=FALSE -DNGRAPH_UNIT_TEST_ENABLE=FALSE \\\n && make -j1 \\\n && make install \\\n && cd .. \\\n && rm -rf build\nRUN cd ngraph/python \\\n && sed -e \"s/^distutils.ccompiler.CCompiler.compile/# &/\" setup.py > setup_.py\nRUN cd ngraph/python \\\n && git clone --recursive https://github.com/jagerman/pybind11.git \\\n && export PYBIND_HEADERS_PATH=$PWD/pybind11 \\\n && export NGRAPH_CPP_BUILD_PATH=$HOME/ngraph_dist \\\n && export NGRAPH_ONNX_IMPORT_ENABLE=TRUE \\\n && python3 -m pip install --user numpy \\\n && python3 setup_.py bdist_wheel \\\n && python3 -m pip install --user -U dist/*.whl \\\n && rm -rf build\nARG NGRAPH_ONNX_VERSION=\"0.14.0\"\nRUN cd ngraph \\\n && git clone https://github.com/NervanaSystems/ngraph-onnx.git -b v${NGRAPH_ONNX_VERSION} \\\n && cd ngraph-onnx \\\n && python3 -m pip install --user -r requirements.txt \\\n && python3 -m pip install --user -r requirements_test.txt \\\n && python3 -m pip install --user -e .\nFROM nvidia/cuda:10.0-cudnn7-devel AS tvm\n#   TVM Build, referenced Dockerfile.demo_gpu\n#   NOTE(disktnk): official installer does not copy header file\nARG TVM_VERSION=\"0.5\"\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends wget -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN wget https://raw.githubusercontent.com/dmlc/tvm/v${TVM_VERSION}/docker/install/ubuntu_install_core.sh -P /install \\\n && bash /install/ubuntu_install_core.sh \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN echo deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-6.0 main >> /etc/apt/sources.list.d/llvm.list \\\n && wget -O - http://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - \\\n && apt-get update \\\n && apt-get install --no-install-recommends llvm-6.0 -y --force-yes \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n#   based https://raw.githubusercontent.com/dmlc/tvm/v${TVM_VERSION}/docker/install/install_tvm_gpu.sh\nRUN cd /usr \\\n && git clone https://github.com/dmlc/tvm --recursive -b v${TVM_VERSION} \\\n && cd /usr/tvm \\\n && echo set\nRUN mkdir -p /usr/tvm/3rdparty/dmlc-core/build \\\n && cd /usr/tvm/3rdparty/dmlc-core/build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/dmlc_core_dist \\\n && make \\\n && make install\nRUN mkdir -p /usr/tvm/3rdparty/dlpack/build \\\n && cd /usr/tvm/3rdparty/dlpack/build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/dlpack_dist \\\n && make \\\n && make install\nFROM ubuntu:18.04 AS dldt\nARG DLDT_VERSION=\"2019_R1.1\"\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends python3-dev python3-pip python3-wheel python3-setuptools git wget sudo -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN mkdir neo \\\n && cd neo \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-gmmlib_18.4.1_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-core_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-opencl_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-opencl_19.04.12237_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-ocloc_19.04.12237_amd64.deb \\\n && sudo dpkg -i *.deb\nRUN python3 -m pip install cython\nRUN git clone https://github.com/opencv/dldt.git --recursive -b ${DLDT_VERSION} \\\n && cd dldt/inference-engine \\\n && bash install_dependencies.sh \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/* \\\n && mkdir build \\\n && cd build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/dldt_dist -DCMAKE_BUILD_TYPE=Release -DGEMM=OPENBLAS -DENABLE_PYTHON=ON \\\n && make -j4 \\\n && make install \\\n && cd .. \\\n && rm -rf build\nRUN cd dldt/model-optimizer \\\n && python3 -m pip install --user -r requirements_onnx.txt\nFROM nvidia/cuda:10.0-cudnn7-devel AS ci-base\nENV DEBIAN_FRONTEND=\"noninteractive\"\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends python3-dev python3-pip python3-wheel python3-setuptools git cmake libblas3 libblas-dev libopenblas-dev curl wget unzip sudo ninja-build libopencv-dev -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN echo deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-6.0 main >> /etc/apt/sources.list.d/llvm.list \\\n && wget -O - http://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - \\\n && apt-get update \\\n && apt-get install --no-install-recommends llvm-6.0 -y --force-yes \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nCOPY --from=ngraph /root/ngraph_dist /root/ngraph_dist\nCOPY --from=ngraph /root/.local /root/.local\nCOPY --from=tvm /root/tvm_dist /usr/local/\nCOPY --from=tvm /root/dmlc_core_dist /usr/local/\nCOPY --from=tvm /root/dlpack_dist /usr/local/\nCOPY --from=tvm /usr/tvm/include/tvm/runtime /usr/local/include/tvm/runtime\nRUN mkdir neo \\\n && cd neo \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-gmmlib_18.4.1_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-core_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-opencl_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-opencl_19.04.12237_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-ocloc_19.04.12237_amd64.deb \\\n && sudo dpkg -i *.deb\nCOPY --from=dldt /root/dldt_dist /usr/local/\nCOPY --from=dldt /dldt/inference-engine/include /root/dldt/inference-engine/include\nCOPY --from=dldt /dldt/inference-engine/bin/intel64/Release/lib /root/dldt/inference-engine/bin/intel64/Release/lib\nCOPY --from=dldt /root/.local /root/.local\nCOPY --from=dldt /dldt/model-optimizer /root/dldt/model-optimizer\nENV PYTHONPATH=\"/root/dldt/model-optimizer:${PYTHONPATH}\"\nRUN python3 -m pip install --user decorator attrs\nENV PYTHONPATH=\"/usr/tvm/python:/usr/tvm/topi/python:/usr/tvm/nnvm/python/:/usr/tvm/vta/python:${PYTHONPATH}\"\nENV PATH=\"/usr/local/nvidia/bin:/usr/local/cuda/bin:/root/.local/bin:${PATH}\"\nENV LD_LIBRARY_PATH=\"/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/root/ngraph_dist/lib:${LD_LIBRARY_PATH}\"\nFROM ci-base AS dev-base\nRUN git clone --recursive https://github.com/pfnet-research/chainer-compiler.git\nRUN python3 -m pip install --user gast\nRUN export CHAINER_VERSION=$( python3 -c \"import imp;print(imp.load_source('_version','chainer-compiler/third_party/chainer/chainer/_version.py').__version__)\" ;) \\\n && python3 -m pip install --user cupy-cuda100==$CHAINER_VERSION\nRUN CHAINER_BUILD_CHAINERX=1 CHAINERX_BUILD_CUDA=1 MAKEFLAGS=-j8 CHAINERX_NVCC_GENERATE_CODE=arch=compute_70,code=sm_70 python3 -m pip install --user chainer-compiler/third_party/chainer[test]\nRUN python3 -m pip install --user chainer-compiler/third_party/onnx-chainer[test-gpu]\nRUN mkdir -p chainer-compiler/build \\\n && cd chainer-compiler/build \\\n && cmake .. -DCHAINER_COMPILER_ENABLE_CUDA=ON -DCHAINER_COMPILER_ENABLE_CUDNN=ON -DCHAINER_COMPILER_ENABLE_OPENCV=ON -DCHAINER_COMPILER_ENABLE_PYTHON=ON -DCHAINER_COMPILER_NGRAPH_DIR=$HOME/ngraph_dist -DCHAINER_COMPILER_DLDT_DIR=$HOME/dldt -DPYTHON_EXECUTABLE=$( which python3 ;) -DCHAINER_COMPILER_ENABLE_TVM=ON -DCHAINERX_BUILD_CUDA=ON -DCHAINERX_BUILD_PYTHON=ON -DCHAINER_COMPILER_PREBUILT_CHAINERX_DIR=$( pip3 show chainer | awk '/^Location: / {print $2}' ;)/chainerx \\\n && make -j8\nFROM dev-base\nLABEL author=\"Daisuke Tanaka <duaipp@gmail.com>\"\n#   Optional packages.\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends less lv screen vim zsh -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"FROM nvidia/cuda:10.0-cudnn7-devel AS ngraph\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends build-essential cmake clang-3.9 git curl zlib1g zlib1g-dev libtinfo-dev unzip autoconf automake libtool python3-dev python3-pip python3-wheel python3-setuptools -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n#  nGraph build, referenced ngraph-onnx/BUILDING.md\n#  NOTE(disktnk): should use 'DPYTHON_EXECUTABLE' (currently not supported)\n#  NOTE(disktnk): failed with '-DNGRAPH_GPU_ENABLE=TRUE', stop using CUDA enabled\n#  NOTE(disktnk): cannot build python bind with multiprocess\nRUN ln -s /usr/bin/python3 /usr/bin/python\nARG NGRAPH_VERSION=\"0.19.0\"\nRUN git clone https://github.com/NervanaSystems/ngraph.git -b v${NGRAPH_VERSION} \\\n && mkdir ngraph/build \\\n && cd ngraph/build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/ngraph_dist -DNGRAPH_ONNX_IMPORT_ENABLE=TRUE -DNGRAPH_USE_PREBUILT_LLVM=TRUE -DNGRAPH_INTELGPU_ENABLE=TRUE -DNGRAPH_GPU_ENABLE=FALSE -DNGRAPH_UNIT_TEST_ENABLE=FALSE \\\n && make -j1 \\\n && make install \\\n && cd .. \\\n && rm -rf build\nRUN cd ngraph/python \\\n && sed -e \"s/^distutils.ccompiler.CCompiler.compile/# &/\" setup.py > setup_.py\nRUN cd ngraph/python \\\n && git clone --recursive https://github.com/jagerman/pybind11.git \\\n && export PYBIND_HEADERS_PATH=$PWD/pybind11 \\\n && export NGRAPH_CPP_BUILD_PATH=$HOME/ngraph_dist \\\n && export NGRAPH_ONNX_IMPORT_ENABLE=TRUE \\\n && python3 -m pip install --user numpy \\\n && python3 setup_.py bdist_wheel \\\n && python3 -m pip install --user -U dist/*.whl \\\n && rm -rf build\nARG NGRAPH_ONNX_VERSION=\"0.14.0\"\nRUN cd ngraph \\\n && git clone https://github.com/NervanaSystems/ngraph-onnx.git -b v${NGRAPH_ONNX_VERSION} \\\n && cd ngraph-onnx \\\n && python3 -m pip install --user -r requirements.txt \\\n && python3 -m pip install --user -r requirements_test.txt \\\n && python3 -m pip install --user -e .\nFROM nvidia/cuda:10.0-cudnn7-devel AS tvm\n#  TVM Build, referenced Dockerfile.demo_gpu\n#  NOTE(disktnk): official installer does not copy header file\nARG TVM_VERSION=\"0.5\"\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends wget -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN wget https://raw.githubusercontent.com/dmlc/tvm/v${TVM_VERSION}/docker/install/ubuntu_install_core.sh -P /install \\\n && bash /install/ubuntu_install_core.sh \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN echo deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-6.0 main >> /etc/apt/sources.list.d/llvm.list \\\n && wget -O - http://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - \\\n && apt-get update \\\n && apt-get install llvm-6.0 -y --force-yes \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n#  based https://raw.githubusercontent.com/dmlc/tvm/v${TVM_VERSION}/docker/install/install_tvm_gpu.sh\nRUN cd /usr \\\n && git clone https://github.com/dmlc/tvm --recursive -b v${TVM_VERSION} \\\n && cd /usr/tvm \\\n && echo set(USE_LLVM llvm-config-6.0) >> config.cmake \\\n && echo set(USE_CUDA ON) >> config.cmake \\\n && echo set(USE_CUDNN ON) >> config.cmake \\\n && echo set(USE_RPC ON) >> config.cmake \\\n && echo set(USE_SORT ON) >> config.cmake \\\n && echo set(USE_GRAPH_RUNTIME ON) >> config.cmake \\\n && echo set(USE_BLAS openblas) >> config.cmake \\\n && echo set(INSTALL_DEV ON) >> config.cmake \\\n && mkdir -p build \\\n && cd build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/tvm_dist \\\n && make -j10 \\\n && make install \\\n && cd .. \\\n && rm -rf build\nRUN mkdir -p /usr/tvm/3rdparty/dmlc-core/build \\\n && cd /usr/tvm/3rdparty/dmlc-core/build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/dmlc_core_dist \\\n && make \\\n && make install\nRUN mkdir -p /usr/tvm/3rdparty/dlpack/build \\\n && cd /usr/tvm/3rdparty/dlpack/build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/dlpack_dist \\\n && make \\\n && make install\nFROM ubuntu:18.04 AS dldt\nARG DLDT_VERSION=\"2019_R1.1\"\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends python3-dev python3-pip python3-wheel python3-setuptools git wget sudo -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN mkdir neo \\\n && cd neo \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-gmmlib_18.4.1_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-core_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-opencl_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-opencl_19.04.12237_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-ocloc_19.04.12237_amd64.deb \\\n && sudo dpkg -i *.deb\nRUN python3 -m pip install cython\nRUN git clone https://github.com/opencv/dldt.git --recursive -b ${DLDT_VERSION} \\\n && cd dldt/inference-engine \\\n && bash install_dependencies.sh \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/* \\\n && mkdir build \\\n && cd build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/dldt_dist -DCMAKE_BUILD_TYPE=Release -DGEMM=OPENBLAS -DENABLE_PYTHON=ON \\\n && make -j4 \\\n && make install \\\n && cd .. \\\n && rm -rf build\nRUN cd dldt/model-optimizer \\\n && python3 -m pip install --user -r requirements_onnx.txt\nFROM nvidia/cuda:10.0-cudnn7-devel AS ci-base\nENV DEBIAN_FRONTEND=\"noninteractive\"\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends python3-dev python3-pip python3-wheel python3-setuptools git cmake libblas3 libblas-dev libopenblas-dev curl wget unzip sudo ninja-build libopencv-dev -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN echo deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-6.0 main >> /etc/apt/sources.list.d/llvm.list \\\n && wget -O - http://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - \\\n && apt-get update \\\n && apt-get install llvm-6.0 -y --force-yes \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nCOPY --from=ngraph /root/ngraph_dist /root/ngraph_dist\nCOPY --from=ngraph /root/.local /root/.local\nCOPY --from=tvm /root/tvm_dist /usr/local/\nCOPY --from=tvm /root/dmlc_core_dist /usr/local/\nCOPY --from=tvm /root/dlpack_dist /usr/local/\nCOPY --from=tvm /usr/tvm/include/tvm/runtime /usr/local/include/tvm/runtime\nRUN mkdir neo \\\n && cd neo \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-gmmlib_18.4.1_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-core_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-opencl_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-opencl_19.04.12237_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-ocloc_19.04.12237_amd64.deb \\\n && sudo dpkg -i *.deb\nCOPY --from=dldt /root/dldt_dist /usr/local/\nCOPY --from=dldt /dldt/inference-engine/include /root/dldt/inference-engine/include\nCOPY --from=dldt /dldt/inference-engine/bin/intel64/Release/lib /root/dldt/inference-engine/bin/intel64/Release/lib\nCOPY --from=dldt /root/.local /root/.local\nCOPY --from=dldt /dldt/model-optimizer /root/dldt/model-optimizer\nENV PYTHONPATH=\"/root/dldt/model-optimizer:${PYTHONPATH}\"\nRUN python3 -m pip install --user decorator attrs\nENV PYTHONPATH=\"/usr/tvm/python:/usr/tvm/topi/python:/usr/tvm/nnvm/python/:/usr/tvm/vta/python:${PYTHONPATH}\"\nENV PATH=\"/usr/local/nvidia/bin:/usr/local/cuda/bin:/root/.local/bin:${PATH}\"\nENV LD_LIBRARY_PATH=\"/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/root/ngraph_dist/lib:${LD_LIBRARY_PATH}\"\nFROM ci-base AS dev-base\nRUN git clone --recursive https://github.com/pfnet-research/chainer-compiler.git\nRUN python3 -m pip install --user gast\nRUN export CHAINER_VERSION=$( python3 -c \"import imp;print(imp.load_source('_version','chainer-compiler/third_party/chainer/chainer/_version.py').__version__)\" ;) \\\n && python3 -m pip install --user cupy-cuda100==$CHAINER_VERSION\nRUN CHAINER_BUILD_CHAINERX=1 CHAINERX_BUILD_CUDA=1 MAKEFLAGS=-j8 CHAINERX_NVCC_GENERATE_CODE=arch=compute_70,code=sm_70 python3 -m pip install --user chainer-compiler/third_party/chainer[test]\nRUN python3 -m pip install --user chainer-compiler/third_party/onnx-chainer[test-gpu]\nRUN mkdir -p chainer-compiler/build \\\n && cd chainer-compiler/build \\\n && cmake .. -DCHAINER_COMPILER_ENABLE_CUDA=ON -DCHAINER_COMPILER_ENABLE_CUDNN=ON -DCHAINER_COMPILER_ENABLE_OPENCV=ON -DCHAINER_COMPILER_ENABLE_PYTHON=ON -DCHAINER_COMPILER_NGRAPH_DIR=$HOME/ngraph_dist -DCHAINER_COMPILER_DLDT_DIR=$HOME/dldt -DPYTHON_EXECUTABLE=$( which python3 ;) -DCHAINER_COMPILER_ENABLE_TVM=ON -DCHAINERX_BUILD_CUDA=ON -DCHAINERX_BUILD_PYTHON=ON -DCHAINER_COMPILER_PREBUILT_CHAINERX_DIR=$( pip3 show chainer | awk '/^Location: / {print $2}' ;)/chainerx \\\n && make -j8\nFROM dev-base\nLABEL author=\"Daisuke Tanaka <duaipp@gmail.com>\"\n#  Optional packages.\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends less lv screen vim zsh -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n","injectedSmells":[],"originalDockerfileHash":"676b5a9bbd1ac5e739c74c9d449def23","successfullyInjectedSmells":[],"originalDockerfileUglified":"FROM nvidia/cuda:10.0-cudnn7-devel AS ngraph\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends build-essential cmake clang-3.9 git curl zlib1g zlib1g-dev libtinfo-dev unzip autoconf automake libtool python3-dev python3-pip python3-wheel python3-setuptools -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n#   nGraph build, referenced ngraph-onnx/BUILDING.md\n#   NOTE(disktnk): should use 'DPYTHON_EXECUTABLE' (currently not supported)\n#   NOTE(disktnk): failed with '-DNGRAPH_GPU_ENABLE=TRUE', stop using CUDA enabled\n#   NOTE(disktnk): cannot build python bind with multiprocess\nRUN ln -s /usr/bin/python3 /usr/bin/python\nARG NGRAPH_VERSION=\"0.19.0\"\nRUN git clone https://github.com/NervanaSystems/ngraph.git -b v${NGRAPH_VERSION} \\\n && mkdir ngraph/build \\\n && cd ngraph/build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/ngraph_dist -DNGRAPH_ONNX_IMPORT_ENABLE=TRUE -DNGRAPH_USE_PREBUILT_LLVM=TRUE -DNGRAPH_INTELGPU_ENABLE=TRUE -DNGRAPH_GPU_ENABLE=FALSE -DNGRAPH_UNIT_TEST_ENABLE=FALSE \\\n && make -j1 \\\n && make install \\\n && cd .. \\\n && rm -rf build\nRUN cd ngraph/python \\\n && sed -e \"s/^distutils.ccompiler.CCompiler.compile/# &/\" setup.py > setup_.py\nRUN cd ngraph/python \\\n && git clone --recursive https://github.com/jagerman/pybind11.git \\\n && export PYBIND_HEADERS_PATH=$PWD/pybind11 \\\n && export NGRAPH_CPP_BUILD_PATH=$HOME/ngraph_dist \\\n && export NGRAPH_ONNX_IMPORT_ENABLE=TRUE \\\n && python3 -m pip install --user numpy \\\n && python3 setup_.py bdist_wheel \\\n && python3 -m pip install --user -U dist/*.whl \\\n && rm -rf build\nARG NGRAPH_ONNX_VERSION=\"0.14.0\"\nRUN cd ngraph \\\n && git clone https://github.com/NervanaSystems/ngraph-onnx.git -b v${NGRAPH_ONNX_VERSION} \\\n && cd ngraph-onnx \\\n && python3 -m pip install --user -r requirements.txt \\\n && python3 -m pip install --user -r requirements_test.txt \\\n && python3 -m pip install --user -e .\nFROM nvidia/cuda:10.0-cudnn7-devel AS tvm\n#   TVM Build, referenced Dockerfile.demo_gpu\n#   NOTE(disktnk): official installer does not copy header file\nARG TVM_VERSION=\"0.5\"\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends wget -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN wget https://raw.githubusercontent.com/dmlc/tvm/v${TVM_VERSION}/docker/install/ubuntu_install_core.sh -P /install \\\n && bash /install/ubuntu_install_core.sh \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN echo deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-6.0 main >> /etc/apt/sources.list.d/llvm.list \\\n && wget -O - http://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - \\\n && apt-get update \\\n && apt-get install llvm-6.0 -y --force-yes \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n#   based https://raw.githubusercontent.com/dmlc/tvm/v${TVM_VERSION}/docker/install/install_tvm_gpu.sh\nRUN cd /usr \\\n && git clone https://github.com/dmlc/tvm --recursive -b v${TVM_VERSION} \\\n && cd /usr/tvm \\\n && echo set\nRUN mkdir -p /usr/tvm/3rdparty/dmlc-core/build \\\n && cd /usr/tvm/3rdparty/dmlc-core/build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/dmlc_core_dist \\\n && make \\\n && make install\nRUN mkdir -p /usr/tvm/3rdparty/dlpack/build \\\n && cd /usr/tvm/3rdparty/dlpack/build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/dlpack_dist \\\n && make \\\n && make install\nFROM ubuntu:18.04 AS dldt\nARG DLDT_VERSION=\"2019_R1.1\"\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends python3-dev python3-pip python3-wheel python3-setuptools git wget sudo -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN mkdir neo \\\n && cd neo \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-gmmlib_18.4.1_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-core_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-opencl_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-opencl_19.04.12237_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-ocloc_19.04.12237_amd64.deb \\\n && sudo dpkg -i *.deb\nRUN python3 -m pip install cython\nRUN git clone https://github.com/opencv/dldt.git --recursive -b ${DLDT_VERSION} \\\n && cd dldt/inference-engine \\\n && bash install_dependencies.sh \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/* \\\n && mkdir build \\\n && cd build \\\n && cmake .. -DCMAKE_INSTALL_PREFIX=$HOME/dldt_dist -DCMAKE_BUILD_TYPE=Release -DGEMM=OPENBLAS -DENABLE_PYTHON=ON \\\n && make -j4 \\\n && make install \\\n && cd .. \\\n && rm -rf build\nRUN cd dldt/model-optimizer \\\n && python3 -m pip install --user -r requirements_onnx.txt\nFROM nvidia/cuda:10.0-cudnn7-devel AS ci-base\nENV DEBIAN_FRONTEND=\"noninteractive\"\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends python3-dev python3-pip python3-wheel python3-setuptools git cmake libblas3 libblas-dev libopenblas-dev curl wget unzip sudo ninja-build libopencv-dev -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nRUN echo deb http://apt.llvm.org/xenial/ llvm-toolchain-xenial-6.0 main >> /etc/apt/sources.list.d/llvm.list \\\n && wget -O - http://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add - \\\n && apt-get update \\\n && apt-get install llvm-6.0 -y --force-yes \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\nCOPY --from=ngraph /root/ngraph_dist /root/ngraph_dist\nCOPY --from=ngraph /root/.local /root/.local\nCOPY --from=tvm /root/tvm_dist /usr/local/\nCOPY --from=tvm /root/dmlc_core_dist /usr/local/\nCOPY --from=tvm /root/dlpack_dist /usr/local/\nCOPY --from=tvm /usr/tvm/include/tvm/runtime /usr/local/include/tvm/runtime\nRUN mkdir neo \\\n && cd neo \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-gmmlib_18.4.1_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-core_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-igc-opencl_18.50.1270_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-opencl_19.04.12237_amd64.deb \\\n && wget https://github.com/intel/compute-runtime/releases/download/19.04.12237/intel-ocloc_19.04.12237_amd64.deb \\\n && sudo dpkg -i *.deb\nCOPY --from=dldt /root/dldt_dist /usr/local/\nCOPY --from=dldt /dldt/inference-engine/include /root/dldt/inference-engine/include\nCOPY --from=dldt /dldt/inference-engine/bin/intel64/Release/lib /root/dldt/inference-engine/bin/intel64/Release/lib\nCOPY --from=dldt /root/.local /root/.local\nCOPY --from=dldt /dldt/model-optimizer /root/dldt/model-optimizer\nENV PYTHONPATH=\"/root/dldt/model-optimizer:${PYTHONPATH}\"\nRUN python3 -m pip install --user decorator attrs\nENV PYTHONPATH=\"/usr/tvm/python:/usr/tvm/topi/python:/usr/tvm/nnvm/python/:/usr/tvm/vta/python:${PYTHONPATH}\"\nENV PATH=\"/usr/local/nvidia/bin:/usr/local/cuda/bin:/root/.local/bin:${PATH}\"\nENV LD_LIBRARY_PATH=\"/usr/local/cuda/lib64:/usr/local/nvidia/lib64:/root/ngraph_dist/lib:${LD_LIBRARY_PATH}\"\nFROM ci-base AS dev-base\nRUN git clone --recursive https://github.com/pfnet-research/chainer-compiler.git\nRUN python3 -m pip install --user gast\nRUN export CHAINER_VERSION=$( python3 -c \"import imp;print(imp.load_source('_version','chainer-compiler/third_party/chainer/chainer/_version.py').__version__)\" ;) \\\n && python3 -m pip install --user cupy-cuda100==$CHAINER_VERSION\nRUN CHAINER_BUILD_CHAINERX=1 CHAINERX_BUILD_CUDA=1 MAKEFLAGS=-j8 CHAINERX_NVCC_GENERATE_CODE=arch=compute_70,code=sm_70 python3 -m pip install --user chainer-compiler/third_party/chainer[test]\nRUN python3 -m pip install --user chainer-compiler/third_party/onnx-chainer[test-gpu]\nRUN mkdir -p chainer-compiler/build \\\n && cd chainer-compiler/build \\\n && cmake .. -DCHAINER_COMPILER_ENABLE_CUDA=ON -DCHAINER_COMPILER_ENABLE_CUDNN=ON -DCHAINER_COMPILER_ENABLE_OPENCV=ON -DCHAINER_COMPILER_ENABLE_PYTHON=ON -DCHAINER_COMPILER_NGRAPH_DIR=$HOME/ngraph_dist -DCHAINER_COMPILER_DLDT_DIR=$HOME/dldt -DPYTHON_EXECUTABLE=$( which python3 ;) -DCHAINER_COMPILER_ENABLE_TVM=ON -DCHAINERX_BUILD_CUDA=ON -DCHAINERX_BUILD_PYTHON=ON -DCHAINER_COMPILER_PREBUILT_CHAINERX_DIR=$( pip3 show chainer | awk '/^Location: / {print $2}' ;)/chainerx \\\n && make -j8\nFROM dev-base\nLABEL author=\"Daisuke Tanaka <duaipp@gmail.com>\"\n#   Optional packages.\nRUN apt-get update -y \\\n && apt-get install --no-install-recommends less lv screen vim zsh -y \\\n && rm -rf /var/lib/apt/lists/* /var/cache/apt/archives/*\n","originalDockerfileUglifiedHash":"33860358644d5a34dfbaccef6c5e625d","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/7aeeda214781ffe7101c37f826dc8fc1afcd3114.dockerfile"}