{"seed":1135289150,"processedDockerfileHash":"942f8c151a913436a75eef90ea0d3139","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-pip","have-a-healthcheck","have-a-user"],"processedDockerfile":"#   from https://github.com/BVLC/caffe/blob/master/docker/standalone/gpu/Dockerfile\nFROM nvidia/cuda:8.0-devel-ubuntu14.04\nMAINTAINER femianjc@miamioh.edu\n#   Handy instructions:\n#   Install nvidia-docker\n#      https://github.com/NVIDIA/nvidia-docker/wiki/Installation\n#\n#   I will ASSUME you are in the top level directory of this repo when you type this...\n#\n#   To build the image:\n#\n#      nvidia-docker build -t facades docker/gpu\n#\n#   To start the container:\n#\n#      sudo nvidia-docker run -it -v ${PWD}:/workspace facades\n#\nRUN apt-get update \\\n && apt-get install --no-install-recommends curl -y \\\n && rm -rf /var/lib/apt/lists/*\nENV CUDNN_VERSION=\"3.0.7\"\nLABEL com.nvidia.cudnn.version=\"${CUDNN_VERSION}\"\n#   cuDNN license: https://developer.nvidia.com/cudnn/license_agreement\nRUN CUDNN_DOWNLOAD_SUM=98679d5ec039acfd4d81b8bfdc6a6352d6439e921523ff9909d364e706275c2b \\\n && curl -fsSL http://developer.download.nvidia.com/compute/redist/cudnn/v3/cudnn-7.0-linux-x64-v3.0-prod.tgz -O \\\n && echo \"$CUDNN_DOWNLOAD_SUM cudnn-7.0-linux-x64-v3.0-prod.tgz\" | sha256sum -c --strict - \\\n && tar --no-same-owner -xzf cudnn-7.0-linux-x64-v3.0-prod.tgz -C /usr/local \\\n && rm cudnn-7.0-linux-x64-v3.0-prod.tgz \\\n && ldconfig\nRUN apt-get update \\\n && apt-get install --no-install-recommends build-essential cmake git wget libatlas-base-dev libboost-all-dev libgflags-dev libgoogle-glog-dev libhdf5-serial-dev libleveldb-dev liblmdb-dev libopencv-dev libprotobuf-dev libsnappy-dev protobuf-compiler python-dev python-numpy python-pip python-scipy vim coreutils -y \\\n && rm -rf /var/lib/apt/lists/*\n#   Used by the facade processing shell scripts in order to package up our results\nRUN apt-get update \\\n && apt-get install --no-install-recommends zip -y \\\n && rm -rf /var/lib/apt/lists/*\nENV CAFFE_ROOT=\"/opt/caffe\"\nWORKDIR $CAFFE_ROOT\nRUN python -m pip install -U pip\nRUN pip install scikit-learn==1.2.2 -U\nRUN pip install scikit-image==0.20.0 -U\n#   NOTE:  Do not install any python packages after building segnet!\n#          The risk of an incompatability is just too great.\n#          Segnet ends up compiling against the particular version of numpy/opencv that\n#          are present when it is build.\n#   NOTE: I _wanted_ to use the latest (or a leter) version of cudnn because I thought it could\n#         improve performance, but TomoSaemann's repo does not unclude the modifications needed\n#         to the Dropout layer that are needed for bayesian inference.\n#\n#         # ENV SEGNET_REPO=https://github.com/TimoSaemann/caffe-segnet-cudnn5\nENV SEGNET_REPO=\"https://github.com/alexgkendall/caffe-segnet\"\nRUN git clone --depth 1 ${SEGNET_REPO} .\nRUN for req in $( cat python/requirements.txt ;) pydot; do pip install $req ; done \\\n && mkdir build \\\n && cd build\n#   NOTE: I _could_ make a Makefile and usin the Dockerfile 'ADD' command instead\n#         of appendining to the example like this, but this seems to work.\nRUN cp Makefile.config.example Makefile.config\nRUN echo USE_CUDNN := 1 >> Makefile.config\nRUN echo WITH_PYTHON_LAYER := 1 >> Makefile.config\nRUN make -j\nRUN make -j python\nRUN make -j pycaffe\n#  NOTE: I am considering shipping a Jupyter interface to help guide people through\n#        the software, but for processing lot's of data I prefer bash\nRUN pip install jupyter==1.0.0 scipy==1.10.1\nENV PYCAFFE_ROOT=\"$CAFFE_ROOT/python\"\nENV PYTHONPATH=\"$PYCAFFE_ROOT:$PYTHONPATH\"\nENV PATH=\"$CAFFE_ROOT/build/tools:$PYCAFFE_ROOT:$PATH\"\nRUN echo \"$CAFFE_ROOT/build/lib\" >> /etc/ld.so.conf.d/caffe.conf \\\n && ldconfig\n#  NOTE: I am not sure that this line is necessary given the 'ldconfig' stuff above; I\n#        had an unrelated issue and added this just-in-case\nENV LD_LIBRARY_PATH=\"${CAFFE_ROOT}/build/lib:$LD_LIBRARY_PATH\"\n#   This is a voume used to hold the data\n#   Use -v /path/to/data:/data in order to provide your data\nVOLUME /data\nVOLUME /output\n#   I generate plots (often to files), and this does not work by default on systems without\n#   an X-server setup properly (such as docker images...) so I am setting it up to use Agg for plotting.\nENV MATPLOTLIBRC=\"${HOME}/.config/matplotlib\"\nRUN mkdir -p ${MATPLOTLIBRC}\nRUN echo backend: Agg > ${MATPLOTLIBRC}/matplotlibrc\n#   Expose some ports for http or ipynb\n#   EXPOSE 80\n#   EXPOSE 8888\nRUN apt-get update \\\n && apt-get install --no-install-recommends sudo curl git -y \\\n && curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash \\\n && sudo apt-get install git-lfs\n#   Add files to the container\nWORKDIR /opt\nRUN git clone https://github.com/jfemiani/facade-segmentation /opt/facades\nENV PYTHONPATH=\"/opt/facades:${PYTHONPATH}\"\nRUN ln -s /opt/facades/scripts/i12-inference/generate /usr/bin/i12-inference\nRUN ln -s /opt/facades/scripts/i12-inference/generate /usr/bin/inference\nVOLUME /workspace\nWORKDIR /workspace\nCMD /bin/bash\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"#  from https://github.com/BVLC/caffe/blob/master/docker/standalone/gpu/Dockerfile\nFROM nvidia/cuda:8.0-devel-ubuntu14.04\nMAINTAINER femianjc@miamioh.edu\n#  Handy instructions:\n#  Install nvidia-docker\n#     https://github.com/NVIDIA/nvidia-docker/wiki/Installation\n#\n#  I will ASSUME you are in the top level directory of this repo when you type this...\n#\n#  To build the image:\n#\n#     nvidia-docker build -t facades docker/gpu\n#\n#  To start the container:\n#\n#     sudo nvidia-docker run -it -v ${PWD}:/workspace facades\n#\nRUN apt-get update \\\n && apt-get install --no-install-recommends curl -y \\\n && rm -rf /var/lib/apt/lists/*\nENV CUDNN_VERSION=\"3.0.7\"\nLABEL com.nvidia.cudnn.version=\"${CUDNN_VERSION}\"\n#  cuDNN license: https://developer.nvidia.com/cudnn/license_agreement\nRUN CUDNN_DOWNLOAD_SUM=98679d5ec039acfd4d81b8bfdc6a6352d6439e921523ff9909d364e706275c2b \\\n && curl -fsSL http://developer.download.nvidia.com/compute/redist/cudnn/v3/cudnn-7.0-linux-x64-v3.0-prod.tgz -O \\\n && echo \"$CUDNN_DOWNLOAD_SUM cudnn-7.0-linux-x64-v3.0-prod.tgz\" | sha256sum -c --strict - \\\n && tar --no-same-owner -xzf cudnn-7.0-linux-x64-v3.0-prod.tgz -C /usr/local \\\n && rm cudnn-7.0-linux-x64-v3.0-prod.tgz \\\n && ldconfig\nRUN apt-get update \\\n && apt-get install --no-install-recommends build-essential cmake git wget libatlas-base-dev libboost-all-dev libgflags-dev libgoogle-glog-dev libhdf5-serial-dev libleveldb-dev liblmdb-dev libopencv-dev libprotobuf-dev libsnappy-dev protobuf-compiler python-dev python-numpy python-pip python-scipy vim coreutils -y \\\n && rm -rf /var/lib/apt/lists/*\n#  Used by the facade processing shell scripts in order to package up our results\nRUN apt-get update \\\n && apt-get install --no-install-recommends zip -y \\\n && rm -rf /var/lib/apt/lists/*\nENV CAFFE_ROOT=\"/opt/caffe\"\nWORKDIR $CAFFE_ROOT\nRUN python -m pip install -U pip\nRUN pip install scikit-learn -U\nRUN pip install scikit-image -U\n#  NOTE:  Do not install any python packages after building segnet!\n#         The risk of an incompatability is just too great.\n#         Segnet ends up compiling against the particular version of numpy/opencv that\n#         are present when it is build.\n#  NOTE: I _wanted_ to use the latest (or a leter) version of cudnn because I thought it could\n#        improve performance, but TomoSaemann's repo does not unclude the modifications needed\n#        to the Dropout layer that are needed for bayesian inference.\n#\n#        # ENV SEGNET_REPO=https://github.com/TimoSaemann/caffe-segnet-cudnn5\nENV SEGNET_REPO=\"https://github.com/alexgkendall/caffe-segnet\"\nRUN git clone --depth 1 ${SEGNET_REPO} .\nRUN for req in $( cat python/requirements.txt ;) pydot; do pip install $req ; done \\\n && mkdir build \\\n && cd build\n#  NOTE: I _could_ make a Makefile and usin the Dockerfile 'ADD' command instead\n#        of appendining to the example like this, but this seems to work.\nRUN cp Makefile.config.example Makefile.config\nRUN echo USE_CUDNN := 1 >> Makefile.config\nRUN echo WITH_PYTHON_LAYER := 1 >> Makefile.config\nRUN make -j\nRUN make -j python\nRUN make -j pycaffe\n# NOTE: I am considering shipping a Jupyter interface to help guide people through\n#       the software, but for processing lot's of data I prefer bash\nRUN pip install jupyter scipy\nENV PYCAFFE_ROOT=\"$CAFFE_ROOT/python\"\nENV PYTHONPATH=\"$PYCAFFE_ROOT:$PYTHONPATH\"\nENV PATH=\"$CAFFE_ROOT/build/tools:$PYCAFFE_ROOT:$PATH\"\nRUN echo \"$CAFFE_ROOT/build/lib\" >> /etc/ld.so.conf.d/caffe.conf \\\n && ldconfig\n# NOTE: I am not sure that this line is necessary given the 'ldconfig' stuff above; I\n#       had an unrelated issue and added this just-in-case\nENV LD_LIBRARY_PATH=\"${CAFFE_ROOT}/build/lib:$LD_LIBRARY_PATH\"\n#  This is a voume used to hold the data\n#  Use -v /path/to/data:/data in order to provide your data\nVOLUME /data\nVOLUME /output\n#  I generate plots (often to files), and this does not work by default on systems without\n#  an X-server setup properly (such as docker images...) so I am setting it up to use Agg for plotting.\nENV MATPLOTLIBRC=\"${HOME}/.config/matplotlib\"\nRUN mkdir -p ${MATPLOTLIBRC}\nRUN echo backend: Agg > ${MATPLOTLIBRC}/matplotlibrc\n#  Expose some ports for http or ipynb\n#  EXPOSE 80\n#  EXPOSE 8888\nRUN apt-get update \\\n && apt-get install sudo curl git -y \\\n && curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash \\\n && sudo apt-get install git-lfs\n#  Add files to the container\nWORKDIR /opt\nRUN git clone https://github.com/jfemiani/facade-segmentation /opt/facades\nENV PYTHONPATH=\"/opt/facades:${PYTHONPATH}\"\nRUN ln -s /opt/facades/scripts/i12-inference/generate /usr/bin/i12-inference\nRUN ln -s /opt/facades/scripts/i12-inference/generate /usr/bin/inference\nVOLUME /workspace\nWORKDIR /workspace\nCMD /bin/bash\n","injectedSmells":[],"originalDockerfileHash":"7690124d919b108e9d49787343ab233e","successfullyInjectedSmells":[],"originalDockerfileUglified":"#   from https://github.com/BVLC/caffe/blob/master/docker/standalone/gpu/Dockerfile\nFROM nvidia/cuda:8.0-devel-ubuntu14.04\nMAINTAINER femianjc@miamioh.edu\n#   Handy instructions:\n#   Install nvidia-docker\n#      https://github.com/NVIDIA/nvidia-docker/wiki/Installation\n#\n#   I will ASSUME you are in the top level directory of this repo when you type this...\n#\n#   To build the image:\n#\n#      nvidia-docker build -t facades docker/gpu\n#\n#   To start the container:\n#\n#      sudo nvidia-docker run -it -v ${PWD}:/workspace facades\n#\nRUN apt-get update \\\n && apt-get install --no-install-recommends curl -y \\\n && rm -rf /var/lib/apt/lists/*\nENV CUDNN_VERSION=\"3.0.7\"\nLABEL com.nvidia.cudnn.version=\"${CUDNN_VERSION}\"\n#   cuDNN license: https://developer.nvidia.com/cudnn/license_agreement\nRUN CUDNN_DOWNLOAD_SUM=98679d5ec039acfd4d81b8bfdc6a6352d6439e921523ff9909d364e706275c2b \\\n && curl -fsSL http://developer.download.nvidia.com/compute/redist/cudnn/v3/cudnn-7.0-linux-x64-v3.0-prod.tgz -O \\\n && echo \"$CUDNN_DOWNLOAD_SUM cudnn-7.0-linux-x64-v3.0-prod.tgz\" | sha256sum -c --strict - \\\n && tar --no-same-owner -xzf cudnn-7.0-linux-x64-v3.0-prod.tgz -C /usr/local \\\n && rm cudnn-7.0-linux-x64-v3.0-prod.tgz \\\n && ldconfig\nRUN apt-get update \\\n && apt-get install --no-install-recommends build-essential cmake git wget libatlas-base-dev libboost-all-dev libgflags-dev libgoogle-glog-dev libhdf5-serial-dev libleveldb-dev liblmdb-dev libopencv-dev libprotobuf-dev libsnappy-dev protobuf-compiler python-dev python-numpy python-pip python-scipy vim coreutils -y \\\n && rm -rf /var/lib/apt/lists/*\n#   Used by the facade processing shell scripts in order to package up our results\nRUN apt-get update \\\n && apt-get install --no-install-recommends zip -y \\\n && rm -rf /var/lib/apt/lists/*\nENV CAFFE_ROOT=\"/opt/caffe\"\nWORKDIR $CAFFE_ROOT\nRUN python -m pip install -U pip\nRUN pip install scikit-learn -U\nRUN pip install scikit-image -U\n#   NOTE:  Do not install any python packages after building segnet!\n#          The risk of an incompatability is just too great.\n#          Segnet ends up compiling against the particular version of numpy/opencv that\n#          are present when it is build.\n#   NOTE: I _wanted_ to use the latest (or a leter) version of cudnn because I thought it could\n#         improve performance, but TomoSaemann's repo does not unclude the modifications needed\n#         to the Dropout layer that are needed for bayesian inference.\n#\n#         # ENV SEGNET_REPO=https://github.com/TimoSaemann/caffe-segnet-cudnn5\nENV SEGNET_REPO=\"https://github.com/alexgkendall/caffe-segnet\"\nRUN git clone --depth 1 ${SEGNET_REPO} .\nRUN for req in $( cat python/requirements.txt ;) pydot; do pip install $req ; done \\\n && mkdir build \\\n && cd build\n#   NOTE: I _could_ make a Makefile and usin the Dockerfile 'ADD' command instead\n#         of appendining to the example like this, but this seems to work.\nRUN cp Makefile.config.example Makefile.config\nRUN echo USE_CUDNN := 1 >> Makefile.config\nRUN echo WITH_PYTHON_LAYER := 1 >> Makefile.config\nRUN make -j\nRUN make -j python\nRUN make -j pycaffe\n#  NOTE: I am considering shipping a Jupyter interface to help guide people through\n#        the software, but for processing lot's of data I prefer bash\nRUN pip install jupyter scipy\nENV PYCAFFE_ROOT=\"$CAFFE_ROOT/python\"\nENV PYTHONPATH=\"$PYCAFFE_ROOT:$PYTHONPATH\"\nENV PATH=\"$CAFFE_ROOT/build/tools:$PYCAFFE_ROOT:$PATH\"\nRUN echo \"$CAFFE_ROOT/build/lib\" >> /etc/ld.so.conf.d/caffe.conf \\\n && ldconfig\n#  NOTE: I am not sure that this line is necessary given the 'ldconfig' stuff above; I\n#        had an unrelated issue and added this just-in-case\nENV LD_LIBRARY_PATH=\"${CAFFE_ROOT}/build/lib:$LD_LIBRARY_PATH\"\n#   This is a voume used to hold the data\n#   Use -v /path/to/data:/data in order to provide your data\nVOLUME /data\nVOLUME /output\n#   I generate plots (often to files), and this does not work by default on systems without\n#   an X-server setup properly (such as docker images...) so I am setting it up to use Agg for plotting.\nENV MATPLOTLIBRC=\"${HOME}/.config/matplotlib\"\nRUN mkdir -p ${MATPLOTLIBRC}\nRUN echo backend: Agg > ${MATPLOTLIBRC}/matplotlibrc\n#   Expose some ports for http or ipynb\n#   EXPOSE 80\n#   EXPOSE 8888\nRUN apt-get update \\\n && apt-get install sudo curl git -y \\\n && curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash \\\n && sudo apt-get install git-lfs\n#   Add files to the container\nWORKDIR /opt\nRUN git clone https://github.com/jfemiani/facade-segmentation /opt/facades\nENV PYTHONPATH=\"/opt/facades:${PYTHONPATH}\"\nRUN ln -s /opt/facades/scripts/i12-inference/generate /usr/bin/i12-inference\nRUN ln -s /opt/facades/scripts/i12-inference/generate /usr/bin/inference\nVOLUME /workspace\nWORKDIR /workspace\nCMD /bin/bash\n","originalDockerfileUglifiedHash":"7530f3372be94e6b977fcba9340627b1","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/16020833c2e09530f6be112eec782e2f7243a221.dockerfile"}