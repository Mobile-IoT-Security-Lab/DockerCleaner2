{"seed":554785535,"processedDockerfileHash":"aa3ae594b7e814f211f58a74ea5282bf","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-pip","use-copy-instead-of-add","have-a-healthcheck","have-a-user"],"processedDockerfile":"FROM rocker/verse:3.5.3\nMAINTAINER Jim Harner <ejharner@gmail.com>\nENV JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\nARG pgversion=9.6\nARG hadoopversion=2.9.1\nARG sparkversion=2.4.3\nARG hiveversion=2.1.1\n#   Update machine and install \n#   RUN apt-get update && apt-get install -y --no-install-recommends apt-utils\nRUN apt-get update \\\n && apt-get install --no-install-recommends libicu-dev postgresql-client-${pgversion} -y \\\n && apt-get clean\n#  ###################\n#   JAVA\n#  ###################\nRUN echo \"deb http://http.debian.net/debian stretch-backports main\" > /etc/apt/sources.list.d/stretch-backports.list\nRUN apt-get update \\\n && apt-get install --no-install-recommends stretch-backports openjdk-8-jdk -y -t\n#   config Java within R for rJava installation\nRUN sudo R CMD javareconf\n#   Install Google Protocol Buffer\n#   ADD protobuf-2.5.0.tar.gz /tmp\n#   RUN cd /tmp/protobuf-2.5.0 && ./configure && make -j4 && make install && cd .. && rm -rf protobuf-*\n#  ###################\n#   HADOOP\n#  ###################\n#   Download and Install Hadoop and set Hadoop environment variable\nRUN cd /opt \\\n && wget --quiet http://archive.apache.org/dist/hadoop/core/hadoop-${hadoopversion}/hadoop-${hadoopversion}.tar.gz \\\n && tar zxf hadoop-${hadoopversion}.tar.gz \\\n && ln -s hadoop-${hadoopversion} hadoop \\\n && rm hadoop-${hadoopversion}.tar.gz \\\n && (cd /opt/hadoop ;ln -s share/hadoop/tools/lib/hadoop-streaming-${hadoopversion}.jar hadoop-streaming.jar ) \\\n && chown -R rstudio:rstudio /opt/hadoop\nENV HADOOP_CMD=\"/opt/hadoop/bin/hadoop\" \\\n    HADOOP_HOME=\"/opt/hadoop\" \\\n    HADOOP_BIN=\"/opt/hadoop/bin\" \\\n    HADOOP_CONF_DIR=\"/opt/hadoop/etc/hadoop\"\n#  ###################\n#   SPARK\n#  ###################\n#   Install Spark\nRUN cd /opt \\\n && wget --quiet http://archive.apache.org/dist/spark/spark-${sparkversion}/spark-${sparkversion}-bin-hadoop2.7.tgz \\\n && tar zxf spark-${sparkversion}-bin-hadoop2.7.tgz \\\n && mv spark-${sparkversion}-bin-hadoop2.7 spark \\\n && cp spark/conf/spark-env.sh.template spark/conf/spark-env.sh \\\n && echo \"export SPARK_DIST_CLASSPATH=/opt/postgresql-42.2.2.jar:$( /opt/hadoop/bin/hadoop classpath ;)\" >> spark/conf/spark-env.sh\n#  ###################\n#   HIVE\n#  ###################\nRUN cd /opt \\\n && wget --quiet http://archive.apache.org/dist/hive/hive-${hiveversion}/apache-hive-${hiveversion}-bin.tar.gz \\\n && tar zxf apache-hive-${hiveversion}-bin.tar.gz \\\n && ln -s apache-hive-${hiveversion}-bin hive \\\n && ln -s /opt/hive/jdbc/hive-jdbc-${hiveversion}-standalone.jar /opt/hive/lib/ \\\n && rm apache-hive-${hiveversion}-bin.tar.gz\n#  ###################\n#   R PACKAGES\n#  ###################\n#   Switch to rstudio CRAN mirror (untested)\n#   RUN R CMD options(repos = c(CRAN = \"https://cran.rstudio.com\"))\n#   Set environment variable for rJava package installation\nENV LD_LIBRARY_PATH=\"$JAVA_HOME/jre/lib/amd64:$JAVA_HOME/jre/lib/amd64/server\"\n#   Install R packages\nRUN Rscript -e \"install.packages(c(\\\"rjson\\\", \\\"RJSONIO\\\", \\\"jsonlite\\\", \\\"bit64\\\", \\\"bit\\\", \\\"functional\\\", \\\"R.methodsS3\\\", \\\"reshape2\\\", \\\"httr\\\", \\\"rvest\\\", \\\"datadr\\\", \\\"trelliscope\\\", \\\"DBI\\\", \\\"RPostgreSQL\\\", \\\"RJDBC\\\", \\\"dbplyr\\\", \\\"glmnet\\\", \\\"testthat\\\", \\\"roxygen2\\\", \\\"XML\\\", \\\"xml2\\\", \\\"housingData\\\", \\\"Lahman\\\", \\\"nycflights13\\\", \\\"flexdashboard\\\", \\\"sparklyr\\\"), repos = 'http://cran.rstudio.com')\"\n#   Copy repository packages to filesystem\nCOPY rjava.tar.gz rhdfs.tar.gz rmr.tar.gz /tmp/pkgs/\n#   Install repository packages\nRUN cd /tmp/pkgs \\\n && R CMD INSTALL rJava rmr2 rhdfs\nCOPY protobuf-2.5.0.tar.gz Rhipe_0.75.2_hadoop-2.tar.gz /tmp/\nRUN cd /tmp/protobuf-2.5.0 \\\n && ./configure --prefix=/usr \\\n && make \\\n && make install \\\n && cd .. \\\n && rm -rf protobuf-* \\\n && cd /tmp/Rhipe \\\n && R CMD INSTALL . \\\n && cd .. \\\n && rm -rf Rhipe\nCOPY postgresql-42.2.2.jar /opt\n#  ###################\n#   ENVIRONMENT CONFIG\n#  ###################\n#   Add necessary mods to Renviron file\nCOPY Renviron /usr/local/lib/R/etc/\nCOPY hdfs-site.xml core-site.xml log4j.properties /opt/hadoop/etc/hadoop/\n#   Create symlink to actual Rscript\nRUN ln -s /usr/local/bin/Rscript /usr/bin/Rscript\n#   Add path to profile so commands are found if attach to the container\nRUN echo \"PATH='/opt/hadoop/bin:/opt/spark/bin:/opt/hive/bin:$PATH'\" >> /etc/profile\n#   this is useless because it only sets it for the following commands in the Dockerfile\n#  ENV PATH /opt/hadoop/bin:/opt/spark/bin:/opt/hive/bin::$PATH\n#   Install Python3\n#   NOTE: python 3 uses the command 'python3'\nRUN easy_install pip \\\n && apt-get install --no-install-recommends python3 -y \\\n && pip install virtualenv==20.21.0\n#   Install TensorFlow Package\nRUN R -e \"install.packages(\\\"tensorflow\\\")\"\n#   USER rstudio\nCOPY rspark-tests /home/rstudio/\nRUN chown -R rstudio:rstudio /home/rstudio\n#   USER root\nEXPOSE 8787/tcp\n#   VOLUME /home/rstudio\nCMD [\"/init\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"FROM rocker/verse:3.5.3\nMAINTAINER Jim Harner <ejharner@gmail.com>\nENV JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\nARG pgversion=9.6\nARG hadoopversion=2.9.1\nARG sparkversion=2.4.3\nARG hiveversion=2.1.1\n#  Update machine and install \n#  RUN apt-get update && apt-get install -y --no-install-recommends apt-utils\nRUN apt-get update \\\n && apt-get install libicu-dev postgresql-client-${pgversion} -y \\\n && apt-get clean\n# ###################\n#  JAVA\n# ###################\nRUN echo \"deb http://http.debian.net/debian stretch-backports main\" > /etc/apt/sources.list.d/stretch-backports.list\nRUN apt-get update \\\n && apt-get install stretch-backports openjdk-8-jdk -y -t\n#  config Java within R for rJava installation\nRUN sudo R CMD javareconf\n#  Install Google Protocol Buffer\n#  ADD protobuf-2.5.0.tar.gz /tmp\n#  RUN cd /tmp/protobuf-2.5.0 && ./configure && make -j4 && make install && cd .. && rm -rf protobuf-*\n# ###################\n#  HADOOP\n# ###################\n#  Download and Install Hadoop and set Hadoop environment variable\nRUN cd /opt \\\n && wget --quiet http://archive.apache.org/dist/hadoop/core/hadoop-${hadoopversion}/hadoop-${hadoopversion}.tar.gz \\\n && tar zxf hadoop-${hadoopversion}.tar.gz \\\n && ln -s hadoop-${hadoopversion} hadoop \\\n && rm hadoop-${hadoopversion}.tar.gz \\\n && (cd /opt/hadoop ;ln -s share/hadoop/tools/lib/hadoop-streaming-${hadoopversion}.jar hadoop-streaming.jar ) \\\n && chown -R rstudio:rstudio /opt/hadoop\nENV HADOOP_CMD=\"/opt/hadoop/bin/hadoop\" \\\n    HADOOP_HOME=\"/opt/hadoop\" \\\n    HADOOP_BIN=\"/opt/hadoop/bin\" \\\n    HADOOP_CONF_DIR=\"/opt/hadoop/etc/hadoop\"\n# ###################\n#  SPARK\n# ###################\n#  Install Spark\nRUN cd /opt \\\n && wget --quiet http://archive.apache.org/dist/spark/spark-${sparkversion}/spark-${sparkversion}-bin-hadoop2.7.tgz \\\n && tar zxf spark-${sparkversion}-bin-hadoop2.7.tgz \\\n && mv spark-${sparkversion}-bin-hadoop2.7 spark \\\n && cp spark/conf/spark-env.sh.template spark/conf/spark-env.sh \\\n && echo \"export SPARK_DIST_CLASSPATH=/opt/postgresql-42.2.2.jar:$( /opt/hadoop/bin/hadoop classpath ;)\" >> spark/conf/spark-env.sh\n# ###################\n#  HIVE\n# ###################\nRUN cd /opt \\\n && wget --quiet http://archive.apache.org/dist/hive/hive-${hiveversion}/apache-hive-${hiveversion}-bin.tar.gz \\\n && tar zxf apache-hive-${hiveversion}-bin.tar.gz \\\n && ln -s apache-hive-${hiveversion}-bin hive \\\n && ln -s /opt/hive/jdbc/hive-jdbc-${hiveversion}-standalone.jar /opt/hive/lib/ \\\n && rm apache-hive-${hiveversion}-bin.tar.gz\n# ###################\n#  R PACKAGES\n# ###################\n#  Switch to rstudio CRAN mirror (untested)\n#  RUN R CMD options(repos = c(CRAN = \"https://cran.rstudio.com\"))\n#  Set environment variable for rJava package installation\nENV LD_LIBRARY_PATH=\"$JAVA_HOME/jre/lib/amd64:$JAVA_HOME/jre/lib/amd64/server\"\n#  Install R packages\nRUN Rscript -e \"install.packages(c(\\\"rjson\\\", \\\"RJSONIO\\\", \\\"jsonlite\\\", \\\"bit64\\\", \\\"bit\\\", \\\"functional\\\", \\\"R.methodsS3\\\", \\\"reshape2\\\", \\\"httr\\\", \\\"rvest\\\", \\\"datadr\\\", \\\"trelliscope\\\", \\\"DBI\\\", \\\"RPostgreSQL\\\", \\\"RJDBC\\\", \\\"dbplyr\\\", \\\"glmnet\\\", \\\"testthat\\\", \\\"roxygen2\\\", \\\"XML\\\", \\\"xml2\\\", \\\"housingData\\\", \\\"Lahman\\\", \\\"nycflights13\\\", \\\"flexdashboard\\\", \\\"sparklyr\\\"), repos = 'http://cran.rstudio.com')\"\n#  Copy repository packages to filesystem\nADD rjava.tar.gz rhdfs.tar.gz rmr.tar.gz /tmp/pkgs/\n#  Install repository packages\nRUN cd /tmp/pkgs \\\n && R CMD INSTALL rJava rmr2 rhdfs\nADD protobuf-2.5.0.tar.gz Rhipe_0.75.2_hadoop-2.tar.gz /tmp/\nRUN cd /tmp/protobuf-2.5.0 \\\n && ./configure --prefix=/usr \\\n && make \\\n && make install \\\n && cd .. \\\n && rm -rf protobuf-* \\\n && cd /tmp/Rhipe \\\n && R CMD INSTALL . \\\n && cd .. \\\n && rm -rf Rhipe\nADD postgresql-42.2.2.jar /opt\n# ###################\n#  ENVIRONMENT CONFIG\n# ###################\n#  Add necessary mods to Renviron file\nADD Renviron /usr/local/lib/R/etc/\nADD hdfs-site.xml core-site.xml log4j.properties /opt/hadoop/etc/hadoop/\n#  Create symlink to actual Rscript\nRUN ln -s /usr/local/bin/Rscript /usr/bin/Rscript\n#  Add path to profile so commands are found if attach to the container\nRUN echo \"PATH='/opt/hadoop/bin:/opt/spark/bin:/opt/hive/bin:$PATH'\" >> /etc/profile\n#  this is useless because it only sets it for the following commands in the Dockerfile\n# ENV PATH /opt/hadoop/bin:/opt/spark/bin:/opt/hive/bin::$PATH\n#  Install Python3\n#  NOTE: python 3 uses the command 'python3'\nRUN easy_install pip \\\n && apt-get install python3 -y \\\n && pip install virtualenv\n#  Install TensorFlow Package\nRUN R -e \"install.packages(\\\"tensorflow\\\")\"\n#  USER rstudio\nADD rspark-tests /home/rstudio/\nRUN chown -R rstudio:rstudio /home/rstudio\n#  USER root\nEXPOSE 8787/tcp\n#  VOLUME /home/rstudio\nCMD [\"/init\"]\n","injectedSmells":[],"originalDockerfileHash":"e381e8da665c47da7ac4de8721115aff","successfullyInjectedSmells":[],"originalDockerfileUglified":"FROM rocker/verse:3.5.3\nMAINTAINER Jim Harner <ejharner@gmail.com>\nENV JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\nARG pgversion=9.6\nARG hadoopversion=2.9.1\nARG sparkversion=2.4.3\nARG hiveversion=2.1.1\n#   Update machine and install \n#   RUN apt-get update && apt-get install -y --no-install-recommends apt-utils\nRUN apt-get update \\\n && apt-get install libicu-dev postgresql-client-${pgversion} -y \\\n && apt-get clean\n#  ###################\n#   JAVA\n#  ###################\nRUN echo \"deb http://http.debian.net/debian stretch-backports main\" > /etc/apt/sources.list.d/stretch-backports.list\nRUN apt-get update \\\n && apt-get install stretch-backports openjdk-8-jdk -y -t\n#   config Java within R for rJava installation\nRUN sudo R CMD javareconf\n#   Install Google Protocol Buffer\n#   ADD protobuf-2.5.0.tar.gz /tmp\n#   RUN cd /tmp/protobuf-2.5.0 && ./configure && make -j4 && make install && cd .. && rm -rf protobuf-*\n#  ###################\n#   HADOOP\n#  ###################\n#   Download and Install Hadoop and set Hadoop environment variable\nRUN cd /opt \\\n && wget --quiet http://archive.apache.org/dist/hadoop/core/hadoop-${hadoopversion}/hadoop-${hadoopversion}.tar.gz \\\n && tar zxf hadoop-${hadoopversion}.tar.gz \\\n && ln -s hadoop-${hadoopversion} hadoop \\\n && rm hadoop-${hadoopversion}.tar.gz \\\n && (cd /opt/hadoop ;ln -s share/hadoop/tools/lib/hadoop-streaming-${hadoopversion}.jar hadoop-streaming.jar ) \\\n && chown -R rstudio:rstudio /opt/hadoop\nENV HADOOP_CMD=\"/opt/hadoop/bin/hadoop\" \\\n    HADOOP_HOME=\"/opt/hadoop\" \\\n    HADOOP_BIN=\"/opt/hadoop/bin\" \\\n    HADOOP_CONF_DIR=\"/opt/hadoop/etc/hadoop\"\n#  ###################\n#   SPARK\n#  ###################\n#   Install Spark\nRUN cd /opt \\\n && wget --quiet http://archive.apache.org/dist/spark/spark-${sparkversion}/spark-${sparkversion}-bin-hadoop2.7.tgz \\\n && tar zxf spark-${sparkversion}-bin-hadoop2.7.tgz \\\n && mv spark-${sparkversion}-bin-hadoop2.7 spark \\\n && cp spark/conf/spark-env.sh.template spark/conf/spark-env.sh \\\n && echo \"export SPARK_DIST_CLASSPATH=/opt/postgresql-42.2.2.jar:$( /opt/hadoop/bin/hadoop classpath ;)\" >> spark/conf/spark-env.sh\n#  ###################\n#   HIVE\n#  ###################\nRUN cd /opt \\\n && wget --quiet http://archive.apache.org/dist/hive/hive-${hiveversion}/apache-hive-${hiveversion}-bin.tar.gz \\\n && tar zxf apache-hive-${hiveversion}-bin.tar.gz \\\n && ln -s apache-hive-${hiveversion}-bin hive \\\n && ln -s /opt/hive/jdbc/hive-jdbc-${hiveversion}-standalone.jar /opt/hive/lib/ \\\n && rm apache-hive-${hiveversion}-bin.tar.gz\n#  ###################\n#   R PACKAGES\n#  ###################\n#   Switch to rstudio CRAN mirror (untested)\n#   RUN R CMD options(repos = c(CRAN = \"https://cran.rstudio.com\"))\n#   Set environment variable for rJava package installation\nENV LD_LIBRARY_PATH=\"$JAVA_HOME/jre/lib/amd64:$JAVA_HOME/jre/lib/amd64/server\"\n#   Install R packages\nRUN Rscript -e \"install.packages(c(\\\"rjson\\\", \\\"RJSONIO\\\", \\\"jsonlite\\\", \\\"bit64\\\", \\\"bit\\\", \\\"functional\\\", \\\"R.methodsS3\\\", \\\"reshape2\\\", \\\"httr\\\", \\\"rvest\\\", \\\"datadr\\\", \\\"trelliscope\\\", \\\"DBI\\\", \\\"RPostgreSQL\\\", \\\"RJDBC\\\", \\\"dbplyr\\\", \\\"glmnet\\\", \\\"testthat\\\", \\\"roxygen2\\\", \\\"XML\\\", \\\"xml2\\\", \\\"housingData\\\", \\\"Lahman\\\", \\\"nycflights13\\\", \\\"flexdashboard\\\", \\\"sparklyr\\\"), repos = 'http://cran.rstudio.com')\"\n#   Copy repository packages to filesystem\nADD rjava.tar.gz rhdfs.tar.gz rmr.tar.gz /tmp/pkgs/\n#   Install repository packages\nRUN cd /tmp/pkgs \\\n && R CMD INSTALL rJava rmr2 rhdfs\nADD protobuf-2.5.0.tar.gz Rhipe_0.75.2_hadoop-2.tar.gz /tmp/\nRUN cd /tmp/protobuf-2.5.0 \\\n && ./configure --prefix=/usr \\\n && make \\\n && make install \\\n && cd .. \\\n && rm -rf protobuf-* \\\n && cd /tmp/Rhipe \\\n && R CMD INSTALL . \\\n && cd .. \\\n && rm -rf Rhipe\nADD postgresql-42.2.2.jar /opt\n#  ###################\n#   ENVIRONMENT CONFIG\n#  ###################\n#   Add necessary mods to Renviron file\nADD Renviron /usr/local/lib/R/etc/\nADD hdfs-site.xml core-site.xml log4j.properties /opt/hadoop/etc/hadoop/\n#   Create symlink to actual Rscript\nRUN ln -s /usr/local/bin/Rscript /usr/bin/Rscript\n#   Add path to profile so commands are found if attach to the container\nRUN echo \"PATH='/opt/hadoop/bin:/opt/spark/bin:/opt/hive/bin:$PATH'\" >> /etc/profile\n#   this is useless because it only sets it for the following commands in the Dockerfile\n#  ENV PATH /opt/hadoop/bin:/opt/spark/bin:/opt/hive/bin::$PATH\n#   Install Python3\n#   NOTE: python 3 uses the command 'python3'\nRUN easy_install pip \\\n && apt-get install python3 -y \\\n && pip install virtualenv\n#   Install TensorFlow Package\nRUN R -e \"install.packages(\\\"tensorflow\\\")\"\n#   USER rstudio\nADD rspark-tests /home/rstudio/\nRUN chown -R rstudio:rstudio /home/rstudio\n#   USER root\nEXPOSE 8787/tcp\n#   VOLUME /home/rstudio\nCMD [\"/init\"]\n","originalDockerfileUglifiedHash":"ed9f318d071876f50b2dad7a776b48f3","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/d79b5333649eb39bb14fe3f7b50862329b672e14.dockerfile"}