{"seed":2811822416,"processedDockerfileHash":"766c9cf274c12af7916ef100a58ec347","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["have-a-healthcheck","have-a-user"],"processedDockerfile":"FROM frolvlad/alpine-oraclejdk8:slim\n#   adapted from https://github.com/P7h/docker-spark/blob/master/Dockerfile\n#   Scala related variables.\nARG SCALA_VERSION=2.11.8\nARG SCALA_BINARY_ARCHIVE_NAME=scala-${SCALA_VERSION}\nARG SCALA_BINARY_DOWNLOAD_URL=https://downloads.lightbend.com/scala/${SCALA_VERSION}/${SCALA_BINARY_ARCHIVE_NAME}.tgz\n#   SBT related variables.\nARG SBT_VERSION=0.13.15\nARG SBT_BINARY_ARCHIVE_NAME=sbt-$SBT_VERSION\nARG SBT_BINARY_DOWNLOAD_URL=https://dl.bintray.com/sbt/native-packages/sbt/${SBT_VERSION}/${SBT_BINARY_ARCHIVE_NAME}.tgz\n#   Configure env variables for Scala, SBT and Spark.\n#   Also configure PATH env variable to include binary folders of Java, Scala, SBT and Spark.\nENV SCALA_HOME=\"/usr/local/scala\"\nENV SBT_HOME=\"/usr/local/sbt\"\nENV SPARK_HOME=\"/usr/local/spark\"\nENV PATH=\"$JAVA_HOME/bin:$SCALA_HOME/bin:$SBT_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH\"\n#   Download, uncompress and move all the required packages and libraries to their corresponding directories in /usr/local/ folder.\nRUN apk update \\\n && apk add build-base nodejs nodejs-npm lapack-dev python3-dev git bzip2 openssl gfortran curl bash \\\n && rm -rf /var/lib/apt/lists/* \\\n && rm -rf /tmp/* \\\n && wget -qO - ${SCALA_BINARY_DOWNLOAD_URL} | tar -xz -C /usr/local/ \\\n && wget -qO - ${SBT_BINARY_DOWNLOAD_URL} | tar -xz -C /usr/local/ \\\n && cd /usr/local/ \\\n && ln -s ${SCALA_BINARY_ARCHIVE_NAME} scala \\\n && packages=' numpy scipy simplejson ' \\\n && pip3 install $packages\n#      cp spark/conf/log4j.properties.template spark/conf/log4j.properties && \\\n#      sed -i -e s/WARN/ERROR/g spark/conf/log4j.properties && \\\n#      sed -i -e s/INFO/ERROR/g spark/conf/log4j.properties \\\n#   HADOOP\nENV HADOOP_VERSION=\"2.7.3\"\nENV HADOOP_HOME=\"/usr/hadoop-$HADOOP_VERSION\"\nENV HADOOP_CONF_DIR=\"$HADOOP_HOME/etc/hadoop\"\nENV PATH=\"$PATH:$HADOOP_HOME/bin\"\nRUN curl -sL --retry 3 \"http://archive.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz\" | gunzip | tar -x -C /usr/ \\\n && rm -rf $HADOOP_HOME/share/doc \\\n && chown -R root:root $HADOOP_HOME\n#   SPARK\nENV SPARK_VERSION=\"2.1.0\"\nENV SPARK_PACKAGE=\"spark-${SPARK_VERSION}-bin-without-hadoop\"\nENV SPARK_HOME=\"/usr/spark-${SPARK_VERSION}\"\nENV SPARK_DIST_CLASSPATH=\"$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*\"\nENV PATH=\"$PATH:${SPARK_HOME}/bin\"\nRUN curl -sL --retry 3 \"http://d3kbcqa49mib13.cloudfront.net/${SPARK_PACKAGE}.tgz\" | gunzip | tar x -C /usr/ \\\n && mv /usr/$SPARK_PACKAGE $SPARK_HOME \\\n && chown -R root:root $SPARK_HOME\n#   Zeppelin\nENV ZEPPELIN_PORT=\"8080\"\nENV ZEPPELIN_HOME=\"/usr/zeppelin\"\nENV ZEPPELIN_CONF_DIR=\"$ZEPPELIN_HOME/conf\"\nENV ZEPPELIN_NOTEBOOK_DIR=\"$ZEPPELIN_HOME/notebook\"\nRUN echo '{ \"allow_root\": true }' > /root/.bowerrc\nRUN set -ex \\\n && curl -sL http://archive.apache.org/dist/maven/maven-3/3.5.0/binaries/apache-maven-3.5.0-bin.tar.gz | gunzip | tar x -C /tmp/\nRUN git clone https://github.com/ShamsUlAzeem/zeppelin.git /usr/src/zeppelin\nRUN cd /usr/src/zeppelin \\\n && git init \\\n && git fetch \\\n && git checkout 'ipynb-export/import'\nRUN cd /usr/src/zeppelin \\\n && MAVEN_OPTS=\"-Xmx2g -XX:MaxPermSize=1024m\" /tmp/apache-maven-3.5.0/bin/mvn package -Pbuild-distr -DskipTests -Pspark-1.6 \\\n && tar xvf /usr/src/zeppelin/zeppelin-distribution/target/zeppelin*.tar.gz -C /usr/ \\\n && mv /usr/zeppelin* $ZEPPELIN_HOME \\\n && mkdir -p $ZEPPELIN_HOME/logs \\\n && mkdir -p $ZEPPELIN_HOME/run \\\n && rm -rf /var/lib/apt/lists/* \\\n && rm -rf /usr/src/zeppelin \\\n && rm -rf /root/.m2 \\\n && rm -rf /root/.npm \\\n && find /tmp -maxdepth 1 -not -name 'apache-maven-3.5.0' -not -name \".\" -exec rm -rf {}\nRUN ln -s -f /usr/bin/pip3 /usr/bin/pip \\\n && ln -s -f /usr/bin/python3 /usr/bin/python\n#   moves all additional zeppelin files to their respective locations\n#   remaining files are notebooks, we move those once everything else is gone\nRUN mkdir -p $ZEPPELIN_HOME/otherpoms \\\n && mkdir -p $ZEPPELIN_HOME/conf \\\n && mkdir -p $ZEPPELIN_HOME/dockerfiles\nCOPY . $ZEPPELIN_HOME/dockerfiles/.\n#   switch lines if building for cuda or cpu\nRUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-native_spark_2.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n#  RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-native_spark_1.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n#  RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-cuda-8.0_spark_2.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n#  RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-cuda-8.0_spark_1.xml $ZEPPELIN_HOME/otherpoms/pom.xml\nRUN ls $ZEPPELIN_HOME/bin/ \\\n && cp -a $ZEPPELIN_HOME/dockerfiles/docker/conf/. $ZEPPELIN_HOME/conf/ \\\n && cp -a $ZEPPELIN_HOME/dockerfiles/. $ZEPPELIN_HOME/notebook_json \\\n && rm -rf $ZEPPELIN_HOME/notebook_json/docker/ \\\n && find $ZEPPELIN_HOME/notebook_json/ -type f -not -name '*.json' -delete \\\n && dos2unix $ZEPPELIN_HOME/conf/zeppelin-env.sh \\\n && dos2unix $ZEPPELIN_HOME/bin/zeppelin.sh \\\n && cd $ZEPPELIN_HOME \\\n && mv $ZEPPELIN_HOME/dockerfiles/docker/json-folder-ids.py $ZEPPELIN_HOME \\\n && python json-folder-ids.py \\\n && cd $ZEPPELIN_HOME/otherpoms \\\n && /tmp/apache-maven-3.5.0/bin/mvn package \\\n && rm -rf $ZEPPELIN_HOME/dockerfiles/\nEXPOSE 8080/tcp 4040/tcp\nWORKDIR $ZEPPELIN_HOME\nCMD [\"/bin/bash\", \"bin/zeppelin.sh\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"FROM frolvlad/alpine-oraclejdk8:slim\n#  adapted from https://github.com/P7h/docker-spark/blob/master/Dockerfile\n#  Scala related variables.\nARG SCALA_VERSION=2.11.8\nARG SCALA_BINARY_ARCHIVE_NAME=scala-${SCALA_VERSION}\nARG SCALA_BINARY_DOWNLOAD_URL=https://downloads.lightbend.com/scala/${SCALA_VERSION}/${SCALA_BINARY_ARCHIVE_NAME}.tgz\n#  SBT related variables.\nARG SBT_VERSION=0.13.15\nARG SBT_BINARY_ARCHIVE_NAME=sbt-$SBT_VERSION\nARG SBT_BINARY_DOWNLOAD_URL=https://dl.bintray.com/sbt/native-packages/sbt/${SBT_VERSION}/${SBT_BINARY_ARCHIVE_NAME}.tgz\n#  Configure env variables for Scala, SBT and Spark.\n#  Also configure PATH env variable to include binary folders of Java, Scala, SBT and Spark.\nENV SCALA_HOME=\"/usr/local/scala\"\nENV SBT_HOME=\"/usr/local/sbt\"\nENV SPARK_HOME=\"/usr/local/spark\"\nENV PATH=\"$JAVA_HOME/bin:$SCALA_HOME/bin:$SBT_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH\"\n#  Download, uncompress and move all the required packages and libraries to their corresponding directories in /usr/local/ folder.\nRUN apk update \\\n && apk add build-base nodejs nodejs-npm lapack-dev python3-dev git bzip2 openssl gfortran curl bash \\\n && rm -rf /var/lib/apt/lists/* \\\n && rm -rf /tmp/* \\\n && wget -qO - ${SCALA_BINARY_DOWNLOAD_URL} | tar -xz -C /usr/local/ \\\n && wget -qO - ${SBT_BINARY_DOWNLOAD_URL} | tar -xz -C /usr/local/ \\\n && cd /usr/local/ \\\n && ln -s ${SCALA_BINARY_ARCHIVE_NAME} scala \\\n && packages=' numpy scipy simplejson ' \\\n && pip3 install $packages\n#     cp spark/conf/log4j.properties.template spark/conf/log4j.properties && \\\n#     sed -i -e s/WARN/ERROR/g spark/conf/log4j.properties && \\\n#     sed -i -e s/INFO/ERROR/g spark/conf/log4j.properties \\\n#  HADOOP\nENV HADOOP_VERSION=\"2.7.3\"\nENV HADOOP_HOME=\"/usr/hadoop-$HADOOP_VERSION\"\nENV HADOOP_CONF_DIR=\"$HADOOP_HOME/etc/hadoop\"\nENV PATH=\"$PATH:$HADOOP_HOME/bin\"\nRUN curl -sL --retry 3 \"http://archive.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz\" | gunzip | tar -x -C /usr/ \\\n && rm -rf $HADOOP_HOME/share/doc \\\n && chown -R root:root $HADOOP_HOME\n#  SPARK\nENV SPARK_VERSION=\"2.1.0\"\nENV SPARK_PACKAGE=\"spark-${SPARK_VERSION}-bin-without-hadoop\"\nENV SPARK_HOME=\"/usr/spark-${SPARK_VERSION}\"\nENV SPARK_DIST_CLASSPATH=\"$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*\"\nENV PATH=\"$PATH:${SPARK_HOME}/bin\"\nRUN curl -sL --retry 3 \"http://d3kbcqa49mib13.cloudfront.net/${SPARK_PACKAGE}.tgz\" | gunzip | tar x -C /usr/ \\\n && mv /usr/$SPARK_PACKAGE $SPARK_HOME \\\n && chown -R root:root $SPARK_HOME\n#  Zeppelin\nENV ZEPPELIN_PORT=\"8080\"\nENV ZEPPELIN_HOME=\"/usr/zeppelin\"\nENV ZEPPELIN_CONF_DIR=\"$ZEPPELIN_HOME/conf\"\nENV ZEPPELIN_NOTEBOOK_DIR=\"$ZEPPELIN_HOME/notebook\"\nRUN echo '{ \"allow_root\": true }' > /root/.bowerrc\nRUN set -ex \\\n && curl -sL http://archive.apache.org/dist/maven/maven-3/3.5.0/binaries/apache-maven-3.5.0-bin.tar.gz | gunzip | tar x -C /tmp/\nRUN git clone https://github.com/ShamsUlAzeem/zeppelin.git /usr/src/zeppelin\nRUN cd /usr/src/zeppelin \\\n && git init \\\n && git fetch \\\n && git checkout 'ipynb-export/import'\nRUN cd /usr/src/zeppelin \\\n && MAVEN_OPTS=\"-Xmx2g -XX:MaxPermSize=1024m\" /tmp/apache-maven-3.5.0/bin/mvn package -Pbuild-distr -DskipTests -Pspark-1.6 \\\n && tar xvf /usr/src/zeppelin/zeppelin-distribution/target/zeppelin*.tar.gz -C /usr/ \\\n && mv /usr/zeppelin* $ZEPPELIN_HOME \\\n && mkdir -p $ZEPPELIN_HOME/logs \\\n && mkdir -p $ZEPPELIN_HOME/run \\\n && rm -rf /var/lib/apt/lists/* \\\n && rm -rf /usr/src/zeppelin \\\n && rm -rf /root/.m2 \\\n && rm -rf /root/.npm \\\n && find /tmp -maxdepth 1 -not -name 'apache-maven-3.5.0' -not -name \".\" -exec rm -rf {} ; \\\n && find $ZEPPELIN_HOME/interpreter -maxdepth 1 -type d -not -name 'spark' -not -name 'md' -not -name \".\" -exec rm -rf {} ;\nRUN ln -s -f /usr/bin/pip3 /usr/bin/pip \\\n && ln -s -f /usr/bin/python3 /usr/bin/python\n#  moves all additional zeppelin files to their respective locations\n#  remaining files are notebooks, we move those once everything else is gone\nRUN mkdir -p $ZEPPELIN_HOME/otherpoms \\\n && mkdir -p $ZEPPELIN_HOME/conf \\\n && mkdir -p $ZEPPELIN_HOME/dockerfiles\nCOPY . $ZEPPELIN_HOME/dockerfiles/.\n#  switch lines if building for cuda or cpu\nRUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-native_spark_2.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n# RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-native_spark_1.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n# RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-cuda-8.0_spark_2.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n# RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-cuda-8.0_spark_1.xml $ZEPPELIN_HOME/otherpoms/pom.xml\nRUN ls $ZEPPELIN_HOME/bin/ \\\n && cp -a $ZEPPELIN_HOME/dockerfiles/docker/conf/. $ZEPPELIN_HOME/conf/ \\\n && cp -a $ZEPPELIN_HOME/dockerfiles/. $ZEPPELIN_HOME/notebook_json \\\n && rm -rf $ZEPPELIN_HOME/notebook_json/docker/ \\\n && find $ZEPPELIN_HOME/notebook_json/ -type f -not -name '*.json' -delete \\\n && dos2unix $ZEPPELIN_HOME/conf/zeppelin-env.sh \\\n && dos2unix $ZEPPELIN_HOME/bin/zeppelin.sh \\\n && cd $ZEPPELIN_HOME \\\n && mv $ZEPPELIN_HOME/dockerfiles/docker/json-folder-ids.py $ZEPPELIN_HOME \\\n && python json-folder-ids.py \\\n && cd $ZEPPELIN_HOME/otherpoms \\\n && /tmp/apache-maven-3.5.0/bin/mvn package \\\n && rm -rf $ZEPPELIN_HOME/dockerfiles/\nEXPOSE 8080/tcp 4040/tcp\nWORKDIR $ZEPPELIN_HOME\nCMD [\"/bin/bash\", \"bin/zeppelin.sh\"]\n","injectedSmells":[],"originalDockerfileHash":"70747697cd64b470186f79a6a7990150","successfullyInjectedSmells":[],"originalDockerfileUglified":"FROM frolvlad/alpine-oraclejdk8:slim\n#   adapted from https://github.com/P7h/docker-spark/blob/master/Dockerfile\n#   Scala related variables.\nARG SCALA_VERSION=2.11.8\nARG SCALA_BINARY_ARCHIVE_NAME=scala-${SCALA_VERSION}\nARG SCALA_BINARY_DOWNLOAD_URL=https://downloads.lightbend.com/scala/${SCALA_VERSION}/${SCALA_BINARY_ARCHIVE_NAME}.tgz\n#   SBT related variables.\nARG SBT_VERSION=0.13.15\nARG SBT_BINARY_ARCHIVE_NAME=sbt-$SBT_VERSION\nARG SBT_BINARY_DOWNLOAD_URL=https://dl.bintray.com/sbt/native-packages/sbt/${SBT_VERSION}/${SBT_BINARY_ARCHIVE_NAME}.tgz\n#   Configure env variables for Scala, SBT and Spark.\n#   Also configure PATH env variable to include binary folders of Java, Scala, SBT and Spark.\nENV SCALA_HOME=\"/usr/local/scala\"\nENV SBT_HOME=\"/usr/local/sbt\"\nENV SPARK_HOME=\"/usr/local/spark\"\nENV PATH=\"$JAVA_HOME/bin:$SCALA_HOME/bin:$SBT_HOME/bin:$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH\"\n#   Download, uncompress and move all the required packages and libraries to their corresponding directories in /usr/local/ folder.\nRUN apk update \\\n && apk add build-base nodejs nodejs-npm lapack-dev python3-dev git bzip2 openssl gfortran curl bash \\\n && rm -rf /var/lib/apt/lists/* \\\n && rm -rf /tmp/* \\\n && wget -qO - ${SCALA_BINARY_DOWNLOAD_URL} | tar -xz -C /usr/local/ \\\n && wget -qO - ${SBT_BINARY_DOWNLOAD_URL} | tar -xz -C /usr/local/ \\\n && cd /usr/local/ \\\n && ln -s ${SCALA_BINARY_ARCHIVE_NAME} scala \\\n && packages=' numpy scipy simplejson ' \\\n && pip3 install $packages\n#      cp spark/conf/log4j.properties.template spark/conf/log4j.properties && \\\n#      sed -i -e s/WARN/ERROR/g spark/conf/log4j.properties && \\\n#      sed -i -e s/INFO/ERROR/g spark/conf/log4j.properties \\\n#   HADOOP\nENV HADOOP_VERSION=\"2.7.3\"\nENV HADOOP_HOME=\"/usr/hadoop-$HADOOP_VERSION\"\nENV HADOOP_CONF_DIR=\"$HADOOP_HOME/etc/hadoop\"\nENV PATH=\"$PATH:$HADOOP_HOME/bin\"\nRUN curl -sL --retry 3 \"http://archive.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz\" | gunzip | tar -x -C /usr/ \\\n && rm -rf $HADOOP_HOME/share/doc \\\n && chown -R root:root $HADOOP_HOME\n#   SPARK\nENV SPARK_VERSION=\"2.1.0\"\nENV SPARK_PACKAGE=\"spark-${SPARK_VERSION}-bin-without-hadoop\"\nENV SPARK_HOME=\"/usr/spark-${SPARK_VERSION}\"\nENV SPARK_DIST_CLASSPATH=\"$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*\"\nENV PATH=\"$PATH:${SPARK_HOME}/bin\"\nRUN curl -sL --retry 3 \"http://d3kbcqa49mib13.cloudfront.net/${SPARK_PACKAGE}.tgz\" | gunzip | tar x -C /usr/ \\\n && mv /usr/$SPARK_PACKAGE $SPARK_HOME \\\n && chown -R root:root $SPARK_HOME\n#   Zeppelin\nENV ZEPPELIN_PORT=\"8080\"\nENV ZEPPELIN_HOME=\"/usr/zeppelin\"\nENV ZEPPELIN_CONF_DIR=\"$ZEPPELIN_HOME/conf\"\nENV ZEPPELIN_NOTEBOOK_DIR=\"$ZEPPELIN_HOME/notebook\"\nRUN echo '{ \"allow_root\": true }' > /root/.bowerrc\nRUN set -ex \\\n && curl -sL http://archive.apache.org/dist/maven/maven-3/3.5.0/binaries/apache-maven-3.5.0-bin.tar.gz | gunzip | tar x -C /tmp/\nRUN git clone https://github.com/ShamsUlAzeem/zeppelin.git /usr/src/zeppelin\nRUN cd /usr/src/zeppelin \\\n && git init \\\n && git fetch \\\n && git checkout 'ipynb-export/import'\nRUN cd /usr/src/zeppelin \\\n && MAVEN_OPTS=\"-Xmx2g -XX:MaxPermSize=1024m\" /tmp/apache-maven-3.5.0/bin/mvn package -Pbuild-distr -DskipTests -Pspark-1.6 \\\n && tar xvf /usr/src/zeppelin/zeppelin-distribution/target/zeppelin*.tar.gz -C /usr/ \\\n && mv /usr/zeppelin* $ZEPPELIN_HOME \\\n && mkdir -p $ZEPPELIN_HOME/logs \\\n && mkdir -p $ZEPPELIN_HOME/run \\\n && rm -rf /var/lib/apt/lists/* \\\n && rm -rf /usr/src/zeppelin \\\n && rm -rf /root/.m2 \\\n && rm -rf /root/.npm \\\n && find /tmp -maxdepth 1 -not -name 'apache-maven-3.5.0' -not -name \".\" -exec rm -rf {}\nRUN ln -s -f /usr/bin/pip3 /usr/bin/pip \\\n && ln -s -f /usr/bin/python3 /usr/bin/python\n#   moves all additional zeppelin files to their respective locations\n#   remaining files are notebooks, we move those once everything else is gone\nRUN mkdir -p $ZEPPELIN_HOME/otherpoms \\\n && mkdir -p $ZEPPELIN_HOME/conf \\\n && mkdir -p $ZEPPELIN_HOME/dockerfiles\nCOPY . $ZEPPELIN_HOME/dockerfiles/.\n#   switch lines if building for cuda or cpu\nRUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-native_spark_2.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n#  RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-native_spark_1.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n#  RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-cuda-8.0_spark_2.xml $ZEPPELIN_HOME/otherpoms/pom.xml\n#  RUN mv $ZEPPELIN_HOME/dockerfiles/docker/pom-cuda-8.0_spark_1.xml $ZEPPELIN_HOME/otherpoms/pom.xml\nRUN ls $ZEPPELIN_HOME/bin/ \\\n && cp -a $ZEPPELIN_HOME/dockerfiles/docker/conf/. $ZEPPELIN_HOME/conf/ \\\n && cp -a $ZEPPELIN_HOME/dockerfiles/. $ZEPPELIN_HOME/notebook_json \\\n && rm -rf $ZEPPELIN_HOME/notebook_json/docker/ \\\n && find $ZEPPELIN_HOME/notebook_json/ -type f -not -name '*.json' -delete \\\n && dos2unix $ZEPPELIN_HOME/conf/zeppelin-env.sh \\\n && dos2unix $ZEPPELIN_HOME/bin/zeppelin.sh \\\n && cd $ZEPPELIN_HOME \\\n && mv $ZEPPELIN_HOME/dockerfiles/docker/json-folder-ids.py $ZEPPELIN_HOME \\\n && python json-folder-ids.py \\\n && cd $ZEPPELIN_HOME/otherpoms \\\n && /tmp/apache-maven-3.5.0/bin/mvn package \\\n && rm -rf $ZEPPELIN_HOME/dockerfiles/\nEXPOSE 8080/tcp 4040/tcp\nWORKDIR $ZEPPELIN_HOME\nCMD [\"/bin/bash\", \"bin/zeppelin.sh\"]\n","originalDockerfileUglifiedHash":"ac85bef84274c55873ba7494fc309fb7","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/a59cb28bd22e832a66110ce96227c4dcb351450d.dockerfile"}