{"seed":702587595,"processedDockerfileHash":"c626e73c7948a9533e7f471b1f134147","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-apt-get","have-a-healthcheck","have-a-user"],"processedDockerfile":"#   Dockerfile for building general development\n#   environment for Data Science Analytics\n#   customized for TVB Big Data Team\nFROM ubuntu:16.04\nLABEL maintainer=\"\\\"michaelchan_wahyan@yahoo.com.hk\\\"\"\nENV SHELL=\"/bin/bash\" \\\n    TZ=\"Asia/Hong_Kong\" \\\n    PYTHONIOENCODING=\"UTF-8\" \\\n    AIRFLOW_HOME=\"/opt/airflow\" \\\n    AIRFLOW_GPL_UNIDECODE=\"yes\" \\\n    CLOUD_SDK_REPO=\"cloud-sdk-xenial\" \\\n    HADOOP_COMMON_HOME=\"/hadoop-2.7.7\" \\\n    HADOOP_HDFS_HOME=\"/hadoop-2.7.7\" \\\n    HADOOP_HOME=\"/hadoop-2.7.7\" \\\n    HADOOP_CONF_DIR=\"/hadoop-2.7.7/etc/hadoop\" \\\n    HADOOP_COMMON_LIB_NATIVE_DIR=\"/hadoop-2.7.7/lib/native\" \\\n    HADOOP_INSTALL=\"/hadoop-2.7.7\" \\\n    HADOOP_MAPRED_HOME=\"/hadoop-2.7.7\" \\\n    JAVA_HOME=\"/jdk1.8.0_171\" \\\n    PYSPARK_DRIVER_PYTHON=\"jupyter\" \\\n    PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" \\\n    PYSPARK_PYTHON=\"python3\" \\\n    SPARK_HOME=\"/spark-2.4.0-bin-hadoop2.7\" \\\n    SPARK_PATH=\"/spark-2.4.0-bin-hadoop2.7\" \\\n    YARN_HOME=\"/hadoop-2.7.7\" \\\n    PATH=\"$PATH:/root/anaconda/bin:/bin:/usr/local/sbin:/usr/local/bin:/usr/local/lib:/usr/lib:/usr/sbin:/usr/bin:/sbin:/bin:/hadoop-2.7.7/sbin:/hadoop-2.7.7/bin\"\n#   ========================\n#   Jupyter Lab installation\n#   ========================\n#   ref : https://github.com/mikebirdgeneau/jupyterlab-docker/blob/master/jupyterlab/Dockerfile\n#   for pip3 installation on jupyterlab related packages :\n#   ipywidgets   nbextension   jupyterlab\n#   ==================\n#   SPARK installation\n#   ==================\n#   ref : https://medium.com/@GalarnykMichael/install-spark-on-ubuntu-pyspark-231c45677de0\n#   SPARK installation - Part 1 (conda)\n#   SPARK installation - Part 2 (spark)\n#   SPARK installation - Part 3 (jdk 8.171)\n#   SPARK installation - Part 4 (hadoop 2.7.6)\n#   =============================\n#   Google Cloud SDK installation\n#   =============================\n#   ref : https://cloud.google.com/sdk/docs/quickstart-debian-ubuntu\n#      many more gcloud packages that could be installed\n#      google-cloud-sdk-app-engine-python\n#      google-cloud-sdk-app-engine-python-extras\n#      google-cloud-sdk-app-engine-java\n#      google-cloud-sdk-app-engine-go\n#      google-cloud-sdk-datalab\n#      google-cloud-sdk-datastore-emulator\n#      google-cloud-sdk-pubsub-emulator\n#      google-cloud-sdk-cbt\n#      google-cloud-sdk-bigtable-emulator\n#      kubectl\nCOPY jdk-8u171-linux-x64.tar.gz /\nRUN apt-get update -y ; apt-get -y upgrade ; apt-get install --no-install-recommends screen=4.3.1-2ubuntu0.1 apt-utils=1.2.35 cmake=3.5.1-1ubuntu3 htop=2.0.1-1ubuntu1 wget=1.17.1-1ubuntu1.5 vim=2:7.4.1689-3ubuntu1.5 nano=2.5.3-2ubuntu2 curl=7.47.0-1ubuntu2.19 git=1:2.7.4-0ubuntu1.10 software-properties-common=0.96.20.10 apt-transport-https=1.2.35 net-tools=1.60-26ubuntu1 wget=1.17.1-1ubuntu1.5 cowsay=3.03+dfsg1-15 fortune sl=3.03-17build1 -y ; add-apt-repository 'deb [arch=amd64,i386] https://cran.rstudio.com/bin/linux/ubuntu xenial/' ; apt-get update -y ; add-apt-repository ppa:jonathonf/python-3.6 ; apt-get update -y ; apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9 ; apt-get update -y ; tar -zxvf jdk-8u171-linux-x64.tar.gz ; rm -f jdk-8u171-linux-x64.tar.gz ; wget https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz ; tar -zxvf spark-2.4.0-bin-hadoop2.7.tgz ; rm -f spark-2.4.0-bin-hadoop2.7.tgz ; wget https://archive.apache.org/dist/hadoop/core/hadoop-2.7.7/hadoop-2.7.7.tar.gz ; tar -zxvf hadoop-2.7.7.tar.gz ; rm -f hadoop-2.7.7.tar.gz ; mkdir /gcs-connector-hadoop ; echo \"deb https://packages.cloud.google.com/apt $CLOUD_SDK_REPO main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list ; curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - ; apt-get update -y ; apt-get install --no-install-recommends google-cloud-sdk -y ; wget https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-latest-hadoop2.jar ; mv gcs-connector-latest-hadoop2.jar /gcs-connector-hadoop/ ; echo export HADOOP_CLASSPATH=/gcs-connector-hadoop/gcs-connector-latest-hadoop2.jar >> /hadoop-2.7.7/etc/hadoop/hadoop-env.sh; echo spark.driver.extraClassPath /gcs-connector-hadoop/gcs-connector-latest-hadoop2.jar >> $SPARK_HOME/conf/spark-defaults.conf; echo spark.driver.memory 5g >> $SPARK_HOME/conf/spark-defaults.conf; echo spark.driver.maxResultSize 5g >> $SPARK_HOME/conf/spark-defaults.conf; echo spark.driver.allowMultipleContexts True >> $SPARK_HOME/conf/spark-defaults.conf\nRUN apt-get install --no-install-recommends libcurl4-openssl-dev=7.47.0-1ubuntu2.19 libssl-dev=1.0.2g-1ubuntu4.20 libeigen3-dev=3.3~beta1-2 libgmp-dev=2:6.1.0+dfsg-2 libgmpxx4ldbl=2:6.1.0+dfsg-2 libmpfr-dev=3.1.4-1 libboost-dev=1.58.0.1ubuntu1 libboost-thread-dev=1.58.0.1ubuntu1 libtbb-dev=4.4~20151115-0ubuntu3 libeigen3-dev=3.3~beta1-2 libgmp-dev=2:6.1.0+dfsg-2 libgmpxx4ldbl=2:6.1.0+dfsg-2 libmpfr-dev=3.1.4-1 libboost-dev=1.58.0.1ubuntu1 libboost-thread-dev=1.58.0.1ubuntu1 libtbb-dev=4.4~20151115-0ubuntu3 -y ; apt-get update -y ; apt-get install --no-install-recommends r-base=3.2.3-4 bc=1.06.95-9build1 npm=3.5.2-0ubuntu4 ca-certificates=20210119~16.04.1 musl-dev=1.1.9-1 gcc=4:5.3.1-1ubuntu1 make=4.1-6 g++=4:5.3.1-1ubuntu1 gfortran=4:5.3.1-1ubuntu1 python3.6 -y ; curl https://bootstrap.pypa.io/get-pip.py | python3.6 ; rm -f /usr/bin/python3 \\\n && ln -s /usr/bin/python3.6 /usr/bin/python3 ; rm -f /usr/bin/python3m \\\n && ln -s /usr/bin/python3.6m /usr/bin/python3m ; apt-get install --no-install-recommends python3.6-dev -y ; apt-get -y upgrade ; apt-get install --no-install-recommends python3.6-tk -y\n#   jupyter(lab) related python packages are\n#   required before installing interactive R kernel\nCOPY requirements0.txt requirements1.txt requirements2.txt requirements3.txt requirements4.txt requirements5.txt /\nRUN pip3 install -r requirements0.txt ; R -e 'install.packages(c(\"devtools\", \"bayesAB\", \"plyr\", \"dplyr\", \"data.table\", \"bigrquery\", \"pwr\", \"cowsay\", \"fortunes\", \"progress\", \"ggplot2\", \"forecast\"))' ; R -e 'devtools::install_github(\"IRkernel/IRkernel\")' ; R -e 'IRkernel::installspec()' ; pip3 install -r requirements1.txt ; pip3 install -r requirements2.txt ; pip3 install -r requirements3.txt ; pip3 install -r requirements4.txt ; pip3 install -r requirements5.txt\nRUN jupyter nbextension enable --py widgetsnbextension ; jupyter serverextension enable --py jupyterlab\n#  jupyter labextension install @jupyterlab/latex\n#   info to hadoop                 <-- HADOOP_CLASSPATH\n#   info to spark                  <-- spark.driver.extraClassPath\n#   max mem consumed per core      <-- spark.driver.memory\n#   prevent rdd.collect() exceed   <-- spark.driver.maxResultSize\n#   RUN pip3 install git+https://github.com/michaelchanwahyan/nbparameterise.git\nCOPY .bashrc .vimrc /root/\nCOPY core-site.xml $HADOOP_CONF_DIR\nCOPY app_template /\nCOPY airflow /opt/airflow\nEXPOSE 9090/tcp 9999/tcp\nCMD [\"/bin/bash\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"#  Dockerfile for building general development\n#  environment for Data Science Analytics\n#  customized for TVB Big Data Team\nFROM ubuntu:16.04\nLABEL maintainer=\"\\\"michaelchan_wahyan@yahoo.com.hk\\\"\"\nENV SHELL=\"/bin/bash\" \\\n    TZ=\"Asia/Hong_Kong\" \\\n    PYTHONIOENCODING=\"UTF-8\" \\\n    AIRFLOW_HOME=\"/opt/airflow\" \\\n    AIRFLOW_GPL_UNIDECODE=\"yes\" \\\n    CLOUD_SDK_REPO=\"cloud-sdk-xenial\" \\\n    HADOOP_COMMON_HOME=\"/hadoop-2.7.7\" \\\n    HADOOP_HDFS_HOME=\"/hadoop-2.7.7\" \\\n    HADOOP_HOME=\"/hadoop-2.7.7\" \\\n    HADOOP_CONF_DIR=\"/hadoop-2.7.7/etc/hadoop\" \\\n    HADOOP_COMMON_LIB_NATIVE_DIR=\"/hadoop-2.7.7/lib/native\" \\\n    HADOOP_INSTALL=\"/hadoop-2.7.7\" \\\n    HADOOP_MAPRED_HOME=\"/hadoop-2.7.7\" \\\n    JAVA_HOME=\"/jdk1.8.0_171\" \\\n    PYSPARK_DRIVER_PYTHON=\"jupyter\" \\\n    PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" \\\n    PYSPARK_PYTHON=\"python3\" \\\n    SPARK_HOME=\"/spark-2.4.0-bin-hadoop2.7\" \\\n    SPARK_PATH=\"/spark-2.4.0-bin-hadoop2.7\" \\\n    YARN_HOME=\"/hadoop-2.7.7\" \\\n    PATH=\"$PATH:/root/anaconda/bin:/bin:/usr/local/sbin:/usr/local/bin:/usr/local/lib:/usr/lib:/usr/sbin:/usr/bin:/sbin:/bin:/hadoop-2.7.7/sbin:/hadoop-2.7.7/bin\"\n#  ========================\n#  Jupyter Lab installation\n#  ========================\n#  ref : https://github.com/mikebirdgeneau/jupyterlab-docker/blob/master/jupyterlab/Dockerfile\n#  for pip3 installation on jupyterlab related packages :\n#  ipywidgets   nbextension   jupyterlab\n#  ==================\n#  SPARK installation\n#  ==================\n#  ref : https://medium.com/@GalarnykMichael/install-spark-on-ubuntu-pyspark-231c45677de0\n#  SPARK installation - Part 1 (conda)\n#  SPARK installation - Part 2 (spark)\n#  SPARK installation - Part 3 (jdk 8.171)\n#  SPARK installation - Part 4 (hadoop 2.7.6)\n#  =============================\n#  Google Cloud SDK installation\n#  =============================\n#  ref : https://cloud.google.com/sdk/docs/quickstart-debian-ubuntu\n#     many more gcloud packages that could be installed\n#     google-cloud-sdk-app-engine-python\n#     google-cloud-sdk-app-engine-python-extras\n#     google-cloud-sdk-app-engine-java\n#     google-cloud-sdk-app-engine-go\n#     google-cloud-sdk-datalab\n#     google-cloud-sdk-datastore-emulator\n#     google-cloud-sdk-pubsub-emulator\n#     google-cloud-sdk-cbt\n#     google-cloud-sdk-bigtable-emulator\n#     kubectl\nCOPY jdk-8u171-linux-x64.tar.gz /\nRUN apt-get update -y ; apt-get -y upgrade ; apt-get install screen apt-utils cmake htop wget vim nano curl git software-properties-common apt-transport-https net-tools wget cowsay fortune sl -y ; add-apt-repository 'deb [arch=amd64,i386] https://cran.rstudio.com/bin/linux/ubuntu xenial/' ; apt-get update -y ; add-apt-repository ppa:jonathonf/python-3.6 ; apt-get update -y ; apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9 ; apt-get update -y ; tar -zxvf jdk-8u171-linux-x64.tar.gz ; rm -f jdk-8u171-linux-x64.tar.gz ; wget https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz ; tar -zxvf spark-2.4.0-bin-hadoop2.7.tgz ; rm -f spark-2.4.0-bin-hadoop2.7.tgz ; wget https://archive.apache.org/dist/hadoop/core/hadoop-2.7.7/hadoop-2.7.7.tar.gz ; tar -zxvf hadoop-2.7.7.tar.gz ; rm -f hadoop-2.7.7.tar.gz ; mkdir /gcs-connector-hadoop ; echo \"deb https://packages.cloud.google.com/apt $CLOUD_SDK_REPO main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list ; curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - ; apt-get update -y ; apt-get install google-cloud-sdk -y ; wget https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-latest-hadoop2.jar ; mv gcs-connector-latest-hadoop2.jar /gcs-connector-hadoop/ ; echo export HADOOP_CLASSPATH=/gcs-connector-hadoop/gcs-connector-latest-hadoop2.jar >> /hadoop-2.7.7/etc/hadoop/hadoop-env.sh; echo spark.driver.extraClassPath /gcs-connector-hadoop/gcs-connector-latest-hadoop2.jar >> $SPARK_HOME/conf/spark-defaults.conf; echo spark.driver.memory 5g >> $SPARK_HOME/conf/spark-defaults.conf; echo spark.driver.maxResultSize 5g >> $SPARK_HOME/conf/spark-defaults.conf; echo spark.driver.allowMultipleContexts True >> $SPARK_HOME/conf/spark-defaults.conf\nRUN apt-get install libcurl4-openssl-dev libssl-dev libeigen3-dev libgmp-dev libgmpxx4ldbl libmpfr-dev libboost-dev libboost-thread-dev libtbb-dev libeigen3-dev libgmp-dev libgmpxx4ldbl libmpfr-dev libboost-dev libboost-thread-dev libtbb-dev -y ; apt-get update -y ; apt-get install r-base bc npm ca-certificates musl-dev gcc make g++ gfortran python3.6 -y ; curl https://bootstrap.pypa.io/get-pip.py | python3.6 ; rm -f /usr/bin/python3 \\\n && ln -s /usr/bin/python3.6 /usr/bin/python3 ; rm -f /usr/bin/python3m \\\n && ln -s /usr/bin/python3.6m /usr/bin/python3m ; apt-get install python3.6-dev -y ; apt-get -y upgrade ; apt-get install python3.6-tk -y\n#  jupyter(lab) related python packages are\n#  required before installing interactive R kernel\nCOPY requirements0.txt requirements1.txt requirements2.txt requirements3.txt requirements4.txt requirements5.txt /\nRUN pip3 install -r requirements0.txt ; R -e 'install.packages(c(\"devtools\", \"bayesAB\", \"plyr\", \"dplyr\", \"data.table\", \"bigrquery\", \"pwr\", \"cowsay\", \"fortunes\", \"progress\", \"ggplot2\", \"forecast\"))' ; R -e 'devtools::install_github(\"IRkernel/IRkernel\")' ; R -e 'IRkernel::installspec()' ; pip3 install -r requirements1.txt ; pip3 install -r requirements2.txt ; pip3 install -r requirements3.txt ; pip3 install -r requirements4.txt ; pip3 install -r requirements5.txt\nRUN jupyter nbextension enable --py widgetsnbextension ; jupyter serverextension enable --py jupyterlab\n# jupyter labextension install @jupyterlab/latex\n#  info to hadoop                 <-- HADOOP_CLASSPATH\n#  info to spark                  <-- spark.driver.extraClassPath\n#  max mem consumed per core      <-- spark.driver.memory\n#  prevent rdd.collect() exceed   <-- spark.driver.maxResultSize\n#  RUN pip3 install git+https://github.com/michaelchanwahyan/nbparameterise.git\nCOPY .bashrc .vimrc /root/\nCOPY core-site.xml $HADOOP_CONF_DIR\nCOPY app_template /\nCOPY airflow /opt/airflow\nEXPOSE 9090/tcp 9999/tcp\nCMD [\"/bin/bash\"]\n","injectedSmells":[],"originalDockerfileHash":"7d70404bf27b08898732387529e0a2cb","successfullyInjectedSmells":[],"originalDockerfileUglified":"#   Dockerfile for building general development\n#   environment for Data Science Analytics\n#   customized for TVB Big Data Team\nFROM ubuntu:16.04\nLABEL maintainer=\"\\\"michaelchan_wahyan@yahoo.com.hk\\\"\"\nENV SHELL=\"/bin/bash\" \\\n    TZ=\"Asia/Hong_Kong\" \\\n    PYTHONIOENCODING=\"UTF-8\" \\\n    AIRFLOW_HOME=\"/opt/airflow\" \\\n    AIRFLOW_GPL_UNIDECODE=\"yes\" \\\n    CLOUD_SDK_REPO=\"cloud-sdk-xenial\" \\\n    HADOOP_COMMON_HOME=\"/hadoop-2.7.7\" \\\n    HADOOP_HDFS_HOME=\"/hadoop-2.7.7\" \\\n    HADOOP_HOME=\"/hadoop-2.7.7\" \\\n    HADOOP_CONF_DIR=\"/hadoop-2.7.7/etc/hadoop\" \\\n    HADOOP_COMMON_LIB_NATIVE_DIR=\"/hadoop-2.7.7/lib/native\" \\\n    HADOOP_INSTALL=\"/hadoop-2.7.7\" \\\n    HADOOP_MAPRED_HOME=\"/hadoop-2.7.7\" \\\n    JAVA_HOME=\"/jdk1.8.0_171\" \\\n    PYSPARK_DRIVER_PYTHON=\"jupyter\" \\\n    PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" \\\n    PYSPARK_PYTHON=\"python3\" \\\n    SPARK_HOME=\"/spark-2.4.0-bin-hadoop2.7\" \\\n    SPARK_PATH=\"/spark-2.4.0-bin-hadoop2.7\" \\\n    YARN_HOME=\"/hadoop-2.7.7\" \\\n    PATH=\"$PATH:/root/anaconda/bin:/bin:/usr/local/sbin:/usr/local/bin:/usr/local/lib:/usr/lib:/usr/sbin:/usr/bin:/sbin:/bin:/hadoop-2.7.7/sbin:/hadoop-2.7.7/bin\"\n#   ========================\n#   Jupyter Lab installation\n#   ========================\n#   ref : https://github.com/mikebirdgeneau/jupyterlab-docker/blob/master/jupyterlab/Dockerfile\n#   for pip3 installation on jupyterlab related packages :\n#   ipywidgets   nbextension   jupyterlab\n#   ==================\n#   SPARK installation\n#   ==================\n#   ref : https://medium.com/@GalarnykMichael/install-spark-on-ubuntu-pyspark-231c45677de0\n#   SPARK installation - Part 1 (conda)\n#   SPARK installation - Part 2 (spark)\n#   SPARK installation - Part 3 (jdk 8.171)\n#   SPARK installation - Part 4 (hadoop 2.7.6)\n#   =============================\n#   Google Cloud SDK installation\n#   =============================\n#   ref : https://cloud.google.com/sdk/docs/quickstart-debian-ubuntu\n#      many more gcloud packages that could be installed\n#      google-cloud-sdk-app-engine-python\n#      google-cloud-sdk-app-engine-python-extras\n#      google-cloud-sdk-app-engine-java\n#      google-cloud-sdk-app-engine-go\n#      google-cloud-sdk-datalab\n#      google-cloud-sdk-datastore-emulator\n#      google-cloud-sdk-pubsub-emulator\n#      google-cloud-sdk-cbt\n#      google-cloud-sdk-bigtable-emulator\n#      kubectl\nCOPY jdk-8u171-linux-x64.tar.gz /\nRUN apt-get update -y ; apt-get -y upgrade ; apt-get install screen apt-utils cmake htop wget vim nano curl git software-properties-common apt-transport-https net-tools wget cowsay fortune sl -y ; add-apt-repository 'deb [arch=amd64,i386] https://cran.rstudio.com/bin/linux/ubuntu xenial/' ; apt-get update -y ; add-apt-repository ppa:jonathonf/python-3.6 ; apt-get update -y ; apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9 ; apt-get update -y ; tar -zxvf jdk-8u171-linux-x64.tar.gz ; rm -f jdk-8u171-linux-x64.tar.gz ; wget https://archive.apache.org/dist/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz ; tar -zxvf spark-2.4.0-bin-hadoop2.7.tgz ; rm -f spark-2.4.0-bin-hadoop2.7.tgz ; wget https://archive.apache.org/dist/hadoop/core/hadoop-2.7.7/hadoop-2.7.7.tar.gz ; tar -zxvf hadoop-2.7.7.tar.gz ; rm -f hadoop-2.7.7.tar.gz ; mkdir /gcs-connector-hadoop ; echo \"deb https://packages.cloud.google.com/apt $CLOUD_SDK_REPO main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list ; curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - ; apt-get update -y ; apt-get install google-cloud-sdk -y ; wget https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-latest-hadoop2.jar ; mv gcs-connector-latest-hadoop2.jar /gcs-connector-hadoop/ ; echo export HADOOP_CLASSPATH=/gcs-connector-hadoop/gcs-connector-latest-hadoop2.jar >> /hadoop-2.7.7/etc/hadoop/hadoop-env.sh; echo spark.driver.extraClassPath /gcs-connector-hadoop/gcs-connector-latest-hadoop2.jar >> $SPARK_HOME/conf/spark-defaults.conf; echo spark.driver.memory 5g >> $SPARK_HOME/conf/spark-defaults.conf; echo spark.driver.maxResultSize 5g >> $SPARK_HOME/conf/spark-defaults.conf; echo spark.driver.allowMultipleContexts True >> $SPARK_HOME/conf/spark-defaults.conf\nRUN apt-get install libcurl4-openssl-dev libssl-dev libeigen3-dev libgmp-dev libgmpxx4ldbl libmpfr-dev libboost-dev libboost-thread-dev libtbb-dev libeigen3-dev libgmp-dev libgmpxx4ldbl libmpfr-dev libboost-dev libboost-thread-dev libtbb-dev -y ; apt-get update -y ; apt-get install r-base bc npm ca-certificates musl-dev gcc make g++ gfortran python3.6 -y ; curl https://bootstrap.pypa.io/get-pip.py | python3.6 ; rm -f /usr/bin/python3 \\\n && ln -s /usr/bin/python3.6 /usr/bin/python3 ; rm -f /usr/bin/python3m \\\n && ln -s /usr/bin/python3.6m /usr/bin/python3m ; apt-get install python3.6-dev -y ; apt-get -y upgrade ; apt-get install python3.6-tk -y\n#   jupyter(lab) related python packages are\n#   required before installing interactive R kernel\nCOPY requirements0.txt requirements1.txt requirements2.txt requirements3.txt requirements4.txt requirements5.txt /\nRUN pip3 install -r requirements0.txt ; R -e 'install.packages(c(\"devtools\", \"bayesAB\", \"plyr\", \"dplyr\", \"data.table\", \"bigrquery\", \"pwr\", \"cowsay\", \"fortunes\", \"progress\", \"ggplot2\", \"forecast\"))' ; R -e 'devtools::install_github(\"IRkernel/IRkernel\")' ; R -e 'IRkernel::installspec()' ; pip3 install -r requirements1.txt ; pip3 install -r requirements2.txt ; pip3 install -r requirements3.txt ; pip3 install -r requirements4.txt ; pip3 install -r requirements5.txt\nRUN jupyter nbextension enable --py widgetsnbextension ; jupyter serverextension enable --py jupyterlab\n#  jupyter labextension install @jupyterlab/latex\n#   info to hadoop                 <-- HADOOP_CLASSPATH\n#   info to spark                  <-- spark.driver.extraClassPath\n#   max mem consumed per core      <-- spark.driver.memory\n#   prevent rdd.collect() exceed   <-- spark.driver.maxResultSize\n#   RUN pip3 install git+https://github.com/michaelchanwahyan/nbparameterise.git\nCOPY .bashrc .vimrc /root/\nCOPY core-site.xml $HADOOP_CONF_DIR\nCOPY app_template /\nCOPY airflow /opt/airflow\nEXPOSE 9090/tcp 9999/tcp\nCMD [\"/bin/bash\"]\n","originalDockerfileUglifiedHash":"efff7c3c0e4ea9e8f4c211fb3ebd0ccc","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/56f2a70ca9306665ea9542b71afeddd2a30ee0da.dockerfile"}