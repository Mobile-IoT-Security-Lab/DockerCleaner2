{"seed":2298113223,"processedDockerfileHash":"d7f2adcef172f121bb4ef0817dc3394b","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","have-a-healthcheck","have-a-user"],"processedDockerfile":"#   debian:9.6 - linux; amd64\n#   https://github.com/docker-library/repo-info/blob/master/repos/debian/tag-details.md#debian96---linux-amd64\nFROM debian@sha256:38236c068c393272ad02db100e09cac36a5465149e2924a035ee60d6c60c38fe\nARG BUILD_DATE\nARG CODENAME=\"stretch\"\nARG CONDA_DIR=\"/opt/conda\"\nARG CONDA_ENV_YML=\"data-toolkit-root-conda-base-env.yml\"\nARG CONDA_INSTALLER=\"Miniconda3-4.5.4-Linux-x86_64.sh\"\nARG CONDA_MD5=\"a946ea1d0c4a642ddf0c3a26a18bb16d\"\nARG CONDA_URL=\"https://repo.continuum.io/miniconda\"\nARG DCOS_CLI_URL=\"https://downloads.dcos.io/binaries/cli/linux/x86-64\"\nARG DCOS_CLI_VERSION=\"1.12\"\nARG DCOS_COMMONS_URL=\"https://downloads.mesosphere.com/dcos-commons\"\nARG DCOS_COMMONS_VERSION=\"0.54.3\"\nARG DEBCONF_NONINTERACTIVE_SEEN=\"true\"\nARG DEBIAN_FRONTEND=\"noninteractive\"\nARG DEBIAN_REPO=\"http://cdn-fastly.deb.debian.org\"\nARG DISTRO=\"debian\"\nARG GPG_KEYSERVER=\"hkps://zimmermann.mayfirst.org\"\nARG HADOOP_HDFS_HOME=\"/opt/hadoop\"\nARG HADOOP_MAJOR_VERSION=\"2.9\"\nARG HADOOP_SHA256=\"3d2023c46b1156c1b102461ad08cbc17c8cc53004eae95dab40a1f659839f28a\"\nARG HADOOP_URL=\"http://www-us.apache.org/dist/hadoop/common\"\nARG HADOOP_VERSION=\"2.9.2\"\nARG HOME=\"/root\"\nARG JAVA_HOME=\"/opt/jdk\"\nARG JAVA_URL=\"https://downloads.mesosphere.com/java\"\nARG JAVA_VERSION=\"8u192\"\nARG LANG=\"en_US.UTF-8\"\nARG LANGUAGE=\"en_US.UTF-8\"\nARG LC_ALL=\"en_US.UTF-8\"\nARG LIBMESOS_BUNDLE_SHA256=\"217c43e4b642c1abdfe0fe309bbaede878cbc9a925562678b1c44273d140d40a\"\nARG LIBMESOS_BUNDLE_URL=\"https://downloads.mesosphere.com/libmesos-bundle\"\nARG LIBMESOS_BUNDLE_VERSION=\"1.12.0\"\nARG MESOSPHERE_PREFIX=\"/opt/mesosphere\"\nARG MESOS_JAR_SHA1=\"aab2e3118b01536af38c3b4243224149c625f008\"\nARG MESOS_MAVEN_URL=\"https://repo1.maven.org/maven2/org/apache/mesos/mesos\"\nARG MESOS_PROTOBUF_JAR_SHA1=\"bfb740747d97e5781c7f6c04bbfa93f5c2df0d4f\"\nARG MESOS_VERSION=\"1.7.0\"\nARG MESOSPHERE_DATA_TOOLKIT_VERSION=\"1.0.0-1.0.0\"\nARG OPENRESTY_REPO=\"https://openresty.org/package\"\nARG SPARK_DIST_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/spark\"\nARG SPARK_DIST_SHA256=\"52e29e83a65688e29da975d1ace7815c6a5b55e76c41d43a28e5e80de2b29843\"\nARG SPARK_HOME=\"/opt/spark\"\nARG SPARK_MAJOR_VERSION=\"2.2\"\nARG SPARK_VERSION=\"2.2.1\"\nARG TENSORFLOW_ECO_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/tensorflow\"\nARG TENSORFLOW_HADOOP_JAR_SHA256=\"668b326be1a7cfa4e621e8abaa9a5dbf1a813bad289ba0ad03e983ae8e841290\"\nARG TENSORFLOW_SPARK_JAR_SHA256=\"bcc3bcb48cfe72997f7c51e6fd8d379c64d26fd200cbd08617631fd8182a2fbf\"\nARG TENSORFLOW_JAR_SHA256=\"6a4e5c80bad7c826233a9b1750a7d4b5a28c6e5c8fccebefc1e6a0d5feeae4a3\"\nARG TENSORFLOW_JNI_SHA256=\"8f74ced6dece0e0889eb09b0731ef728feffe0aadadaf8d6401a3ff15aafcc6e\"\nARG TENSORFLOW_SERVING_APT_URL=\"http://storage.googleapis.com/tensorflow-serving-apt\"\nARG TENSORFLOW_SERVING_VERSION=\"1.11.0\"\nARG TENSORFLOW_URL=\"https://storage.googleapis.com/tensorflow\"\nARG TENSORFLOW_VARIANT=\"cpu\"\nARG TENSORFLOW_VERSION=\"1.11.0\"\nARG TINI_GPG_KEY=\"595E85A6B1B4779EA4DAAEC70B588DFF0527A9B7\"\nARG TINI_URL=\"https://github.com/krallin/tini/releases/download\"\nARG TINI_VERSION=\"v0.18.0\"\nARG VCS_REF\nARG XGBOOST_JAVA_JAR_SHA256=\"4a6599ee3f1bd10d984e8b03747d5bc3cb637aeb791474178de2c285857bf69e\"\nARG XGBOOST_SPARK_JAR_SHA256=\"cd31fb96b26fee197e126215949bc4f5c9a3cafd7ff157ab0037a63777c2935e\"\nARG XGBOOST_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/xgboost\"\nARG XGBOOST_VERSION=\"0.71\"\nLABEL maintainer=\"Mesosphere Support <support+data-toolkit@mesosphere.com>\" \\\n      org.label-schema.build-date=\"${BUILD_DATE}\" \\\n      org.label-schema.name=\"Mesosphere Data Analytics Toolkit\" \\\n      org.label-schema.description=\"Data Analytics Docker Image bundled with popular tools, libraries and frameworks.\" \\\n      org.label-schema.url=\"https://mesosphere.com\" \\\n      org.label-schema.vcs-ref=\"${VCS_REF}\" \\\n      org.label-schema.vcs-url=\"https://github.com/mesosphere/mesosphere-jupyter-service\" \\\n      org.label-schema.version=\"${MESOSPHERE_DATA_TOOLKIT_VERSION}\" \\\n      org.label-schema.schema-version=\"1.0\"\nENV BOOTSTRAP=\"${MESOSPHERE_PREFIX}/bin/bootstrap\" \\\n    CODENAME=\"${CODENAME:-stretch}\" \\\n    CONDA_DIR=\"${CONDA_DIR:-/opt/conda}\" \\\n    DEBCONF_NONINTERACTIVE_SEEN=\"${DEBCONF_NONINTERACTIVE_SEEN:-true}\" \\\n    DEBIAN_FRONTEND=\"${DEBIAN_FRONTEND:-noninteractive}\" \\\n    DISTRO=\"${DISTRO:-debian}\" \\\n    GPG_KEYSERVER=\"${GPG_KEYSERVER:-hkps://zimmermann.mayfirst.org}\" \\\n    HADOOP_HDFS_HOME=\"${HADOOP_HDFS_HOME:-/opt/hadoop}\" \\\n    HOME=\"${HOME:-/root}\" \\\n    JAVA_HOME=\"${JAVA_HOME:-/opt/jdk}\" \\\n    LANG=\"${LANG:-en_US.UTF-8}\" \\\n    LANGUAGE=\"${LANGUAGE:-en_US.UTF-8}\" \\\n    LC_ALL=\"${LC_ALL:-en_US.UTF-8}\" \\\n    MESOSPHERE_PREFIX=\"${MESOSPHERE_PREFIX:-/opt/mesosphere}\" \\\n    MESOS_AUTHENTICATEE=\"com_mesosphere_dcos_ClassicRPCAuthenticatee\" \\\n    MESOS_HTTP_AUTHENTICATEE=\"com_mesosphere_dcos_http_Authenticatee\" \\\n    MESOS_MODULES=\"{\\\"libraries\\\": [{\\\"file\\\": \\\"libdcos_security.so\\\", \\\"modules\\\": [{\\\"name\\\": \\\"com_mesosphere_dcos_ClassicRPCAuthenticatee\\\"}]}]}\" \\\n    MESOS_NATIVE_LIBRARY=\"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libmesos.so\" \\\n    MESOS_NATIVE_JAVA_LIBRARY=\"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libmesos.so\" \\\n    NODE_OPTIONS=\"--max-old-space-size=8192\" \\\n    PATH=\"${JAVA_HOME}/bin:${SPARK_HOME}/bin:${HADOOP_HDFS_HOME}/bin:${CONDA_DIR}/bin:${MESOSPHERE_PREFIX}/bin:${PATH}\" \\\n    SHELL=\"/bin/bash\" \\\n    SPARK_HOME=\"${SPARK_HOME:-/opt/spark}\"\nRUN echo \"deb ${DEBIAN_REPO}/${DISTRO} ${CODENAME} main\" >> /etc/apt/sources.list \\\n && echo \"deb ${DEBIAN_REPO}/${DISTRO}-security ${CODENAME}/updates main\" >> /etc/apt/sources.list \\\n && apt-get update -yq --fix-missing \\\n && (apt-get update ;apt-get install --no-install-recommends apt-transport-https=2.6.0 apt-utils=2.6.0 ca-certificates=20230311 curl=7.88.1-7ubuntu1 dirmngr=2.2.40-1ubuntu2 gnupg2=2.2.40-1ubuntu2 locales=2.37-0ubuntu2 -yq ) \\\n && echo \"en_US.UTF-8 UTF-8\" >> /etc/locale.gen \\\n && locale-gen \\\n && curl --retry 3 -fsSL https://openresty.org/package/pubkey.gpg -o /tmp/openresty-pubkey.gpg \\\n && apt-key add /tmp/openresty-pubkey.gpg \\\n && rm /tmp/openresty-pubkey.gpg \\\n && echo \"deb ${OPENRESTY_REPO}/${DISTRO} ${CODENAME} openresty\" > /etc/apt/sources.list.d/openresty.list \\\n && apt-get update -yq --fix-missing \\\n && apt-get -yq dist-upgrade \\\n && (apt-get update ;apt-get install --no-install-recommends bash-completion=1:2.11-6ubuntu1 bzip2=1.0.8-5build1 cmake=3.25.1-1 dnsutils=1:9.18.12-1ubuntu1 ffmpeg=7:5.1.2-3ubuntu1 g++=4:12.2.0-3ubuntu1 gcc=4:12.2.0-3ubuntu1 git=1:2.39.2-1ubuntu1 info=6.8-6build2 jq=1.6-2.1ubuntu3 kstart=4.3-1 less=590-1.2 libaio1=0.3.113-4 luarocks=3.8.0+dfsg1-1 make=4.3-4.1build1 man netcat openresty openresty-opm openssh-client=1:9.0p1-1ubuntu8 procps=2:4.0.3-1ubuntu1 psmisc=23.6-1 rsync=3.2.7-1 runit=2.1.2-54ubuntu1 sudo=1.9.13p1-1ubuntu2 sssd=2.8.1-1ubuntu1 unzip=6.0-27ubuntu1 vim=2:9.0.1000-4ubuntu2 wget=1.21.3-1ubuntu1 zlib1g-dev=1:1.2.13.dfsg-1ubuntu4 -yq ) \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/* \\\n && opm get zmartzone/lua-resty-openidc \\\n && rm -rf ~/.opm/cache \\\n && chmod ugo+rw /usr/local/openresty/nginx/logs \\\n && chmod ugo+rw /usr/local/openresty/nginx \\\n && addgroup --gid 99 nobody \\\n && usermod -u 99 -g 99 nobody \\\n && echo \"nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\" >> /etc/passwd \\\n && usermod -a -G users nobody\nRUN cd /tmp \\\n && apt-key adv --no-tty --keyserver \"${GPG_KEYSERVER}\" --recv-keys \"${TINI_GPG_KEY}\" \\\n && curl --retry 3 -fsSL \"${TINI_URL}/${TINI_VERSION}/tini\" -o /usr/bin/tini \\\n && curl --retry 3 -fsSL -O \"${TINI_URL}/${TINI_VERSION}/tini.asc\" \\\n && export GNUPGHOME=\"$( mktemp -d ;)\" \\\n && gpg --no-tty --keyserver \"${GPG_KEYSERVER}\" --recv-keys \"${TINI_GPG_KEY}\" \\\n && gpg --no-tty --batch --verify tini.asc /usr/bin/tini \\\n && rm -rf \"${GNUPGHOME}\" tini.asc \\\n && chmod +x /usr/bin/tini \\\n && mkdir -p \"${CONDA_DIR}\" \"${HADOOP_HDFS_HOME}\" \"${JAVA_HOME}\" \"${MESOSPHERE_PREFIX}/bin\" \"${SPARK_HOME}\" \\\n && curl --retry 3 -fsSL -O \"${LIBMESOS_BUNDLE_URL}/libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" \\\n && echo \"${LIBMESOS_BUNDLE_SHA256}\" \"libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" | sha256sum -c - \\\n && tar xf \"libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" -C \"${MESOSPHERE_PREFIX}\" \\\n && cd \"${MESOSPHERE_PREFIX}/libmesos-bundle/lib\" \\\n && curl --retry 3 -fsSL -O \"${MESOS_MAVEN_URL}/${MESOS_VERSION}/mesos-${MESOS_VERSION}.jar\" \\\n && echo \"${MESOS_JAR_SHA1} mesos-${MESOS_VERSION}.jar\" | sha1sum -c - \\\n && curl --retry 3 -fsSL -O \"${MESOS_MAVEN_URL}/${MESOS_VERSION}/mesos-${MESOS_VERSION}-shaded-protobuf.jar\" \\\n && echo \"${MESOS_PROTOBUF_JAR_SHA1} mesos-${MESOS_VERSION}-shaded-protobuf.jar\" | sha1sum -c - \\\n && cd /tmp \\\n && curl --retry 3 -fsSL -O \"${DCOS_COMMONS_URL}/artifacts/${DCOS_COMMONS_VERSION}/bootstrap.zip\" \\\n && unzip \"bootstrap.zip\" -d \"${MESOSPHERE_PREFIX}/bin/\" \\\n && curl --retry 3 -fsSL \"${DCOS_CLI_URL}/dcos-${DCOS_CLI_VERSION}/dcos\" -o ${MESOSPHERE_PREFIX}/bin/dcos \\\n && chmod +x ${MESOSPHERE_PREFIX}/bin/dcos \\\n && curl --retry 3 -fsSL -O \"${JAVA_URL}/server-jre-${JAVA_VERSION}-linux-x64.tar.gz\" \\\n && tar xf \"server-jre-${JAVA_VERSION}-linux-x64.tar.gz\" -C \"${JAVA_HOME}\" --strip-components=1 \\\n && curl --retry 3 -fsSL -O \"${HADOOP_URL}/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz\" \\\n && echo \"${HADOOP_SHA256}\" \"hadoop-${HADOOP_VERSION}.tar.gz\" | sha256sum -c - \\\n && tar xf \"hadoop-${HADOOP_VERSION}.tar.gz\" -C \"${HADOOP_HDFS_HOME}\" --strip-components=1 \\\n && rm -rf \"${HADOOP_HDFS_HOME}/share/doc\" \\\n && curl --retry 3 -fsSL -O \"${SPARK_DIST_URL}/spark-${SPARK_VERSION}-bin.tgz\" \\\n && echo \"${SPARK_DIST_SHA256}\" \"spark-${SPARK_VERSION}-bin.tgz\" | sha256sum -c - \\\n && tar xf \"spark-${SPARK_VERSION}-bin.tgz\" -C \"${SPARK_HOME}\" --strip-components=1 \\\n && cd \"${SPARK_HOME}/jars\" \\\n && curl --retry 3 -fsSL -O \"${XGBOOST_URL}/${XGBOOST_VERSION}/xgboost4j-${XGBOOST_VERSION}.jar\" \\\n && echo \"${XGBOOST_JAVA_JAR_SHA256}\" \"xgboost4j-${XGBOOST_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${XGBOOST_URL}/${XGBOOST_VERSION}/xgboost4j-spark-${XGBOOST_VERSION}.jar\" \\\n && echo \"${XGBOOST_SPARK_JAR_SHA256}\" \"xgboost4j-spark-${XGBOOST_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_URL}/libtensorflow/libtensorflow-${TENSORFLOW_VERSION}.jar\" \\\n && echo \"${TENSORFLOW_JAR_SHA256}\" \"libtensorflow-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_ECO_URL}/${TENSORFLOW_VERSION}/hadoop-${HADOOP_MAJOR_VERSION}/tensorflow-hadoop-${TENSORFLOW_VERSION}.jar\" \\\n && echo \"${TENSORFLOW_HADOOP_JAR_SHA256}\" \"tensorflow-hadoop-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_ECO_URL}/${TENSORFLOW_VERSION}/spark-${SPARK_MAJOR_VERSION}/spark-tensorflow-connector_2.11-${TENSORFLOW_VERSION}.jar\" \\\n && echo \"${TENSORFLOW_SPARK_JAR_SHA256}\" \"spark-tensorflow-connector_2.11-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n && cd /tmp \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_URL}/libtensorflow/libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" \\\n && echo \"${TENSORFLOW_JNI_SHA256}\" \"libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" | sha256sum -c - \\\n && tar xf \"libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" \"./libtensorflow_jni.so\" \\\n && mv \"libtensorflow_jni.so\" \"/usr/lib\" \\\n && rm -rf /tmp/*\nRUN echo \"deb [arch=amd64] ${TENSORFLOW_SERVING_APT_URL} stable tensorflow-model-server tensorflow-model-server-universal\" > /etc/apt/sources.list.d/tensorflow-serving.list \\\n && curl --retry 3 -fsSL ${TENSORFLOW_SERVING_APT_URL}/tensorflow-serving.release.pub.gpg | apt-key add - \\\n && : \\\n && TENSORFLOW_SERVING_DEB=\"$( mktemp ;)\" \\\n && curl --retry 3 -fsSL \"${TENSORFLOW_SERVING_APT_URL}/pool/tensorflow-model-server-${TENSORFLOW_SERVING_VERSION}/t/tensorflow-model-server/tensorflow-model-server_${TENSORFLOW_SERVING_VERSION}_all.deb\" -o \"${TENSORFLOW_SERVING_DEB}\" \\\n && dpkg -i \"${TENSORFLOW_SERVING_DEB}\" \\\n && rm -f \"${TENSORFLOW_SERVING_DEB}\" \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\nCOPY \"${CONDA_ENV_YML}\" \"${CONDA_DIR}/\"\nRUN cd /tmp \\\n && curl --retry 3 -fsSL -O \"${CONDA_URL}/${CONDA_INSTALLER}\" \\\n && echo \"${CONDA_MD5} ${CONDA_INSTALLER}\" | md5sum -c - \\\n && bash \"./${CONDA_INSTALLER}\" -u -b -p \"${CONDA_DIR}\" \\\n && ${CONDA_DIR}/bin/conda update --json --all -yq \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages defaults::conda \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::blas \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::boost \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::gsl \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::numpy \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::openblas \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::scikit-learn \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::scipy \\\n && ${CONDA_DIR}/bin/conda config --system --prepend channels conda-forge \\\n && ${CONDA_DIR}/bin/conda config --system --set auto_update_conda false \\\n && ${CONDA_DIR}/bin/conda config --system --set show_channel_urls true \\\n && ${CONDA_DIR}/bin/conda update --json -yq pip \\\n && ${CONDA_DIR}/bin/conda env update --json -q -f \"${CONDA_DIR}/${CONDA_ENV_YML}\" \\\n && ${CONDA_DIR}/bin/conda remove --force --json -yq openjdk pyqt qt qtconsole \\\n && rm -rf \"${HOME}/.cache/pip\" \"${HOME}/.cache/yarn\" \"${HOME}/.npm/_cacache\" \"${HOME}/.node-gyp\" \\\n && ${CONDA_DIR}/bin/conda clean --json -tipsy \\\n && for dir in .conda/envs bin work; do mkdir -p \"${HOME}/${dir}\" ; done \\\n && rm -rf /tmp/*\nCOPY profile \"/etc/skel/.profile\"\nCOPY profile \"${HOME}/.profile\"\nCOPY bash_profile \"/etc/skel/.bash_profile\"\nCOPY bash_profile \"${HOME}/.bash_profile\"\nCOPY bashrc \"/etc/skel/.bashrc\"\nCOPY bashrc \"${HOME}/.bashrc\"\nRUN cp \"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libcurl.so.4\" /usr/lib/x86_64-linux-gnu/libcurl.so.4.4.0\nENV SPARK_DIST_CLASSPATH=\"${HADOOP_HDFS_HOME}/etc/hadoop:${HADOOP_HDFS_HOME}/share/hadoop/common/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/common/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/*:${HADOOP_HDFS_HOME}/share/hadoop/yarn:${HADOOP_HDFS_HOME}/share/hadoop/yarn/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/yarn/*:${HADOOP_HDFS_HOME}/share/hadoop/mapreduce/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/mapreduce/*:${HADOOP_HDFS_HOME}/share/hadoop/tools/lib/*\" \\\n    HADOOP_CLASSPATH=\"${HADOOP_CLASSPATH}:${HADOOP_HDFS_HOME}/share/hadoop/tools/lib/*\" \\\n    PYTHONPATH=\"${SPARK_HOME}/python:${SPARK_HOME}/python/lib/py4j-0.10.4-src.zip:${PYTHONPATH}\" \\\n    LD_LIBRARY_PATH=\"/usr/lib/x86_64-linux-gnu:${MESOSPHERE_PREFIX}/libmesos-bundle/lib:${JAVA_HOME}/jre/lib/amd64/server:${HADOOP_HDFS_HOME}/lib/native\"\nWORKDIR \"/mnt/mesos/sandbox\"\nCOPY krb5.conf.mustache /etc/\nCOPY hadoop-env.sh \"${HADOOP_HDFS_HOME}/etc/hadoop/\"\nCOPY hadooprc \"${HOME}/.hadooprc\"\nCOPY conf/ \"${SPARK_HOME}/conf/\"\nCOPY nginx /usr/local/openresty/nginx/\nRUN chmod -R ugo+rw \"${SPARK_HOME}/conf\" \\\n && cp \"${CONDA_DIR}/share/examples/krb5/krb5.conf\" /etc \\\n && chmod ugo+rw /etc/krb5.conf \\\n && chmod ugo+rw /usr/local/openresty/nginx/conf/nginx.conf \\\n && chmod ugo+rw /usr/local/openresty/nginx/conf/sites/proxy.conf\nCOPY start-spark-history.sh /usr/local/bin/\nCOPY start-tensorboard.sh /usr/local/bin/\nCOPY start-worker.sh \"/usr/local/bin/\"\nCOPY start-dask-worker.sh \"/usr/local/bin/\"\nCOPY start-ray-worker.sh \"/usr/local/bin/\"\nCOPY ray-worker-health-check.sh \"/usr/local/bin/\"\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"#  debian:9.6 - linux; amd64\n#  https://github.com/docker-library/repo-info/blob/master/repos/debian/tag-details.md#debian96---linux-amd64\nFROM debian@sha256:38236c068c393272ad02db100e09cac36a5465149e2924a035ee60d6c60c38fe\nARG BUILD_DATE\nARG CODENAME=\"stretch\"\nARG CONDA_DIR=\"/opt/conda\"\nARG CONDA_ENV_YML=\"data-toolkit-root-conda-base-env.yml\"\nARG CONDA_INSTALLER=\"Miniconda3-4.5.4-Linux-x86_64.sh\"\nARG CONDA_MD5=\"a946ea1d0c4a642ddf0c3a26a18bb16d\"\nARG CONDA_URL=\"https://repo.continuum.io/miniconda\"\nARG DCOS_CLI_URL=\"https://downloads.dcos.io/binaries/cli/linux/x86-64\"\nARG DCOS_CLI_VERSION=\"1.12\"\nARG DCOS_COMMONS_URL=\"https://downloads.mesosphere.com/dcos-commons\"\nARG DCOS_COMMONS_VERSION=\"0.54.3\"\nARG DEBCONF_NONINTERACTIVE_SEEN=\"true\"\nARG DEBIAN_FRONTEND=\"noninteractive\"\nARG DEBIAN_REPO=\"http://cdn-fastly.deb.debian.org\"\nARG DISTRO=\"debian\"\nARG GPG_KEYSERVER=\"hkps://zimmermann.mayfirst.org\"\nARG HADOOP_HDFS_HOME=\"/opt/hadoop\"\nARG HADOOP_MAJOR_VERSION=\"2.9\"\nARG HADOOP_SHA256=\"3d2023c46b1156c1b102461ad08cbc17c8cc53004eae95dab40a1f659839f28a\"\nARG HADOOP_URL=\"http://www-us.apache.org/dist/hadoop/common\"\nARG HADOOP_VERSION=\"2.9.2\"\nARG HOME=\"/root\"\nARG JAVA_HOME=\"/opt/jdk\"\nARG JAVA_URL=\"https://downloads.mesosphere.com/java\"\nARG JAVA_VERSION=\"8u192\"\nARG LANG=\"en_US.UTF-8\"\nARG LANGUAGE=\"en_US.UTF-8\"\nARG LC_ALL=\"en_US.UTF-8\"\nARG LIBMESOS_BUNDLE_SHA256=\"217c43e4b642c1abdfe0fe309bbaede878cbc9a925562678b1c44273d140d40a\"\nARG LIBMESOS_BUNDLE_URL=\"https://downloads.mesosphere.com/libmesos-bundle\"\nARG LIBMESOS_BUNDLE_VERSION=\"1.12.0\"\nARG MESOSPHERE_PREFIX=\"/opt/mesosphere\"\nARG MESOS_JAR_SHA1=\"aab2e3118b01536af38c3b4243224149c625f008\"\nARG MESOS_MAVEN_URL=\"https://repo1.maven.org/maven2/org/apache/mesos/mesos\"\nARG MESOS_PROTOBUF_JAR_SHA1=\"bfb740747d97e5781c7f6c04bbfa93f5c2df0d4f\"\nARG MESOS_VERSION=\"1.7.0\"\nARG MESOSPHERE_DATA_TOOLKIT_VERSION=\"1.0.0-1.0.0\"\nARG OPENRESTY_REPO=\"https://openresty.org/package\"\nARG SPARK_DIST_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/spark\"\nARG SPARK_DIST_SHA256=\"52e29e83a65688e29da975d1ace7815c6a5b55e76c41d43a28e5e80de2b29843\"\nARG SPARK_HOME=\"/opt/spark\"\nARG SPARK_MAJOR_VERSION=\"2.2\"\nARG SPARK_VERSION=\"2.2.1\"\nARG TENSORFLOW_ECO_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/tensorflow\"\nARG TENSORFLOW_HADOOP_JAR_SHA256=\"668b326be1a7cfa4e621e8abaa9a5dbf1a813bad289ba0ad03e983ae8e841290\"\nARG TENSORFLOW_SPARK_JAR_SHA256=\"bcc3bcb48cfe72997f7c51e6fd8d379c64d26fd200cbd08617631fd8182a2fbf\"\nARG TENSORFLOW_JAR_SHA256=\"6a4e5c80bad7c826233a9b1750a7d4b5a28c6e5c8fccebefc1e6a0d5feeae4a3\"\nARG TENSORFLOW_JNI_SHA256=\"8f74ced6dece0e0889eb09b0731ef728feffe0aadadaf8d6401a3ff15aafcc6e\"\nARG TENSORFLOW_SERVING_APT_URL=\"http://storage.googleapis.com/tensorflow-serving-apt\"\nARG TENSORFLOW_SERVING_VERSION=\"1.11.0\"\nARG TENSORFLOW_URL=\"https://storage.googleapis.com/tensorflow\"\nARG TENSORFLOW_VARIANT=\"cpu\"\nARG TENSORFLOW_VERSION=\"1.11.0\"\nARG TINI_GPG_KEY=\"595E85A6B1B4779EA4DAAEC70B588DFF0527A9B7\"\nARG TINI_URL=\"https://github.com/krallin/tini/releases/download\"\nARG TINI_VERSION=\"v0.18.0\"\nARG VCS_REF\nARG XGBOOST_JAVA_JAR_SHA256=\"4a6599ee3f1bd10d984e8b03747d5bc3cb637aeb791474178de2c285857bf69e\"\nARG XGBOOST_SPARK_JAR_SHA256=\"cd31fb96b26fee197e126215949bc4f5c9a3cafd7ff157ab0037a63777c2935e\"\nARG XGBOOST_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/xgboost\"\nARG XGBOOST_VERSION=\"0.71\"\nLABEL maintainer=\"Mesosphere Support <support+data-toolkit@mesosphere.com>\" \\\n      org.label-schema.build-date=\"${BUILD_DATE}\" \\\n      org.label-schema.name=\"Mesosphere Data Analytics Toolkit\" \\\n      org.label-schema.description=\"Data Analytics Docker Image bundled with popular tools, libraries and frameworks.\" \\\n      org.label-schema.url=\"https://mesosphere.com\" \\\n      org.label-schema.vcs-ref=\"${VCS_REF}\" \\\n      org.label-schema.vcs-url=\"https://github.com/mesosphere/mesosphere-jupyter-service\" \\\n      org.label-schema.version=\"${MESOSPHERE_DATA_TOOLKIT_VERSION}\" \\\n      org.label-schema.schema-version=\"1.0\"\nENV BOOTSTRAP=\"${MESOSPHERE_PREFIX}/bin/bootstrap\" \\\n    CODENAME=\"${CODENAME:-stretch}\" \\\n    CONDA_DIR=\"${CONDA_DIR:-/opt/conda}\" \\\n    DEBCONF_NONINTERACTIVE_SEEN=\"${DEBCONF_NONINTERACTIVE_SEEN:-true}\" \\\n    DEBIAN_FRONTEND=\"${DEBIAN_FRONTEND:-noninteractive}\" \\\n    DISTRO=\"${DISTRO:-debian}\" \\\n    GPG_KEYSERVER=\"${GPG_KEYSERVER:-hkps://zimmermann.mayfirst.org}\" \\\n    HADOOP_HDFS_HOME=\"${HADOOP_HDFS_HOME:-/opt/hadoop}\" \\\n    HOME=\"${HOME:-/root}\" \\\n    JAVA_HOME=\"${JAVA_HOME:-/opt/jdk}\" \\\n    LANG=\"${LANG:-en_US.UTF-8}\" \\\n    LANGUAGE=\"${LANGUAGE:-en_US.UTF-8}\" \\\n    LC_ALL=\"${LC_ALL:-en_US.UTF-8}\" \\\n    MESOSPHERE_PREFIX=\"${MESOSPHERE_PREFIX:-/opt/mesosphere}\" \\\n    MESOS_AUTHENTICATEE=\"com_mesosphere_dcos_ClassicRPCAuthenticatee\" \\\n    MESOS_HTTP_AUTHENTICATEE=\"com_mesosphere_dcos_http_Authenticatee\" \\\n    MESOS_MODULES=\"{\\\"libraries\\\": [{\\\"file\\\": \\\"libdcos_security.so\\\", \\\"modules\\\": [{\\\"name\\\": \\\"com_mesosphere_dcos_ClassicRPCAuthenticatee\\\"}]}]}\" \\\n    MESOS_NATIVE_LIBRARY=\"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libmesos.so\" \\\n    MESOS_NATIVE_JAVA_LIBRARY=\"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libmesos.so\" \\\n    NODE_OPTIONS=\"--max-old-space-size=8192\" \\\n    PATH=\"${JAVA_HOME}/bin:${SPARK_HOME}/bin:${HADOOP_HDFS_HOME}/bin:${CONDA_DIR}/bin:${MESOSPHERE_PREFIX}/bin:${PATH}\" \\\n    SHELL=\"/bin/bash\" \\\n    SPARK_HOME=\"${SPARK_HOME:-/opt/spark}\"\nRUN echo \"deb ${DEBIAN_REPO}/${DISTRO} ${CODENAME} main\" >> /etc/apt/sources.list \\\n && echo \"deb ${DEBIAN_REPO}/${DISTRO}-security ${CODENAME}/updates main\" >> /etc/apt/sources.list \\\n && apt-get update -yq --fix-missing \\\n && apt-get install --no-install-recommends apt-transport-https apt-utils ca-certificates curl dirmngr gnupg2 locales -yq \\\n && echo \"en_US.UTF-8 UTF-8\" >> /etc/locale.gen \\\n && locale-gen \\\n && curl --retry 3 -fsSL https://openresty.org/package/pubkey.gpg -o /tmp/openresty-pubkey.gpg \\\n && apt-key add /tmp/openresty-pubkey.gpg \\\n && rm /tmp/openresty-pubkey.gpg \\\n && echo \"deb ${OPENRESTY_REPO}/${DISTRO} ${CODENAME} openresty\" > /etc/apt/sources.list.d/openresty.list \\\n && apt-get update -yq --fix-missing \\\n && apt-get -yq dist-upgrade \\\n && apt-get install --no-install-recommends bash-completion bzip2 cmake dnsutils ffmpeg g++ gcc git info jq kstart less libaio1 luarocks make man netcat openresty openresty-opm openssh-client procps psmisc rsync runit sudo sssd unzip vim wget zlib1g-dev -yq \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/* \\\n && opm get zmartzone/lua-resty-openidc \\\n && rm -rf ~/.opm/cache \\\n && chmod ugo+rw /usr/local/openresty/nginx/logs \\\n && chmod ugo+rw /usr/local/openresty/nginx \\\n && addgroup --gid 99 nobody \\\n && usermod -u 99 -g 99 nobody \\\n && echo \"nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\" >> /etc/passwd \\\n && usermod -a -G users nobody\nRUN cd /tmp \\\n && apt-key adv --no-tty --keyserver \"${GPG_KEYSERVER}\" --recv-keys \"${TINI_GPG_KEY}\" \\\n && curl --retry 3 -fsSL \"${TINI_URL}/${TINI_VERSION}/tini\" -o /usr/bin/tini \\\n && curl --retry 3 -fsSL -O \"${TINI_URL}/${TINI_VERSION}/tini.asc\" \\\n && export GNUPGHOME=\"$( mktemp -d ;)\" \\\n && gpg --no-tty --keyserver \"${GPG_KEYSERVER}\" --recv-keys \"${TINI_GPG_KEY}\" \\\n && gpg --no-tty --batch --verify tini.asc /usr/bin/tini \\\n && rm -rf \"${GNUPGHOME}\" tini.asc \\\n && chmod +x /usr/bin/tini \\\n && mkdir -p \"${CONDA_DIR}\" \"${HADOOP_HDFS_HOME}\" \"${JAVA_HOME}\" \"${MESOSPHERE_PREFIX}/bin\" \"${SPARK_HOME}\" \\\n && curl --retry 3 -fsSL -O \"${LIBMESOS_BUNDLE_URL}/libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" \\\n && echo \"${LIBMESOS_BUNDLE_SHA256}\" \"libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" | sha256sum -c - \\\n && tar xf \"libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" -C \"${MESOSPHERE_PREFIX}\" \\\n && cd \"${MESOSPHERE_PREFIX}/libmesos-bundle/lib\" \\\n && curl --retry 3 -fsSL -O \"${MESOS_MAVEN_URL}/${MESOS_VERSION}/mesos-${MESOS_VERSION}.jar\" \\\n && echo \"${MESOS_JAR_SHA1} mesos-${MESOS_VERSION}.jar\" | sha1sum -c - \\\n && curl --retry 3 -fsSL -O \"${MESOS_MAVEN_URL}/${MESOS_VERSION}/mesos-${MESOS_VERSION}-shaded-protobuf.jar\" \\\n && echo \"${MESOS_PROTOBUF_JAR_SHA1} mesos-${MESOS_VERSION}-shaded-protobuf.jar\" | sha1sum -c - \\\n && cd /tmp \\\n && curl --retry 3 -fsSL -O \"${DCOS_COMMONS_URL}/artifacts/${DCOS_COMMONS_VERSION}/bootstrap.zip\" \\\n && unzip \"bootstrap.zip\" -d \"${MESOSPHERE_PREFIX}/bin/\" \\\n && curl --retry 3 -fsSL \"${DCOS_CLI_URL}/dcos-${DCOS_CLI_VERSION}/dcos\" -o ${MESOSPHERE_PREFIX}/bin/dcos \\\n && chmod +x ${MESOSPHERE_PREFIX}/bin/dcos \\\n && curl --retry 3 -fsSL -O \"${JAVA_URL}/server-jre-${JAVA_VERSION}-linux-x64.tar.gz\" \\\n && tar xf \"server-jre-${JAVA_VERSION}-linux-x64.tar.gz\" -C \"${JAVA_HOME}\" --strip-components=1 \\\n && curl --retry 3 -fsSL -O \"${HADOOP_URL}/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz\" \\\n && echo \"${HADOOP_SHA256}\" \"hadoop-${HADOOP_VERSION}.tar.gz\" | sha256sum -c - \\\n && tar xf \"hadoop-${HADOOP_VERSION}.tar.gz\" -C \"${HADOOP_HDFS_HOME}\" --strip-components=1 \\\n && rm -rf \"${HADOOP_HDFS_HOME}/share/doc\" \\\n && curl --retry 3 -fsSL -O \"${SPARK_DIST_URL}/spark-${SPARK_VERSION}-bin.tgz\" \\\n && echo \"${SPARK_DIST_SHA256}\" \"spark-${SPARK_VERSION}-bin.tgz\" | sha256sum -c - \\\n && tar xf \"spark-${SPARK_VERSION}-bin.tgz\" -C \"${SPARK_HOME}\" --strip-components=1 \\\n && cd \"${SPARK_HOME}/jars\" \\\n && curl --retry 3 -fsSL -O \"${XGBOOST_URL}/${XGBOOST_VERSION}/xgboost4j-${XGBOOST_VERSION}.jar\" \\\n && echo \"${XGBOOST_JAVA_JAR_SHA256}\" \"xgboost4j-${XGBOOST_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${XGBOOST_URL}/${XGBOOST_VERSION}/xgboost4j-spark-${XGBOOST_VERSION}.jar\" \\\n && echo \"${XGBOOST_SPARK_JAR_SHA256}\" \"xgboost4j-spark-${XGBOOST_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_URL}/libtensorflow/libtensorflow-${TENSORFLOW_VERSION}.jar\" \\\n && echo \"${TENSORFLOW_JAR_SHA256}\" \"libtensorflow-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_ECO_URL}/${TENSORFLOW_VERSION}/hadoop-${HADOOP_MAJOR_VERSION}/tensorflow-hadoop-${TENSORFLOW_VERSION}.jar\" \\\n && echo \"${TENSORFLOW_HADOOP_JAR_SHA256}\" \"tensorflow-hadoop-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_ECO_URL}/${TENSORFLOW_VERSION}/spark-${SPARK_MAJOR_VERSION}/spark-tensorflow-connector_2.11-${TENSORFLOW_VERSION}.jar\" \\\n && echo \"${TENSORFLOW_SPARK_JAR_SHA256}\" \"spark-tensorflow-connector_2.11-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n && cd /tmp \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_URL}/libtensorflow/libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" \\\n && echo \"${TENSORFLOW_JNI_SHA256}\" \"libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" | sha256sum -c - \\\n && tar xf \"libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" \"./libtensorflow_jni.so\" \\\n && mv \"libtensorflow_jni.so\" \"/usr/lib\" \\\n && rm -rf /tmp/*\nRUN echo \"deb [arch=amd64] ${TENSORFLOW_SERVING_APT_URL} stable tensorflow-model-server tensorflow-model-server-universal\" > /etc/apt/sources.list.d/tensorflow-serving.list \\\n && curl --retry 3 -fsSL ${TENSORFLOW_SERVING_APT_URL}/tensorflow-serving.release.pub.gpg | apt-key add - \\\n && apt-get update \\\n && TENSORFLOW_SERVING_DEB=\"$( mktemp ;)\" \\\n && curl --retry 3 -fsSL \"${TENSORFLOW_SERVING_APT_URL}/pool/tensorflow-model-server-${TENSORFLOW_SERVING_VERSION}/t/tensorflow-model-server/tensorflow-model-server_${TENSORFLOW_SERVING_VERSION}_all.deb\" -o \"${TENSORFLOW_SERVING_DEB}\" \\\n && dpkg -i \"${TENSORFLOW_SERVING_DEB}\" \\\n && rm -f \"${TENSORFLOW_SERVING_DEB}\" \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\nCOPY \"${CONDA_ENV_YML}\" \"${CONDA_DIR}/\"\nRUN cd /tmp \\\n && curl --retry 3 -fsSL -O \"${CONDA_URL}/${CONDA_INSTALLER}\" \\\n && echo \"${CONDA_MD5} ${CONDA_INSTALLER}\" | md5sum -c - \\\n && bash \"./${CONDA_INSTALLER}\" -u -b -p \"${CONDA_DIR}\" \\\n && ${CONDA_DIR}/bin/conda update --json --all -yq \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages defaults::conda \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::blas \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::boost \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::gsl \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::numpy \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::openblas \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::scikit-learn \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::scipy \\\n && ${CONDA_DIR}/bin/conda config --system --prepend channels conda-forge \\\n && ${CONDA_DIR}/bin/conda config --system --set auto_update_conda false \\\n && ${CONDA_DIR}/bin/conda config --system --set show_channel_urls true \\\n && ${CONDA_DIR}/bin/conda update --json -yq pip \\\n && ${CONDA_DIR}/bin/conda env update --json -q -f \"${CONDA_DIR}/${CONDA_ENV_YML}\" \\\n && ${CONDA_DIR}/bin/conda remove --force --json -yq openjdk pyqt qt qtconsole \\\n && rm -rf \"${HOME}/.cache/pip\" \"${HOME}/.cache/yarn\" \"${HOME}/.npm/_cacache\" \"${HOME}/.node-gyp\" \\\n && ${CONDA_DIR}/bin/conda clean --json -tipsy \\\n && for dir in .conda/envs bin work; do mkdir -p \"${HOME}/${dir}\" ; done \\\n && rm -rf /tmp/*\nCOPY profile \"/etc/skel/.profile\"\nCOPY profile \"${HOME}/.profile\"\nCOPY bash_profile \"/etc/skel/.bash_profile\"\nCOPY bash_profile \"${HOME}/.bash_profile\"\nCOPY bashrc \"/etc/skel/.bashrc\"\nCOPY bashrc \"${HOME}/.bashrc\"\nRUN cp \"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libcurl.so.4\" /usr/lib/x86_64-linux-gnu/libcurl.so.4.4.0\nENV SPARK_DIST_CLASSPATH=\"${HADOOP_HDFS_HOME}/etc/hadoop:${HADOOP_HDFS_HOME}/share/hadoop/common/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/common/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/*:${HADOOP_HDFS_HOME}/share/hadoop/yarn:${HADOOP_HDFS_HOME}/share/hadoop/yarn/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/yarn/*:${HADOOP_HDFS_HOME}/share/hadoop/mapreduce/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/mapreduce/*:${HADOOP_HDFS_HOME}/share/hadoop/tools/lib/*\" \\\n    HADOOP_CLASSPATH=\"${HADOOP_CLASSPATH}:${HADOOP_HDFS_HOME}/share/hadoop/tools/lib/*\" \\\n    PYTHONPATH=\"${SPARK_HOME}/python:${SPARK_HOME}/python/lib/py4j-0.10.4-src.zip:${PYTHONPATH}\" \\\n    LD_LIBRARY_PATH=\"/usr/lib/x86_64-linux-gnu:${MESOSPHERE_PREFIX}/libmesos-bundle/lib:${JAVA_HOME}/jre/lib/amd64/server:${HADOOP_HDFS_HOME}/lib/native\"\nWORKDIR \"/mnt/mesos/sandbox\"\nCOPY krb5.conf.mustache /etc/\nCOPY hadoop-env.sh \"${HADOOP_HDFS_HOME}/etc/hadoop/\"\nCOPY hadooprc \"${HOME}/.hadooprc\"\nCOPY conf/ \"${SPARK_HOME}/conf/\"\nCOPY nginx /usr/local/openresty/nginx/\nRUN chmod -R ugo+rw \"${SPARK_HOME}/conf\" \\\n && cp \"${CONDA_DIR}/share/examples/krb5/krb5.conf\" /etc \\\n && chmod ugo+rw /etc/krb5.conf \\\n && chmod ugo+rw /usr/local/openresty/nginx/conf/nginx.conf \\\n && chmod ugo+rw /usr/local/openresty/nginx/conf/sites/proxy.conf\nCOPY start-spark-history.sh /usr/local/bin/\nCOPY start-tensorboard.sh /usr/local/bin/\nCOPY start-worker.sh \"/usr/local/bin/\"\nCOPY start-dask-worker.sh \"/usr/local/bin/\"\nCOPY start-ray-worker.sh \"/usr/local/bin/\"\nCOPY ray-worker-health-check.sh \"/usr/local/bin/\"\n","injectedSmells":[],"originalDockerfileHash":"a81f159d51b04bdb5070c6db88fa6cc7","successfullyInjectedSmells":[],"originalDockerfileUglified":"#   debian:9.6 - linux; amd64\n#   https://github.com/docker-library/repo-info/blob/master/repos/debian/tag-details.md#debian96---linux-amd64\nFROM debian@sha256:38236c068c393272ad02db100e09cac36a5465149e2924a035ee60d6c60c38fe\nARG BUILD_DATE\nARG CODENAME=\"stretch\"\nARG CONDA_DIR=\"/opt/conda\"\nARG CONDA_ENV_YML=\"data-toolkit-root-conda-base-env.yml\"\nARG CONDA_INSTALLER=\"Miniconda3-4.5.4-Linux-x86_64.sh\"\nARG CONDA_MD5=\"a946ea1d0c4a642ddf0c3a26a18bb16d\"\nARG CONDA_URL=\"https://repo.continuum.io/miniconda\"\nARG DCOS_CLI_URL=\"https://downloads.dcos.io/binaries/cli/linux/x86-64\"\nARG DCOS_CLI_VERSION=\"1.12\"\nARG DCOS_COMMONS_URL=\"https://downloads.mesosphere.com/dcos-commons\"\nARG DCOS_COMMONS_VERSION=\"0.54.3\"\nARG DEBCONF_NONINTERACTIVE_SEEN=\"true\"\nARG DEBIAN_FRONTEND=\"noninteractive\"\nARG DEBIAN_REPO=\"http://cdn-fastly.deb.debian.org\"\nARG DISTRO=\"debian\"\nARG GPG_KEYSERVER=\"hkps://zimmermann.mayfirst.org\"\nARG HADOOP_HDFS_HOME=\"/opt/hadoop\"\nARG HADOOP_MAJOR_VERSION=\"2.9\"\nARG HADOOP_SHA256=\"3d2023c46b1156c1b102461ad08cbc17c8cc53004eae95dab40a1f659839f28a\"\nARG HADOOP_URL=\"http://www-us.apache.org/dist/hadoop/common\"\nARG HADOOP_VERSION=\"2.9.2\"\nARG HOME=\"/root\"\nARG JAVA_HOME=\"/opt/jdk\"\nARG JAVA_URL=\"https://downloads.mesosphere.com/java\"\nARG JAVA_VERSION=\"8u192\"\nARG LANG=\"en_US.UTF-8\"\nARG LANGUAGE=\"en_US.UTF-8\"\nARG LC_ALL=\"en_US.UTF-8\"\nARG LIBMESOS_BUNDLE_SHA256=\"217c43e4b642c1abdfe0fe309bbaede878cbc9a925562678b1c44273d140d40a\"\nARG LIBMESOS_BUNDLE_URL=\"https://downloads.mesosphere.com/libmesos-bundle\"\nARG LIBMESOS_BUNDLE_VERSION=\"1.12.0\"\nARG MESOSPHERE_PREFIX=\"/opt/mesosphere\"\nARG MESOS_JAR_SHA1=\"aab2e3118b01536af38c3b4243224149c625f008\"\nARG MESOS_MAVEN_URL=\"https://repo1.maven.org/maven2/org/apache/mesos/mesos\"\nARG MESOS_PROTOBUF_JAR_SHA1=\"bfb740747d97e5781c7f6c04bbfa93f5c2df0d4f\"\nARG MESOS_VERSION=\"1.7.0\"\nARG MESOSPHERE_DATA_TOOLKIT_VERSION=\"1.0.0-1.0.0\"\nARG OPENRESTY_REPO=\"https://openresty.org/package\"\nARG SPARK_DIST_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/spark\"\nARG SPARK_DIST_SHA256=\"52e29e83a65688e29da975d1ace7815c6a5b55e76c41d43a28e5e80de2b29843\"\nARG SPARK_HOME=\"/opt/spark\"\nARG SPARK_MAJOR_VERSION=\"2.2\"\nARG SPARK_VERSION=\"2.2.1\"\nARG TENSORFLOW_ECO_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/tensorflow\"\nARG TENSORFLOW_HADOOP_JAR_SHA256=\"668b326be1a7cfa4e621e8abaa9a5dbf1a813bad289ba0ad03e983ae8e841290\"\nARG TENSORFLOW_SPARK_JAR_SHA256=\"bcc3bcb48cfe72997f7c51e6fd8d379c64d26fd200cbd08617631fd8182a2fbf\"\nARG TENSORFLOW_JAR_SHA256=\"6a4e5c80bad7c826233a9b1750a7d4b5a28c6e5c8fccebefc1e6a0d5feeae4a3\"\nARG TENSORFLOW_JNI_SHA256=\"8f74ced6dece0e0889eb09b0731ef728feffe0aadadaf8d6401a3ff15aafcc6e\"\nARG TENSORFLOW_SERVING_APT_URL=\"http://storage.googleapis.com/tensorflow-serving-apt\"\nARG TENSORFLOW_SERVING_VERSION=\"1.11.0\"\nARG TENSORFLOW_URL=\"https://storage.googleapis.com/tensorflow\"\nARG TENSORFLOW_VARIANT=\"cpu\"\nARG TENSORFLOW_VERSION=\"1.11.0\"\nARG TINI_GPG_KEY=\"595E85A6B1B4779EA4DAAEC70B588DFF0527A9B7\"\nARG TINI_URL=\"https://github.com/krallin/tini/releases/download\"\nARG TINI_VERSION=\"v0.18.0\"\nARG VCS_REF\nARG XGBOOST_JAVA_JAR_SHA256=\"4a6599ee3f1bd10d984e8b03747d5bc3cb637aeb791474178de2c285857bf69e\"\nARG XGBOOST_SPARK_JAR_SHA256=\"cd31fb96b26fee197e126215949bc4f5c9a3cafd7ff157ab0037a63777c2935e\"\nARG XGBOOST_URL=\"https://downloads.mesosphere.com/mesosphere-jupyter-service/assets/xgboost\"\nARG XGBOOST_VERSION=\"0.71\"\nLABEL maintainer=\"Mesosphere Support <support+data-toolkit@mesosphere.com>\" \\\n      org.label-schema.build-date=\"${BUILD_DATE}\" \\\n      org.label-schema.name=\"Mesosphere Data Analytics Toolkit\" \\\n      org.label-schema.description=\"Data Analytics Docker Image bundled with popular tools, libraries and frameworks.\" \\\n      org.label-schema.url=\"https://mesosphere.com\" \\\n      org.label-schema.vcs-ref=\"${VCS_REF}\" \\\n      org.label-schema.vcs-url=\"https://github.com/mesosphere/mesosphere-jupyter-service\" \\\n      org.label-schema.version=\"${MESOSPHERE_DATA_TOOLKIT_VERSION}\" \\\n      org.label-schema.schema-version=\"1.0\"\nENV BOOTSTRAP=\"${MESOSPHERE_PREFIX}/bin/bootstrap\" \\\n    CODENAME=\"${CODENAME:-stretch}\" \\\n    CONDA_DIR=\"${CONDA_DIR:-/opt/conda}\" \\\n    DEBCONF_NONINTERACTIVE_SEEN=\"${DEBCONF_NONINTERACTIVE_SEEN:-true}\" \\\n    DEBIAN_FRONTEND=\"${DEBIAN_FRONTEND:-noninteractive}\" \\\n    DISTRO=\"${DISTRO:-debian}\" \\\n    GPG_KEYSERVER=\"${GPG_KEYSERVER:-hkps://zimmermann.mayfirst.org}\" \\\n    HADOOP_HDFS_HOME=\"${HADOOP_HDFS_HOME:-/opt/hadoop}\" \\\n    HOME=\"${HOME:-/root}\" \\\n    JAVA_HOME=\"${JAVA_HOME:-/opt/jdk}\" \\\n    LANG=\"${LANG:-en_US.UTF-8}\" \\\n    LANGUAGE=\"${LANGUAGE:-en_US.UTF-8}\" \\\n    LC_ALL=\"${LC_ALL:-en_US.UTF-8}\" \\\n    MESOSPHERE_PREFIX=\"${MESOSPHERE_PREFIX:-/opt/mesosphere}\" \\\n    MESOS_AUTHENTICATEE=\"com_mesosphere_dcos_ClassicRPCAuthenticatee\" \\\n    MESOS_HTTP_AUTHENTICATEE=\"com_mesosphere_dcos_http_Authenticatee\" \\\n    MESOS_MODULES=\"{\\\"libraries\\\": [{\\\"file\\\": \\\"libdcos_security.so\\\", \\\"modules\\\": [{\\\"name\\\": \\\"com_mesosphere_dcos_ClassicRPCAuthenticatee\\\"}]}]}\" \\\n    MESOS_NATIVE_LIBRARY=\"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libmesos.so\" \\\n    MESOS_NATIVE_JAVA_LIBRARY=\"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libmesos.so\" \\\n    NODE_OPTIONS=\"--max-old-space-size=8192\" \\\n    PATH=\"${JAVA_HOME}/bin:${SPARK_HOME}/bin:${HADOOP_HDFS_HOME}/bin:${CONDA_DIR}/bin:${MESOSPHERE_PREFIX}/bin:${PATH}\" \\\n    SHELL=\"/bin/bash\" \\\n    SPARK_HOME=\"${SPARK_HOME:-/opt/spark}\"\nRUN echo \"deb ${DEBIAN_REPO}/${DISTRO} ${CODENAME} main\" >> /etc/apt/sources.list \\\n && echo \"deb ${DEBIAN_REPO}/${DISTRO}-security ${CODENAME}/updates main\" >> /etc/apt/sources.list \\\n && apt-get update -yq --fix-missing \\\n && apt-get install --no-install-recommends apt-transport-https apt-utils ca-certificates curl dirmngr gnupg2 locales -yq \\\n && echo \"en_US.UTF-8 UTF-8\" >> /etc/locale.gen \\\n && locale-gen \\\n && curl --retry 3 -fsSL https://openresty.org/package/pubkey.gpg -o /tmp/openresty-pubkey.gpg \\\n && apt-key add /tmp/openresty-pubkey.gpg \\\n && rm /tmp/openresty-pubkey.gpg \\\n && echo \"deb ${OPENRESTY_REPO}/${DISTRO} ${CODENAME} openresty\" > /etc/apt/sources.list.d/openresty.list \\\n && apt-get update -yq --fix-missing \\\n && apt-get -yq dist-upgrade \\\n && apt-get install --no-install-recommends bash-completion bzip2 cmake dnsutils ffmpeg g++ gcc git info jq kstart less libaio1 luarocks make man netcat openresty openresty-opm openssh-client procps psmisc rsync runit sudo sssd unzip vim wget zlib1g-dev -yq \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/* \\\n && opm get zmartzone/lua-resty-openidc \\\n && rm -rf ~/.opm/cache \\\n && chmod ugo+rw /usr/local/openresty/nginx/logs \\\n && chmod ugo+rw /usr/local/openresty/nginx \\\n && addgroup --gid 99 nobody \\\n && usermod -u 99 -g 99 nobody \\\n && echo \"nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\" >> /etc/passwd \\\n && usermod -a -G users nobody\nRUN cd /tmp \\\n && apt-key adv --no-tty --keyserver \"${GPG_KEYSERVER}\" --recv-keys \"${TINI_GPG_KEY}\" \\\n && curl --retry 3 -fsSL \"${TINI_URL}/${TINI_VERSION}/tini\" -o /usr/bin/tini \\\n && curl --retry 3 -fsSL -O \"${TINI_URL}/${TINI_VERSION}/tini.asc\" \\\n && export GNUPGHOME=\"$( mktemp -d ;)\" \\\n && gpg --no-tty --keyserver \"${GPG_KEYSERVER}\" --recv-keys \"${TINI_GPG_KEY}\" \\\n && gpg --no-tty --batch --verify tini.asc /usr/bin/tini \\\n && rm -rf \"${GNUPGHOME}\" tini.asc \\\n && chmod +x /usr/bin/tini \\\n && mkdir -p \"${CONDA_DIR}\" \"${HADOOP_HDFS_HOME}\" \"${JAVA_HOME}\" \"${MESOSPHERE_PREFIX}/bin\" \"${SPARK_HOME}\" \\\n && curl --retry 3 -fsSL -O \"${LIBMESOS_BUNDLE_URL}/libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" \\\n && echo \"${LIBMESOS_BUNDLE_SHA256}\" \"libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" | sha256sum -c - \\\n && tar xf \"libmesos-bundle-${LIBMESOS_BUNDLE_VERSION}.tar.gz\" -C \"${MESOSPHERE_PREFIX}\" \\\n && cd \"${MESOSPHERE_PREFIX}/libmesos-bundle/lib\" \\\n && curl --retry 3 -fsSL -O \"${MESOS_MAVEN_URL}/${MESOS_VERSION}/mesos-${MESOS_VERSION}.jar\" \\\n && echo \"${MESOS_JAR_SHA1} mesos-${MESOS_VERSION}.jar\" | sha1sum -c - \\\n && curl --retry 3 -fsSL -O \"${MESOS_MAVEN_URL}/${MESOS_VERSION}/mesos-${MESOS_VERSION}-shaded-protobuf.jar\" \\\n && echo \"${MESOS_PROTOBUF_JAR_SHA1} mesos-${MESOS_VERSION}-shaded-protobuf.jar\" | sha1sum -c - \\\n && cd /tmp \\\n && curl --retry 3 -fsSL -O \"${DCOS_COMMONS_URL}/artifacts/${DCOS_COMMONS_VERSION}/bootstrap.zip\" \\\n && unzip \"bootstrap.zip\" -d \"${MESOSPHERE_PREFIX}/bin/\" \\\n && curl --retry 3 -fsSL \"${DCOS_CLI_URL}/dcos-${DCOS_CLI_VERSION}/dcos\" -o ${MESOSPHERE_PREFIX}/bin/dcos \\\n && chmod +x ${MESOSPHERE_PREFIX}/bin/dcos \\\n && curl --retry 3 -fsSL -O \"${JAVA_URL}/server-jre-${JAVA_VERSION}-linux-x64.tar.gz\" \\\n && tar xf \"server-jre-${JAVA_VERSION}-linux-x64.tar.gz\" -C \"${JAVA_HOME}\" --strip-components=1 \\\n && curl --retry 3 -fsSL -O \"${HADOOP_URL}/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz\" \\\n && echo \"${HADOOP_SHA256}\" \"hadoop-${HADOOP_VERSION}.tar.gz\" | sha256sum -c - \\\n && tar xf \"hadoop-${HADOOP_VERSION}.tar.gz\" -C \"${HADOOP_HDFS_HOME}\" --strip-components=1 \\\n && rm -rf \"${HADOOP_HDFS_HOME}/share/doc\" \\\n && curl --retry 3 -fsSL -O \"${SPARK_DIST_URL}/spark-${SPARK_VERSION}-bin.tgz\" \\\n && echo \"${SPARK_DIST_SHA256}\" \"spark-${SPARK_VERSION}-bin.tgz\" | sha256sum -c - \\\n && tar xf \"spark-${SPARK_VERSION}-bin.tgz\" -C \"${SPARK_HOME}\" --strip-components=1 \\\n && cd \"${SPARK_HOME}/jars\" \\\n && curl --retry 3 -fsSL -O \"${XGBOOST_URL}/${XGBOOST_VERSION}/xgboost4j-${XGBOOST_VERSION}.jar\" \\\n && echo \"${XGBOOST_JAVA_JAR_SHA256}\" \"xgboost4j-${XGBOOST_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${XGBOOST_URL}/${XGBOOST_VERSION}/xgboost4j-spark-${XGBOOST_VERSION}.jar\" \\\n && echo \"${XGBOOST_SPARK_JAR_SHA256}\" \"xgboost4j-spark-${XGBOOST_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_URL}/libtensorflow/libtensorflow-${TENSORFLOW_VERSION}.jar\" \\\n && echo \"${TENSORFLOW_JAR_SHA256}\" \"libtensorflow-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_ECO_URL}/${TENSORFLOW_VERSION}/hadoop-${HADOOP_MAJOR_VERSION}/tensorflow-hadoop-${TENSORFLOW_VERSION}.jar\" \\\n && echo \"${TENSORFLOW_HADOOP_JAR_SHA256}\" \"tensorflow-hadoop-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_ECO_URL}/${TENSORFLOW_VERSION}/spark-${SPARK_MAJOR_VERSION}/spark-tensorflow-connector_2.11-${TENSORFLOW_VERSION}.jar\" \\\n && echo \"${TENSORFLOW_SPARK_JAR_SHA256}\" \"spark-tensorflow-connector_2.11-${TENSORFLOW_VERSION}.jar\" | sha256sum -c - \\\n && cd /tmp \\\n && curl --retry 3 -fsSL -O \"${TENSORFLOW_URL}/libtensorflow/libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" \\\n && echo \"${TENSORFLOW_JNI_SHA256}\" \"libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" | sha256sum -c - \\\n && tar xf \"libtensorflow_jni-${TENSORFLOW_VARIANT}-linux-x86_64-${TENSORFLOW_VERSION}.tar.gz\" \"./libtensorflow_jni.so\" \\\n && mv \"libtensorflow_jni.so\" \"/usr/lib\" \\\n && rm -rf /tmp/*\nRUN echo \"deb [arch=amd64] ${TENSORFLOW_SERVING_APT_URL} stable tensorflow-model-server tensorflow-model-server-universal\" > /etc/apt/sources.list.d/tensorflow-serving.list \\\n && curl --retry 3 -fsSL ${TENSORFLOW_SERVING_APT_URL}/tensorflow-serving.release.pub.gpg | apt-key add - \\\n && apt-get update \\\n && TENSORFLOW_SERVING_DEB=\"$( mktemp ;)\" \\\n && curl --retry 3 -fsSL \"${TENSORFLOW_SERVING_APT_URL}/pool/tensorflow-model-server-${TENSORFLOW_SERVING_VERSION}/t/tensorflow-model-server/tensorflow-model-server_${TENSORFLOW_SERVING_VERSION}_all.deb\" -o \"${TENSORFLOW_SERVING_DEB}\" \\\n && dpkg -i \"${TENSORFLOW_SERVING_DEB}\" \\\n && rm -f \"${TENSORFLOW_SERVING_DEB}\" \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\nCOPY \"${CONDA_ENV_YML}\" \"${CONDA_DIR}/\"\nRUN cd /tmp \\\n && curl --retry 3 -fsSL -O \"${CONDA_URL}/${CONDA_INSTALLER}\" \\\n && echo \"${CONDA_MD5} ${CONDA_INSTALLER}\" | md5sum -c - \\\n && bash \"./${CONDA_INSTALLER}\" -u -b -p \"${CONDA_DIR}\" \\\n && ${CONDA_DIR}/bin/conda update --json --all -yq \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages defaults::conda \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::blas \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::boost \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::gsl \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::numpy \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::openblas \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::scikit-learn \\\n && ${CONDA_DIR}/bin/conda config --env --add pinned_packages conda-forge::scipy \\\n && ${CONDA_DIR}/bin/conda config --system --prepend channels conda-forge \\\n && ${CONDA_DIR}/bin/conda config --system --set auto_update_conda false \\\n && ${CONDA_DIR}/bin/conda config --system --set show_channel_urls true \\\n && ${CONDA_DIR}/bin/conda update --json -yq pip \\\n && ${CONDA_DIR}/bin/conda env update --json -q -f \"${CONDA_DIR}/${CONDA_ENV_YML}\" \\\n && ${CONDA_DIR}/bin/conda remove --force --json -yq openjdk pyqt qt qtconsole \\\n && rm -rf \"${HOME}/.cache/pip\" \"${HOME}/.cache/yarn\" \"${HOME}/.npm/_cacache\" \"${HOME}/.node-gyp\" \\\n && ${CONDA_DIR}/bin/conda clean --json -tipsy \\\n && for dir in .conda/envs bin work; do mkdir -p \"${HOME}/${dir}\" ; done \\\n && rm -rf /tmp/*\nCOPY profile \"/etc/skel/.profile\"\nCOPY profile \"${HOME}/.profile\"\nCOPY bash_profile \"/etc/skel/.bash_profile\"\nCOPY bash_profile \"${HOME}/.bash_profile\"\nCOPY bashrc \"/etc/skel/.bashrc\"\nCOPY bashrc \"${HOME}/.bashrc\"\nRUN cp \"${MESOSPHERE_PREFIX}/libmesos-bundle/lib/libcurl.so.4\" /usr/lib/x86_64-linux-gnu/libcurl.so.4.4.0\nENV SPARK_DIST_CLASSPATH=\"${HADOOP_HDFS_HOME}/etc/hadoop:${HADOOP_HDFS_HOME}/share/hadoop/common/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/common/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/hdfs/*:${HADOOP_HDFS_HOME}/share/hadoop/yarn:${HADOOP_HDFS_HOME}/share/hadoop/yarn/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/yarn/*:${HADOOP_HDFS_HOME}/share/hadoop/mapreduce/lib/*:${HADOOP_HDFS_HOME}/share/hadoop/mapreduce/*:${HADOOP_HDFS_HOME}/share/hadoop/tools/lib/*\" \\\n    HADOOP_CLASSPATH=\"${HADOOP_CLASSPATH}:${HADOOP_HDFS_HOME}/share/hadoop/tools/lib/*\" \\\n    PYTHONPATH=\"${SPARK_HOME}/python:${SPARK_HOME}/python/lib/py4j-0.10.4-src.zip:${PYTHONPATH}\" \\\n    LD_LIBRARY_PATH=\"/usr/lib/x86_64-linux-gnu:${MESOSPHERE_PREFIX}/libmesos-bundle/lib:${JAVA_HOME}/jre/lib/amd64/server:${HADOOP_HDFS_HOME}/lib/native\"\nWORKDIR \"/mnt/mesos/sandbox\"\nCOPY krb5.conf.mustache /etc/\nCOPY hadoop-env.sh \"${HADOOP_HDFS_HOME}/etc/hadoop/\"\nCOPY hadooprc \"${HOME}/.hadooprc\"\nCOPY conf/ \"${SPARK_HOME}/conf/\"\nCOPY nginx /usr/local/openresty/nginx/\nRUN chmod -R ugo+rw \"${SPARK_HOME}/conf\" \\\n && cp \"${CONDA_DIR}/share/examples/krb5/krb5.conf\" /etc \\\n && chmod ugo+rw /etc/krb5.conf \\\n && chmod ugo+rw /usr/local/openresty/nginx/conf/nginx.conf \\\n && chmod ugo+rw /usr/local/openresty/nginx/conf/sites/proxy.conf\nCOPY start-spark-history.sh /usr/local/bin/\nCOPY start-tensorboard.sh /usr/local/bin/\nCOPY start-worker.sh \"/usr/local/bin/\"\nCOPY start-dask-worker.sh \"/usr/local/bin/\"\nCOPY start-ray-worker.sh \"/usr/local/bin/\"\nCOPY ray-worker-health-check.sh \"/usr/local/bin/\"\n","originalDockerfileUglifiedHash":"802db1abf350654a502556fb09dbc86c","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/cd1c7c8101925facf60d21b96828d7dc5d976182.dockerfile"}