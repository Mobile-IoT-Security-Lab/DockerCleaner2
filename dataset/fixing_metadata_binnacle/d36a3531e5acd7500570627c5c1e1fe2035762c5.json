{"seed":435104008,"processedDockerfileHash":"4fa5d3eb90711f9c40d2f58c4423d37e","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-apt-get","have-a-healthcheck","have-a-user"],"processedDockerfile":"#   Need devel version cause we need /usr/include/cudnn.h \n#   for compiling libctc_decoder_with_kenlm.so\nFROM nvidia/cuda:10.0-cudnn7-devel-ubuntu18.04\n#   >> START Install base software\n#   Get basic packages\nRUN apt-get update \\\n && apt-get install --no-install-recommends build-essential curl wget git python3 python3-dev python3-pip python3-wheel python3-numpy libcurl3-dev ca-certificates gcc sox libsox-fmt-mp3 htop nano swig cmake libboost-all-dev zlib1g-dev libbz2-dev liblzma-dev locales pkg-config libsox-dev openjdk-8-jdk bash-completion g++ unzip -y\nRUN ln -s -f /usr/bin/python3 /usr/bin/python\n#   Install NCCL 2.2\nRUN apt-get install --no-install-recommends libnccl2=2.3.7-1+cuda10.0 libnccl-dev=2.3.7-1+cuda10.0 -qq -y --allow-downgrades --allow-change-held-packages\n#   Install Bazel\nRUN curl -LO \"https://github.com/bazelbuild/bazel/releases/download/0.19.2/bazel_0.19.2-linux-x86_64.deb\"\nRUN dpkg -i bazel_*.deb\n#   Install CUDA CLI Tools\nRUN apt-get install --no-install-recommends cuda-command-line-tools-10-0 -qq -y\n#   Install pip\nRUN wget https://bootstrap.pypa.io/get-pip.py \\\n && python3 get-pip.py \\\n && rm get-pip.py\n#   << END Install base software\n#   >> START Configure Tensorflow Build\n#   Clone TensoFlow from Mozilla repo\nRUN git clone https://github.com/mozilla/tensorflow/\nWORKDIR /tensorflow\nRUN git checkout r1.13\n#   GPU Environment Setup\nENV TF_NEED_CUDA=\"1\"\nENV CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\nENV TF_CUDA_VERSION=\"10.0\"\nENV TF_CUDNN_VERSION=\"7\"\nENV CUDNN_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu/\"\nENV TF_CUDA_COMPUTE_CAPABILITIES=\"6.0\"\nENV TF_NCCL_VERSION=\"2.3\"\n#   ENV NCCL_INSTALL_PATH /usr/lib/x86_64-linux-gnu/\n#   Common Environment Setup\nENV TF_BUILD_CONTAINER_TYPE=\"GPU\"\nENV TF_BUILD_OPTIONS=\"OPT\"\nENV TF_BUILD_DISABLE_GCP=\"1\"\nENV TF_BUILD_ENABLE_XLA=\"0\"\nENV TF_BUILD_PYTHON_VERSION=\"PYTHON3\"\nENV TF_BUILD_IS_OPT=\"OPT\"\nENV TF_BUILD_IS_PIP=\"PIP\"\n#   Other Parameters\nENV CC_OPT_FLAGS=\"-mavx -mavx2 -msse4.1 -msse4.2 -mfma\"\nENV TF_NEED_GCP=\"0\"\nENV TF_NEED_HDFS=\"0\"\nENV TF_NEED_JEMALLOC=\"1\"\nENV TF_NEED_OPENCL=\"0\"\nENV TF_CUDA_CLANG=\"0\"\nENV TF_NEED_MKL=\"0\"\nENV TF_ENABLE_XLA=\"0\"\nENV TF_NEED_AWS=\"0\"\nENV TF_NEED_KAFKA=\"0\"\nENV TF_NEED_NGRAPH=\"0\"\nENV TF_DOWNLOAD_CLANG=\"0\"\nENV TF_NEED_TENSORRT=\"0\"\nENV TF_NEED_GDR=\"0\"\nENV TF_NEED_VERBS=\"0\"\nENV TF_NEED_OPENCL_SYCL=\"0\"\nENV PYTHON_BIN_PATH=\"/usr/bin/python3.6\"\nENV PYTHON_LIB_PATH=\"/usr/lib/python3.6/dist-packages\"\n#   << END Configure Tensorflow Build\n#   >> START Configure Bazel\n#   Running bazel inside a `docker build` command causes trouble, cf:\n#     https://github.com/bazelbuild/bazel/issues/134\n#   The easiest solution is to set up a bazelrc file forcing --batch.\nRUN echo \"startup --batch\" >> /etc/bazel.bazelrc\n#   Similarly, we need to workaround sandboxing issues:\n#     https://github.com/bazelbuild/bazel/issues/418\nRUN echo \"build --spawn_strategy=standalone --genrule_strategy=standalone\" >> /etc/bazel.bazelrc\n#   Put cuda libraries to where they are expected to be\nRUN mkdir /usr/local/cuda/lib \\\n && ln -s /usr/lib/x86_64-linux-gnu/libnccl.so.2 /usr/local/cuda/lib/libnccl.so.2 \\\n && ln -s /usr/include/nccl.h /usr/local/cuda/include/nccl.h \\\n && ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 \\\n && ln -s /usr/include/cudnn.h /usr/local/cuda/include/cudnn.h\n#   Set library paths\nENV LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu/:/usr/local/cuda/lib64/stubs/\"\n#   << END Configure Bazel\n#   Copy DeepSpeech repo contents to container's /DeepSpeech\nCOPY . /DeepSpeech/\n#   Alternative clone from GitHub \n#   RUN apt-get update && apt-get install -y git-lfs \n#   WORKDIR /\n#   RUN git clone https://github.com/mozilla/DeepSpeech.git\nWORKDIR /DeepSpeech\nRUN pip3 --no-cache-dir install -r requirements.txt\n#   Link DeepSpeech native_client libs to tf folder\nRUN ln -s /DeepSpeech/native_client /tensorflow\n#   >> START Build and bind\nWORKDIR /tensorflow\n#   Fix for not found script https://github.com/tensorflow/tensorflow/issues/471\nRUN ./configure\n#   Using CPU optimizations:\n#   -mtune=generic -march=x86-64 -msse -msse2 -msse3 -msse4.1 -msse4.2 -mavx.\n#   Adding --config=cuda flag to build using CUDA.\n#   passing LD_LIBRARY_PATH is required cause Bazel doesn't pickup it from environment\n#   Build DeepSpeech\nRUN bazel build --config=monolithic --config=cuda -c opt --copt=-O3 --copt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --copt=-mtune=generic --copt=-march=x86-64 --copt=-msse --copt=-msse2 --copt=-msse3 --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie --verbose_failures --action_env=LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\n#  ##\n#  ## Using TensorFlow upstream should work\n#  ##\n#   # Build TF pip package\n#   RUN bazel build --config=opt --config=cuda --copt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --copt=-mtune=generic --copt=-march=x86-64 --copt=-msse --copt=-msse2 --copt=-msse3 --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx //tensorflow/tools/pip_package:build_pip_package --verbose_failures --action_env=LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\n#\n#   # Build wheel\n#   RUN bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\n#\n#   # Install tensorflow from our custom wheel\n#   RUN pip3 install /tmp/tensorflow_pkg/*.whl\n#   Copy built libs to /DeepSpeech/native_client\nRUN cp /tensorflow/bazel-bin/native_client/generate_trie /DeepSpeech/native_client/ \\\n && cp /tensorflow/bazel-bin/native_client/libdeepspeech.so /DeepSpeech/native_client/\n#   Install TensorFlow\nWORKDIR /DeepSpeech/\nRUN pip3 install tensorflow-gpu==1.13.1\n#   Make DeepSpeech and install Python bindings\nENV TFDIR=\"/tensorflow\"\nWORKDIR /DeepSpeech/native_client\nRUN make deepspeech\nWORKDIR /DeepSpeech/native_client/python\nRUN make bindings\nRUN pip3 install dist/deepspeech*\nWORKDIR /DeepSpeech/native_client/ctcdecode\nRUN make\nRUN pip3 install dist/*.whl\n#   << END Build and bind\n#   Allow Python printing utf-8\nENV PYTHONIOENCODING=\"UTF-8\"\n#   Build KenLM in /DeepSpeech/native_client/kenlm folder\nWORKDIR /DeepSpeech/native_client\nRUN rm -rf kenlm \\\n && git clone --depth 1 https://github.com/kpu/kenlm \\\n && cd kenlm \\\n && mkdir -p build \\\n && cd build \\\n && cmake .. \\\n && make -j 4\n#   Done\nWORKDIR /DeepSpeech\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"#  Need devel version cause we need /usr/include/cudnn.h \n#  for compiling libctc_decoder_with_kenlm.so\nFROM nvidia/cuda:10.0-cudnn7-devel-ubuntu18.04\n#  >> START Install base software\n#  Get basic packages\nRUN apt-get update \\\n && apt-get install --no-install-recommends build-essential curl wget git python3 python3-dev python3-pip python3-wheel python3-numpy libcurl3-dev ca-certificates gcc sox libsox-fmt-mp3 htop nano swig cmake libboost-all-dev zlib1g-dev libbz2-dev liblzma-dev locales pkg-config libsox-dev openjdk-8-jdk bash-completion g++ unzip -y\nRUN ln -s -f /usr/bin/python3 /usr/bin/python\n#  Install NCCL 2.2\nRUN apt-get install libnccl2=2.3.7-1+cuda10.0 libnccl-dev=2.3.7-1+cuda10.0 -qq -y --allow-downgrades --allow-change-held-packages\n#  Install Bazel\nRUN curl -LO \"https://github.com/bazelbuild/bazel/releases/download/0.19.2/bazel_0.19.2-linux-x86_64.deb\"\nRUN dpkg -i bazel_*.deb\n#  Install CUDA CLI Tools\nRUN apt-get install cuda-command-line-tools-10-0 -qq -y\n#  Install pip\nRUN wget https://bootstrap.pypa.io/get-pip.py \\\n && python3 get-pip.py \\\n && rm get-pip.py\n#  << END Install base software\n#  >> START Configure Tensorflow Build\n#  Clone TensoFlow from Mozilla repo\nRUN git clone https://github.com/mozilla/tensorflow/\nWORKDIR /tensorflow\nRUN git checkout r1.13\n#  GPU Environment Setup\nENV TF_NEED_CUDA=\"1\"\nENV CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\nENV TF_CUDA_VERSION=\"10.0\"\nENV TF_CUDNN_VERSION=\"7\"\nENV CUDNN_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu/\"\nENV TF_CUDA_COMPUTE_CAPABILITIES=\"6.0\"\nENV TF_NCCL_VERSION=\"2.3\"\n#  ENV NCCL_INSTALL_PATH /usr/lib/x86_64-linux-gnu/\n#  Common Environment Setup\nENV TF_BUILD_CONTAINER_TYPE=\"GPU\"\nENV TF_BUILD_OPTIONS=\"OPT\"\nENV TF_BUILD_DISABLE_GCP=\"1\"\nENV TF_BUILD_ENABLE_XLA=\"0\"\nENV TF_BUILD_PYTHON_VERSION=\"PYTHON3\"\nENV TF_BUILD_IS_OPT=\"OPT\"\nENV TF_BUILD_IS_PIP=\"PIP\"\n#  Other Parameters\nENV CC_OPT_FLAGS=\"-mavx -mavx2 -msse4.1 -msse4.2 -mfma\"\nENV TF_NEED_GCP=\"0\"\nENV TF_NEED_HDFS=\"0\"\nENV TF_NEED_JEMALLOC=\"1\"\nENV TF_NEED_OPENCL=\"0\"\nENV TF_CUDA_CLANG=\"0\"\nENV TF_NEED_MKL=\"0\"\nENV TF_ENABLE_XLA=\"0\"\nENV TF_NEED_AWS=\"0\"\nENV TF_NEED_KAFKA=\"0\"\nENV TF_NEED_NGRAPH=\"0\"\nENV TF_DOWNLOAD_CLANG=\"0\"\nENV TF_NEED_TENSORRT=\"0\"\nENV TF_NEED_GDR=\"0\"\nENV TF_NEED_VERBS=\"0\"\nENV TF_NEED_OPENCL_SYCL=\"0\"\nENV PYTHON_BIN_PATH=\"/usr/bin/python3.6\"\nENV PYTHON_LIB_PATH=\"/usr/lib/python3.6/dist-packages\"\n#  << END Configure Tensorflow Build\n#  >> START Configure Bazel\n#  Running bazel inside a `docker build` command causes trouble, cf:\n#    https://github.com/bazelbuild/bazel/issues/134\n#  The easiest solution is to set up a bazelrc file forcing --batch.\nRUN echo \"startup --batch\" >> /etc/bazel.bazelrc\n#  Similarly, we need to workaround sandboxing issues:\n#    https://github.com/bazelbuild/bazel/issues/418\nRUN echo \"build --spawn_strategy=standalone --genrule_strategy=standalone\" >> /etc/bazel.bazelrc\n#  Put cuda libraries to where they are expected to be\nRUN mkdir /usr/local/cuda/lib \\\n && ln -s /usr/lib/x86_64-linux-gnu/libnccl.so.2 /usr/local/cuda/lib/libnccl.so.2 \\\n && ln -s /usr/include/nccl.h /usr/local/cuda/include/nccl.h \\\n && ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 \\\n && ln -s /usr/include/cudnn.h /usr/local/cuda/include/cudnn.h\n#  Set library paths\nENV LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu/:/usr/local/cuda/lib64/stubs/\"\n#  << END Configure Bazel\n#  Copy DeepSpeech repo contents to container's /DeepSpeech\nCOPY . /DeepSpeech/\n#  Alternative clone from GitHub \n#  RUN apt-get update && apt-get install -y git-lfs \n#  WORKDIR /\n#  RUN git clone https://github.com/mozilla/DeepSpeech.git\nWORKDIR /DeepSpeech\nRUN pip3 --no-cache-dir install -r requirements.txt\n#  Link DeepSpeech native_client libs to tf folder\nRUN ln -s /DeepSpeech/native_client /tensorflow\n#  >> START Build and bind\nWORKDIR /tensorflow\n#  Fix for not found script https://github.com/tensorflow/tensorflow/issues/471\nRUN ./configure\n#  Using CPU optimizations:\n#  -mtune=generic -march=x86-64 -msse -msse2 -msse3 -msse4.1 -msse4.2 -mavx.\n#  Adding --config=cuda flag to build using CUDA.\n#  passing LD_LIBRARY_PATH is required cause Bazel doesn't pickup it from environment\n#  Build DeepSpeech\nRUN bazel build --config=monolithic --config=cuda -c opt --copt=-O3 --copt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --copt=-mtune=generic --copt=-march=x86-64 --copt=-msse --copt=-msse2 --copt=-msse3 --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie --verbose_failures --action_env=LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\n# ##\n# ## Using TensorFlow upstream should work\n# ##\n#  # Build TF pip package\n#  RUN bazel build --config=opt --config=cuda --copt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --copt=-mtune=generic --copt=-march=x86-64 --copt=-msse --copt=-msse2 --copt=-msse3 --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx //tensorflow/tools/pip_package:build_pip_package --verbose_failures --action_env=LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\n#\n#  # Build wheel\n#  RUN bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\n#\n#  # Install tensorflow from our custom wheel\n#  RUN pip3 install /tmp/tensorflow_pkg/*.whl\n#  Copy built libs to /DeepSpeech/native_client\nRUN cp /tensorflow/bazel-bin/native_client/generate_trie /DeepSpeech/native_client/ \\\n && cp /tensorflow/bazel-bin/native_client/libdeepspeech.so /DeepSpeech/native_client/\n#  Install TensorFlow\nWORKDIR /DeepSpeech/\nRUN pip3 install tensorflow-gpu==1.13.1\n#  Make DeepSpeech and install Python bindings\nENV TFDIR=\"/tensorflow\"\nWORKDIR /DeepSpeech/native_client\nRUN make deepspeech\nWORKDIR /DeepSpeech/native_client/python\nRUN make bindings\nRUN pip3 install dist/deepspeech*\nWORKDIR /DeepSpeech/native_client/ctcdecode\nRUN make\nRUN pip3 install dist/*.whl\n#  << END Build and bind\n#  Allow Python printing utf-8\nENV PYTHONIOENCODING=\"UTF-8\"\n#  Build KenLM in /DeepSpeech/native_client/kenlm folder\nWORKDIR /DeepSpeech/native_client\nRUN rm -rf kenlm \\\n && git clone --depth 1 https://github.com/kpu/kenlm \\\n && cd kenlm \\\n && mkdir -p build \\\n && cd build \\\n && cmake .. \\\n && make -j 4\n#  Done\nWORKDIR /DeepSpeech\n","injectedSmells":[],"originalDockerfileHash":"fd1b69ab4f40e23d55641e3f19ef2908","successfullyInjectedSmells":[],"originalDockerfileUglified":"#   Need devel version cause we need /usr/include/cudnn.h \n#   for compiling libctc_decoder_with_kenlm.so\nFROM nvidia/cuda:10.0-cudnn7-devel-ubuntu18.04\n#   >> START Install base software\n#   Get basic packages\nRUN apt-get update \\\n && apt-get install --no-install-recommends build-essential curl wget git python3 python3-dev python3-pip python3-wheel python3-numpy libcurl3-dev ca-certificates gcc sox libsox-fmt-mp3 htop nano swig cmake libboost-all-dev zlib1g-dev libbz2-dev liblzma-dev locales pkg-config libsox-dev openjdk-8-jdk bash-completion g++ unzip -y\nRUN ln -s -f /usr/bin/python3 /usr/bin/python\n#   Install NCCL 2.2\nRUN apt-get install libnccl2=2.3.7-1+cuda10.0 libnccl-dev=2.3.7-1+cuda10.0 -qq -y --allow-downgrades --allow-change-held-packages\n#   Install Bazel\nRUN curl -LO \"https://github.com/bazelbuild/bazel/releases/download/0.19.2/bazel_0.19.2-linux-x86_64.deb\"\nRUN dpkg -i bazel_*.deb\n#   Install CUDA CLI Tools\nRUN apt-get install cuda-command-line-tools-10-0 -qq -y\n#   Install pip\nRUN wget https://bootstrap.pypa.io/get-pip.py \\\n && python3 get-pip.py \\\n && rm get-pip.py\n#   << END Install base software\n#   >> START Configure Tensorflow Build\n#   Clone TensoFlow from Mozilla repo\nRUN git clone https://github.com/mozilla/tensorflow/\nWORKDIR /tensorflow\nRUN git checkout r1.13\n#   GPU Environment Setup\nENV TF_NEED_CUDA=\"1\"\nENV CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\nENV TF_CUDA_VERSION=\"10.0\"\nENV TF_CUDNN_VERSION=\"7\"\nENV CUDNN_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu/\"\nENV TF_CUDA_COMPUTE_CAPABILITIES=\"6.0\"\nENV TF_NCCL_VERSION=\"2.3\"\n#   ENV NCCL_INSTALL_PATH /usr/lib/x86_64-linux-gnu/\n#   Common Environment Setup\nENV TF_BUILD_CONTAINER_TYPE=\"GPU\"\nENV TF_BUILD_OPTIONS=\"OPT\"\nENV TF_BUILD_DISABLE_GCP=\"1\"\nENV TF_BUILD_ENABLE_XLA=\"0\"\nENV TF_BUILD_PYTHON_VERSION=\"PYTHON3\"\nENV TF_BUILD_IS_OPT=\"OPT\"\nENV TF_BUILD_IS_PIP=\"PIP\"\n#   Other Parameters\nENV CC_OPT_FLAGS=\"-mavx -mavx2 -msse4.1 -msse4.2 -mfma\"\nENV TF_NEED_GCP=\"0\"\nENV TF_NEED_HDFS=\"0\"\nENV TF_NEED_JEMALLOC=\"1\"\nENV TF_NEED_OPENCL=\"0\"\nENV TF_CUDA_CLANG=\"0\"\nENV TF_NEED_MKL=\"0\"\nENV TF_ENABLE_XLA=\"0\"\nENV TF_NEED_AWS=\"0\"\nENV TF_NEED_KAFKA=\"0\"\nENV TF_NEED_NGRAPH=\"0\"\nENV TF_DOWNLOAD_CLANG=\"0\"\nENV TF_NEED_TENSORRT=\"0\"\nENV TF_NEED_GDR=\"0\"\nENV TF_NEED_VERBS=\"0\"\nENV TF_NEED_OPENCL_SYCL=\"0\"\nENV PYTHON_BIN_PATH=\"/usr/bin/python3.6\"\nENV PYTHON_LIB_PATH=\"/usr/lib/python3.6/dist-packages\"\n#   << END Configure Tensorflow Build\n#   >> START Configure Bazel\n#   Running bazel inside a `docker build` command causes trouble, cf:\n#     https://github.com/bazelbuild/bazel/issues/134\n#   The easiest solution is to set up a bazelrc file forcing --batch.\nRUN echo \"startup --batch\" >> /etc/bazel.bazelrc\n#   Similarly, we need to workaround sandboxing issues:\n#     https://github.com/bazelbuild/bazel/issues/418\nRUN echo \"build --spawn_strategy=standalone --genrule_strategy=standalone\" >> /etc/bazel.bazelrc\n#   Put cuda libraries to where they are expected to be\nRUN mkdir /usr/local/cuda/lib \\\n && ln -s /usr/lib/x86_64-linux-gnu/libnccl.so.2 /usr/local/cuda/lib/libnccl.so.2 \\\n && ln -s /usr/include/nccl.h /usr/local/cuda/include/nccl.h \\\n && ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 \\\n && ln -s /usr/include/cudnn.h /usr/local/cuda/include/cudnn.h\n#   Set library paths\nENV LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/lib/x86_64-linux-gnu/:/usr/local/cuda/lib64/stubs/\"\n#   << END Configure Bazel\n#   Copy DeepSpeech repo contents to container's /DeepSpeech\nCOPY . /DeepSpeech/\n#   Alternative clone from GitHub \n#   RUN apt-get update && apt-get install -y git-lfs \n#   WORKDIR /\n#   RUN git clone https://github.com/mozilla/DeepSpeech.git\nWORKDIR /DeepSpeech\nRUN pip3 --no-cache-dir install -r requirements.txt\n#   Link DeepSpeech native_client libs to tf folder\nRUN ln -s /DeepSpeech/native_client /tensorflow\n#   >> START Build and bind\nWORKDIR /tensorflow\n#   Fix for not found script https://github.com/tensorflow/tensorflow/issues/471\nRUN ./configure\n#   Using CPU optimizations:\n#   -mtune=generic -march=x86-64 -msse -msse2 -msse3 -msse4.1 -msse4.2 -mavx.\n#   Adding --config=cuda flag to build using CUDA.\n#   passing LD_LIBRARY_PATH is required cause Bazel doesn't pickup it from environment\n#   Build DeepSpeech\nRUN bazel build --config=monolithic --config=cuda -c opt --copt=-O3 --copt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --copt=-mtune=generic --copt=-march=x86-64 --copt=-msse --copt=-msse2 --copt=-msse3 --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-fvisibility=hidden //native_client:libdeepspeech.so //native_client:generate_trie --verbose_failures --action_env=LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\n#  ##\n#  ## Using TensorFlow upstream should work\n#  ##\n#   # Build TF pip package\n#   RUN bazel build --config=opt --config=cuda --copt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --copt=-mtune=generic --copt=-march=x86-64 --copt=-msse --copt=-msse2 --copt=-msse3 --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx //tensorflow/tools/pip_package:build_pip_package --verbose_failures --action_env=LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\n#\n#   # Build wheel\n#   RUN bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\n#\n#   # Install tensorflow from our custom wheel\n#   RUN pip3 install /tmp/tensorflow_pkg/*.whl\n#   Copy built libs to /DeepSpeech/native_client\nRUN cp /tensorflow/bazel-bin/native_client/generate_trie /DeepSpeech/native_client/ \\\n && cp /tensorflow/bazel-bin/native_client/libdeepspeech.so /DeepSpeech/native_client/\n#   Install TensorFlow\nWORKDIR /DeepSpeech/\nRUN pip3 install tensorflow-gpu==1.13.1\n#   Make DeepSpeech and install Python bindings\nENV TFDIR=\"/tensorflow\"\nWORKDIR /DeepSpeech/native_client\nRUN make deepspeech\nWORKDIR /DeepSpeech/native_client/python\nRUN make bindings\nRUN pip3 install dist/deepspeech*\nWORKDIR /DeepSpeech/native_client/ctcdecode\nRUN make\nRUN pip3 install dist/*.whl\n#   << END Build and bind\n#   Allow Python printing utf-8\nENV PYTHONIOENCODING=\"UTF-8\"\n#   Build KenLM in /DeepSpeech/native_client/kenlm folder\nWORKDIR /DeepSpeech/native_client\nRUN rm -rf kenlm \\\n && git clone --depth 1 https://github.com/kpu/kenlm \\\n && cd kenlm \\\n && mkdir -p build \\\n && cd build \\\n && cmake .. \\\n && make -j 4\n#   Done\nWORKDIR /DeepSpeech\n","originalDockerfileUglifiedHash":"b6ce15de8b735b948ad9e2d35bf4fccf","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/d36a3531e5acd7500570627c5c1e1fe2035762c5.dockerfile"}