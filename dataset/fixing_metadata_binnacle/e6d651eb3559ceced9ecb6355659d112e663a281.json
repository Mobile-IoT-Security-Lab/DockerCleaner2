{"seed":126357759,"processedDockerfileHash":"8bfe85bfb5c1d75b7d824d3eea9db552","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-copy-instead-of-add","have-a-healthcheck","have-a-user"],"processedDockerfile":"FROM centos:7\nMAINTAINER Humble Chirammal hchiramm@redhat.com Saravanakumar Arumugam sarumuga@redhat.com\nENV container=\"docker\"\nENV ARCH=\"\\\"x86_64\\\"\"\nLABEL architecture=\"$ARCH\" \\\n      name=\"gluster/gluster-centos\" \\\n      version=\"latest\" \\\n      vendor=\"CentOS Community\" \\\n      summary=\"This image has a running glusterfs service (CentOS 7 + latest Gluster)\" \\\n      io.k8s.display-name=\"Gluster server based on CentOS 7\" \\\n      io.k8s.description=\"Gluster Image is based on CentOS Image which is a scalable network filesystem. Using common off-the-shelf hardware, you can create large, distributed storage solutions for media streaming, data analysis, and other data- and bandwidth-intensive tasks.\" \\\n      description=\"Gluster Image is based on CentOS Image which is a scalable network filesystem. Using common off-the-shelf hardware, you can create large, distributed storage solutions for media streaming, data analysis, and other data- and bandwidth-intensive tasks.\" \\\n      io.openshift.tags=\"gluster,glusterfs,glusterfs-centos\"\nRUN yum --setopt=tsflags=nodocs -y update \\\n && yum install -y centos-release-gluster \\\n && yum clean all \\\n && (cd /lib/systemd/system/sysinit.target.wants/ ;for i in *; do [ $i == systemd-tmpfiles-setup.service ] || rm -f $i ; done ) \\\n && rm -f /lib/systemd/system/multi-user.target.wants/* \\\n && rm -f /etc/systemd/system/*.wants/* \\\n && rm -f /lib/systemd/system/local-fs.target.wants/* \\\n && rm -f /lib/systemd/system/sockets.target.wants/*udev* \\\n && rm -f /lib/systemd/system/sockets.target.wants/*initctl* \\\n && rm -f /lib/systemd/system/basic.target.wants/* \\\n && rm -f /lib/systemd/system/anaconda.target.wants/* \\\n && yum --setopt=tsflags=nodocs -y install nfs-utils \\\n && yum --setopt=tsflags=nodocs -y install attr \\\n && yum --setopt=tsflags=nodocs -y install iputils \\\n && yum --setopt=tsflags=nodocs -y install iproute \\\n && yum --setopt=tsflags=nodocs -y install openssh-server \\\n && yum --setopt=tsflags=nodocs -y install openssh-clients \\\n && yum --setopt=tsflags=nodocs -y install rsync \\\n && yum --setopt=tsflags=nodocs -y install tar \\\n && yum --setopt=tsflags=nodocs -y install cronie \\\n && yum --setopt=tsflags=nodocs -y install sudo \\\n && yum --setopt=tsflags=nodocs -y install xfsprogs \\\n && yum --setopt=tsflags=nodocs -y install glusterfs \\\n && yum --setopt=tsflags=nodocs -y install glusterfs-server \\\n && yum --setopt=tsflags=nodocs -y install glusterfs-rdma \\\n && yum --setopt=tsflags=nodocs -y install gluster-block \\\n && yum --setopt=tsflags=nodocs -y install glusterfs-geo-replication \\\n && yum clean all \\\n && sed -i '/Defaults requiretty/c\\#Defaults requiretty' /etc/sudoers \\\n && sed -i '/Port 22/c\\Port 2222' /etc/ssh/sshd_config \\\n && sed -i 's/Requires\\=rpcbind\\.service//g' /usr/lib/systemd/system/glusterd.service \\\n && sed -i 's/rpcbind\\.service/gluster-setup\\.service/g' /usr/lib/systemd/system/glusterd.service \\\n && sed -i 's/rpcbind\\.service//g' /usr/lib/systemd/system/gluster-blockd.service \\\n && mkdir -p /etc/glusterfs_bkp /var/lib/glusterd_bkp /var/log/glusterfs_bkp \\\n && cp -r /etc/glusterfs/* /etc/glusterfs_bkp \\\n && cp -r /var/lib/glusterd/* /var/lib/glusterd_bkp \\\n && cp -r /var/log/glusterfs/* /var/log/glusterfs_bkp \\\n && mkdir -p /var/log/core\n#   downgrade lvm2 because of regression reported in https://bugzilla.redhat.com/1676612\n#   once the bug is fixed, disable obtain_device_list_from_udev in lvm.conf\nRUN true \\\n && yum -y downgrade device-mapper-libs-1.02.149-10.el7_6.2 device-mapper-1.02.149-10.el7_6.2 device-mapper-event-libs-1.02.149-10.el7_6.2 device-mapper-event-1.02.149-10.el7_6.2 device-mapper-persistent-data-0.7.0-0.1.rc6.el7_4.1 lvm2-libs-2.02.180-10.el7_6.2 lvm2-2.02.180-10.el7_6.2 \\\n && yum -y clean all \\\n && true\n#   do not run udev (if needed, bind-mount /run/udev instead?)\nRUN true \\\n && systemctl mask systemd-udev-trigger.service \\\n && systemctl mask systemd-udevd.service \\\n && systemctl mask systemd-udevd.socket \\\n && systemctl mask systemd-udevd-kernel.socket \\\n && true\n#   use lvmetad from the host, dont run it in the container\n#   don't wait for udev to manage the /dev entries, disable udev_sync, udev_rules in lvm.conf\nVOLUME [ \"/run/lvm\" ]\nRUN true \\\n && systemctl mask lvm2-lvmetad.service \\\n && systemctl mask lvm2-lvmetad.socket \\\n && sed -i 's/^\\sudev_rules\\s*=\\s*1/udev_rules = 0/' /etc/lvm/lvm.conf \\\n && sed -i 's/^\\sudev_sync\\s*=\\s*1/udev_sync= 0/' /etc/lvm/lvm.conf \\\n && sed -i 's/^\\sobtain_device_list_from_udev\\s*=\\s*1/obtain_device_list_from_udev = 0/' /etc/lvm/lvm.conf \\\n && true\n#   prevent dmeventd from running in the container, it may cause conflicts with\n#   the service running on the host\n#   monitoring of activated LVs can not be done inside the container\nRUN true \\\n && systemctl mask dm-event.service \\\n && systemctl disable dm-event.socket \\\n && systemctl mask dm-event.socket \\\n && systemctl disable lvm2-monitor.service \\\n && systemctl mask lvm2-monitor.service \\\n && sed -i 's/^\\smonitoring\\s*=\\s*1/monitoring = 0/' /etc/lvm/lvm.conf \\\n && true\nVOLUME [ \"/sys/fs/cgroup\" ]\nCOPY gluster-fake-disk.service /etc/systemd/system/gluster-fake-disk.service\nCOPY fake-disk.sh /usr/libexec/gluster/fake-disk.sh\nCOPY gluster-setup.service /etc/systemd/system/gluster-setup.service\nCOPY gluster-setup.sh /usr/sbin/gluster-setup.sh\nCOPY gluster-block-setup.service /etc/systemd/system/gluster-block-setup.service\nCOPY gluster-block-setup.sh /usr/sbin/gluster-block-setup.sh\nCOPY update-params.sh /usr/local/bin/update-params.sh\nCOPY status-probe.sh /usr/local/bin/status-probe.sh\nCOPY tcmu-runner-params /etc/sysconfig/tcmu-runner-params\nCOPY gluster-check-diskspace.service /etc/systemd/system/gluster-check-diskspace.service\nCOPY check_diskspace.sh /usr/local/bin/check_diskspace.sh\nRUN chmod 644 /etc/systemd/system/gluster-setup.service \\\n && chmod 644 /etc/systemd/system/gluster-check-diskspace.service \\\n && chmod 755 /usr/libexec/gluster/fake-disk.sh \\\n && chmod 500 /usr/sbin/gluster-setup.sh \\\n && chmod 644 /etc/systemd/system/gluster-block-setup.service \\\n && chmod 500 /usr/sbin/gluster-block-setup.sh \\\n && chmod +x /usr/local/bin/update-params.sh \\\n && chmod +x /usr/local/bin/status-probe.sh \\\n && chmod +x /usr/local/bin/check_diskspace.sh \\\n && systemctl disable nfs-server.service \\\n && systemctl mask getty.target \\\n && systemctl enable gluster-fake-disk.service \\\n && systemctl enable gluster-setup.service \\\n && systemctl enable gluster-block-setup.service \\\n && systemctl enable gluster-blockd.service \\\n && systemctl enable glusterd.service \\\n && systemctl enable gluster-check-diskspace.service\nEXPOSE 2222/tcp 111/tcp 245/tcp 443/tcp 24007/tcp 2049/tcp 8080/tcp 6010/tcp 6011/tcp 6012/tcp 38465/tcp 38466/tcp 38468/tcp 38469/tcp 49152/tcp 49153/tcp 49154/tcp 49156/tcp 49157/tcp 49158/tcp 49159/tcp 49160/tcp 49161/tcp 49162/tcp\nENTRYPOINT [\"/usr/local/bin/update-params.sh\"]\nCMD [\"/usr/sbin/init\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"FROM centos:7\nMAINTAINER Humble Chirammal hchiramm@redhat.com Saravanakumar Arumugam sarumuga@redhat.com\nENV container=\"docker\"\nENV ARCH=\"\\\"x86_64\\\"\"\nLABEL architecture=\"$ARCH\" \\\n      name=\"gluster/gluster-centos\" \\\n      version=\"latest\" \\\n      vendor=\"CentOS Community\" \\\n      summary=\"This image has a running glusterfs service (CentOS 7 + latest Gluster)\" \\\n      io.k8s.display-name=\"Gluster server based on CentOS 7\" \\\n      io.k8s.description=\"Gluster Image is based on CentOS Image which is a scalable network filesystem. Using common off-the-shelf hardware, you can create large, distributed storage solutions for media streaming, data analysis, and other data- and bandwidth-intensive tasks.\" \\\n      description=\"Gluster Image is based on CentOS Image which is a scalable network filesystem. Using common off-the-shelf hardware, you can create large, distributed storage solutions for media streaming, data analysis, and other data- and bandwidth-intensive tasks.\" \\\n      io.openshift.tags=\"gluster,glusterfs,glusterfs-centos\"\nRUN yum --setopt=tsflags=nodocs -y update \\\n && yum install -y centos-release-gluster \\\n && yum clean all \\\n && (cd /lib/systemd/system/sysinit.target.wants/ ;for i in *; do [ $i == systemd-tmpfiles-setup.service ] || rm -f $i ; done ) \\\n && rm -f /lib/systemd/system/multi-user.target.wants/* \\\n && rm -f /etc/systemd/system/*.wants/* \\\n && rm -f /lib/systemd/system/local-fs.target.wants/* \\\n && rm -f /lib/systemd/system/sockets.target.wants/*udev* \\\n && rm -f /lib/systemd/system/sockets.target.wants/*initctl* \\\n && rm -f /lib/systemd/system/basic.target.wants/* \\\n && rm -f /lib/systemd/system/anaconda.target.wants/* \\\n && yum --setopt=tsflags=nodocs -y install nfs-utils \\\n && yum --setopt=tsflags=nodocs -y install attr \\\n && yum --setopt=tsflags=nodocs -y install iputils \\\n && yum --setopt=tsflags=nodocs -y install iproute \\\n && yum --setopt=tsflags=nodocs -y install openssh-server \\\n && yum --setopt=tsflags=nodocs -y install openssh-clients \\\n && yum --setopt=tsflags=nodocs -y install rsync \\\n && yum --setopt=tsflags=nodocs -y install tar \\\n && yum --setopt=tsflags=nodocs -y install cronie \\\n && yum --setopt=tsflags=nodocs -y install sudo \\\n && yum --setopt=tsflags=nodocs -y install xfsprogs \\\n && yum --setopt=tsflags=nodocs -y install glusterfs \\\n && yum --setopt=tsflags=nodocs -y install glusterfs-server \\\n && yum --setopt=tsflags=nodocs -y install glusterfs-rdma \\\n && yum --setopt=tsflags=nodocs -y install gluster-block \\\n && yum --setopt=tsflags=nodocs -y install glusterfs-geo-replication \\\n && yum clean all \\\n && sed -i '/Defaults requiretty/c\\#Defaults requiretty' /etc/sudoers \\\n && sed -i '/Port 22/c\\Port 2222' /etc/ssh/sshd_config \\\n && sed -i 's/Requires\\=rpcbind\\.service//g' /usr/lib/systemd/system/glusterd.service \\\n && sed -i 's/rpcbind\\.service/gluster-setup\\.service/g' /usr/lib/systemd/system/glusterd.service \\\n && sed -i 's/rpcbind\\.service//g' /usr/lib/systemd/system/gluster-blockd.service \\\n && mkdir -p /etc/glusterfs_bkp /var/lib/glusterd_bkp /var/log/glusterfs_bkp \\\n && cp -r /etc/glusterfs/* /etc/glusterfs_bkp \\\n && cp -r /var/lib/glusterd/* /var/lib/glusterd_bkp \\\n && cp -r /var/log/glusterfs/* /var/log/glusterfs_bkp \\\n && mkdir -p /var/log/core\n#  downgrade lvm2 because of regression reported in https://bugzilla.redhat.com/1676612\n#  once the bug is fixed, disable obtain_device_list_from_udev in lvm.conf\nRUN true \\\n && yum -y downgrade device-mapper-libs-1.02.149-10.el7_6.2 device-mapper-1.02.149-10.el7_6.2 device-mapper-event-libs-1.02.149-10.el7_6.2 device-mapper-event-1.02.149-10.el7_6.2 device-mapper-persistent-data-0.7.0-0.1.rc6.el7_4.1 lvm2-libs-2.02.180-10.el7_6.2 lvm2-2.02.180-10.el7_6.2 \\\n && yum -y clean all \\\n && true\n#  do not run udev (if needed, bind-mount /run/udev instead?)\nRUN true \\\n && systemctl mask systemd-udev-trigger.service \\\n && systemctl mask systemd-udevd.service \\\n && systemctl mask systemd-udevd.socket \\\n && systemctl mask systemd-udevd-kernel.socket \\\n && true\n#  use lvmetad from the host, dont run it in the container\n#  don't wait for udev to manage the /dev entries, disable udev_sync, udev_rules in lvm.conf\nVOLUME [ \"/run/lvm\" ]\nRUN true \\\n && systemctl mask lvm2-lvmetad.service \\\n && systemctl mask lvm2-lvmetad.socket \\\n && sed -i 's/^\\sudev_rules\\s*=\\s*1/udev_rules = 0/' /etc/lvm/lvm.conf \\\n && sed -i 's/^\\sudev_sync\\s*=\\s*1/udev_sync= 0/' /etc/lvm/lvm.conf \\\n && sed -i 's/^\\sobtain_device_list_from_udev\\s*=\\s*1/obtain_device_list_from_udev = 0/' /etc/lvm/lvm.conf \\\n && true\n#  prevent dmeventd from running in the container, it may cause conflicts with\n#  the service running on the host\n#  monitoring of activated LVs can not be done inside the container\nRUN true \\\n && systemctl mask dm-event.service \\\n && systemctl disable dm-event.socket \\\n && systemctl mask dm-event.socket \\\n && systemctl disable lvm2-monitor.service \\\n && systemctl mask lvm2-monitor.service \\\n && sed -i 's/^\\smonitoring\\s*=\\s*1/monitoring = 0/' /etc/lvm/lvm.conf \\\n && true\nVOLUME [ \"/sys/fs/cgroup\" ]\nADD gluster-fake-disk.service /etc/systemd/system/gluster-fake-disk.service\nADD fake-disk.sh /usr/libexec/gluster/fake-disk.sh\nADD gluster-setup.service /etc/systemd/system/gluster-setup.service\nADD gluster-setup.sh /usr/sbin/gluster-setup.sh\nADD gluster-block-setup.service /etc/systemd/system/gluster-block-setup.service\nADD gluster-block-setup.sh /usr/sbin/gluster-block-setup.sh\nADD update-params.sh /usr/local/bin/update-params.sh\nADD status-probe.sh /usr/local/bin/status-probe.sh\nADD tcmu-runner-params /etc/sysconfig/tcmu-runner-params\nADD gluster-check-diskspace.service /etc/systemd/system/gluster-check-diskspace.service\nADD check_diskspace.sh /usr/local/bin/check_diskspace.sh\nRUN chmod 644 /etc/systemd/system/gluster-setup.service \\\n && chmod 644 /etc/systemd/system/gluster-check-diskspace.service \\\n && chmod 755 /usr/libexec/gluster/fake-disk.sh \\\n && chmod 500 /usr/sbin/gluster-setup.sh \\\n && chmod 644 /etc/systemd/system/gluster-block-setup.service \\\n && chmod 500 /usr/sbin/gluster-block-setup.sh \\\n && chmod +x /usr/local/bin/update-params.sh \\\n && chmod +x /usr/local/bin/status-probe.sh \\\n && chmod +x /usr/local/bin/check_diskspace.sh \\\n && systemctl disable nfs-server.service \\\n && systemctl mask getty.target \\\n && systemctl enable gluster-fake-disk.service \\\n && systemctl enable gluster-setup.service \\\n && systemctl enable gluster-block-setup.service \\\n && systemctl enable gluster-blockd.service \\\n && systemctl enable glusterd.service \\\n && systemctl enable gluster-check-diskspace.service\nEXPOSE 2222/tcp 111/tcp 245/tcp 443/tcp 24007/tcp 2049/tcp 8080/tcp 6010/tcp 6011/tcp 6012/tcp 38465/tcp 38466/tcp 38468/tcp 38469/tcp 49152/tcp 49153/tcp 49154/tcp 49156/tcp 49157/tcp 49158/tcp 49159/tcp 49160/tcp 49161/tcp 49162/tcp\nENTRYPOINT [\"/usr/local/bin/update-params.sh\"]\nCMD [\"/usr/sbin/init\"]\n","injectedSmells":[],"originalDockerfileHash":"e20138c61e49cebf5b4a6e78078810ff","successfullyInjectedSmells":[],"originalDockerfileUglified":"FROM centos:7\nMAINTAINER Humble Chirammal hchiramm@redhat.com Saravanakumar Arumugam sarumuga@redhat.com\nENV container=\"docker\"\nENV ARCH=\"\\\"x86_64\\\"\"\nLABEL architecture=\"$ARCH\" \\\n      name=\"gluster/gluster-centos\" \\\n      version=\"latest\" \\\n      vendor=\"CentOS Community\" \\\n      summary=\"This image has a running glusterfs service (CentOS 7 + latest Gluster)\" \\\n      io.k8s.display-name=\"Gluster server based on CentOS 7\" \\\n      io.k8s.description=\"Gluster Image is based on CentOS Image which is a scalable network filesystem. Using common off-the-shelf hardware, you can create large, distributed storage solutions for media streaming, data analysis, and other data- and bandwidth-intensive tasks.\" \\\n      description=\"Gluster Image is based on CentOS Image which is a scalable network filesystem. Using common off-the-shelf hardware, you can create large, distributed storage solutions for media streaming, data analysis, and other data- and bandwidth-intensive tasks.\" \\\n      io.openshift.tags=\"gluster,glusterfs,glusterfs-centos\"\nRUN yum --setopt=tsflags=nodocs -y update \\\n && yum install -y centos-release-gluster \\\n && yum clean all \\\n && (cd /lib/systemd/system/sysinit.target.wants/ ;for i in *; do [ $i == systemd-tmpfiles-setup.service ] || rm -f $i ; done ) \\\n && rm -f /lib/systemd/system/multi-user.target.wants/* \\\n && rm -f /etc/systemd/system/*.wants/* \\\n && rm -f /lib/systemd/system/local-fs.target.wants/* \\\n && rm -f /lib/systemd/system/sockets.target.wants/*udev* \\\n && rm -f /lib/systemd/system/sockets.target.wants/*initctl* \\\n && rm -f /lib/systemd/system/basic.target.wants/* \\\n && rm -f /lib/systemd/system/anaconda.target.wants/* \\\n && yum --setopt=tsflags=nodocs -y install nfs-utils \\\n && yum --setopt=tsflags=nodocs -y install attr \\\n && yum --setopt=tsflags=nodocs -y install iputils \\\n && yum --setopt=tsflags=nodocs -y install iproute \\\n && yum --setopt=tsflags=nodocs -y install openssh-server \\\n && yum --setopt=tsflags=nodocs -y install openssh-clients \\\n && yum --setopt=tsflags=nodocs -y install rsync \\\n && yum --setopt=tsflags=nodocs -y install tar \\\n && yum --setopt=tsflags=nodocs -y install cronie \\\n && yum --setopt=tsflags=nodocs -y install sudo \\\n && yum --setopt=tsflags=nodocs -y install xfsprogs \\\n && yum --setopt=tsflags=nodocs -y install glusterfs \\\n && yum --setopt=tsflags=nodocs -y install glusterfs-server \\\n && yum --setopt=tsflags=nodocs -y install glusterfs-rdma \\\n && yum --setopt=tsflags=nodocs -y install gluster-block \\\n && yum --setopt=tsflags=nodocs -y install glusterfs-geo-replication \\\n && yum clean all \\\n && sed -i '/Defaults requiretty/c\\#Defaults requiretty' /etc/sudoers \\\n && sed -i '/Port 22/c\\Port 2222' /etc/ssh/sshd_config \\\n && sed -i 's/Requires\\=rpcbind\\.service//g' /usr/lib/systemd/system/glusterd.service \\\n && sed -i 's/rpcbind\\.service/gluster-setup\\.service/g' /usr/lib/systemd/system/glusterd.service \\\n && sed -i 's/rpcbind\\.service//g' /usr/lib/systemd/system/gluster-blockd.service \\\n && mkdir -p /etc/glusterfs_bkp /var/lib/glusterd_bkp /var/log/glusterfs_bkp \\\n && cp -r /etc/glusterfs/* /etc/glusterfs_bkp \\\n && cp -r /var/lib/glusterd/* /var/lib/glusterd_bkp \\\n && cp -r /var/log/glusterfs/* /var/log/glusterfs_bkp \\\n && mkdir -p /var/log/core\n#   downgrade lvm2 because of regression reported in https://bugzilla.redhat.com/1676612\n#   once the bug is fixed, disable obtain_device_list_from_udev in lvm.conf\nRUN true \\\n && yum -y downgrade device-mapper-libs-1.02.149-10.el7_6.2 device-mapper-1.02.149-10.el7_6.2 device-mapper-event-libs-1.02.149-10.el7_6.2 device-mapper-event-1.02.149-10.el7_6.2 device-mapper-persistent-data-0.7.0-0.1.rc6.el7_4.1 lvm2-libs-2.02.180-10.el7_6.2 lvm2-2.02.180-10.el7_6.2 \\\n && yum -y clean all \\\n && true\n#   do not run udev (if needed, bind-mount /run/udev instead?)\nRUN true \\\n && systemctl mask systemd-udev-trigger.service \\\n && systemctl mask systemd-udevd.service \\\n && systemctl mask systemd-udevd.socket \\\n && systemctl mask systemd-udevd-kernel.socket \\\n && true\n#   use lvmetad from the host, dont run it in the container\n#   don't wait for udev to manage the /dev entries, disable udev_sync, udev_rules in lvm.conf\nVOLUME [ \"/run/lvm\" ]\nRUN true \\\n && systemctl mask lvm2-lvmetad.service \\\n && systemctl mask lvm2-lvmetad.socket \\\n && sed -i 's/^\\sudev_rules\\s*=\\s*1/udev_rules = 0/' /etc/lvm/lvm.conf \\\n && sed -i 's/^\\sudev_sync\\s*=\\s*1/udev_sync= 0/' /etc/lvm/lvm.conf \\\n && sed -i 's/^\\sobtain_device_list_from_udev\\s*=\\s*1/obtain_device_list_from_udev = 0/' /etc/lvm/lvm.conf \\\n && true\n#   prevent dmeventd from running in the container, it may cause conflicts with\n#   the service running on the host\n#   monitoring of activated LVs can not be done inside the container\nRUN true \\\n && systemctl mask dm-event.service \\\n && systemctl disable dm-event.socket \\\n && systemctl mask dm-event.socket \\\n && systemctl disable lvm2-monitor.service \\\n && systemctl mask lvm2-monitor.service \\\n && sed -i 's/^\\smonitoring\\s*=\\s*1/monitoring = 0/' /etc/lvm/lvm.conf \\\n && true\nVOLUME [ \"/sys/fs/cgroup\" ]\nADD gluster-fake-disk.service /etc/systemd/system/gluster-fake-disk.service\nADD fake-disk.sh /usr/libexec/gluster/fake-disk.sh\nADD gluster-setup.service /etc/systemd/system/gluster-setup.service\nADD gluster-setup.sh /usr/sbin/gluster-setup.sh\nADD gluster-block-setup.service /etc/systemd/system/gluster-block-setup.service\nADD gluster-block-setup.sh /usr/sbin/gluster-block-setup.sh\nADD update-params.sh /usr/local/bin/update-params.sh\nADD status-probe.sh /usr/local/bin/status-probe.sh\nADD tcmu-runner-params /etc/sysconfig/tcmu-runner-params\nADD gluster-check-diskspace.service /etc/systemd/system/gluster-check-diskspace.service\nADD check_diskspace.sh /usr/local/bin/check_diskspace.sh\nRUN chmod 644 /etc/systemd/system/gluster-setup.service \\\n && chmod 644 /etc/systemd/system/gluster-check-diskspace.service \\\n && chmod 755 /usr/libexec/gluster/fake-disk.sh \\\n && chmod 500 /usr/sbin/gluster-setup.sh \\\n && chmod 644 /etc/systemd/system/gluster-block-setup.service \\\n && chmod 500 /usr/sbin/gluster-block-setup.sh \\\n && chmod +x /usr/local/bin/update-params.sh \\\n && chmod +x /usr/local/bin/status-probe.sh \\\n && chmod +x /usr/local/bin/check_diskspace.sh \\\n && systemctl disable nfs-server.service \\\n && systemctl mask getty.target \\\n && systemctl enable gluster-fake-disk.service \\\n && systemctl enable gluster-setup.service \\\n && systemctl enable gluster-block-setup.service \\\n && systemctl enable gluster-blockd.service \\\n && systemctl enable glusterd.service \\\n && systemctl enable gluster-check-diskspace.service\nEXPOSE 2222/tcp 111/tcp 245/tcp 443/tcp 24007/tcp 2049/tcp 8080/tcp 6010/tcp 6011/tcp 6012/tcp 38465/tcp 38466/tcp 38468/tcp 38469/tcp 49152/tcp 49153/tcp 49154/tcp 49156/tcp 49157/tcp 49158/tcp 49159/tcp 49160/tcp 49161/tcp 49162/tcp\nENTRYPOINT [\"/usr/local/bin/update-params.sh\"]\nCMD [\"/usr/sbin/init\"]\n","originalDockerfileUglifiedHash":"24e13a5571b3a9c2e30eae82dd4de250","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/e6d651eb3559ceced9ecb6355659d112e663a281.dockerfile"}