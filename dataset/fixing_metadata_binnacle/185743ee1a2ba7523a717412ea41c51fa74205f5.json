{"seed":3266008497,"processedDockerfileHash":"7e3477d831442734b4950a3d3cc4a874","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","use-copy-instead-of-add","have-a-healthcheck","have-a-user"],"processedDockerfile":"FROM java:openjdk-8-jdk\nMAINTAINER Dalitso Banda <dalitsohb@gmail.com>\n#   `Z_VERSION` will be updated by `dev/change_zeppelin_version.sh`\nENV Z_VERSION=\"git_master\"\nENV Z_COMMIT=\"2ea945f548a4e41312026d5ee1070714c155a11e\"\nENV LOG_TAG=\"[ZEPPELIN_${Z_VERSION}]:\" \\\n    Z_HOME=\"/zeppelin\" \\\n    LANG=\"en_US.UTF-8\" \\\n    LC_ALL=\"en_US.UTF-8\"\nRUN echo \"$LOG_TAG Install essentials\" \\\n && apt-get update -y \\\n && apt-get install --no-install-recommends locales -y \\\n && locale-gen $LANG \\\n && apt-get install --no-install-recommends git wget grep curl sed -y \\\n && apt-get autoclean \\\n && apt-get autoremove\nRUN echo \"$LOG_TAG Getting maven\" \\\n && wget http://www.eu.apache.org/dist/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz \\\n && tar -zxf apache-maven-3.3.9-bin.tar.gz -C /usr/local/ \\\n && ln -s /usr/local/apache-maven-3.3.9/bin/mvn /usr/local/bin/mvn\nCOPY patch_beam.patch /tmp/patch_beam.patch\nRUN echo \"$LOG_TAG install nodejs\" \\\n && curl -sL https://deb.nodesource.com/setup_11.x | bash - \\\n && apt-get install --no-install-recommends nodejs -y \\\n && echo \"$LOG_TAG Download Zeppelin source\" \\\n && git clone https://github.com/apache/zeppelin.git /zeppelin-${Z_VERSION}-bin-all \\\n && mv /zeppelin-${Z_VERSION}-bin-all ${Z_HOME}_src \\\n && mkdir ${Z_HOME}/notebook/mmlspark -p \\\n && cd ${Z_HOME}_src \\\n && git checkout ${Z_COMMIT} \\\n && echo '{ \"allow_root\": true }' > /root/.bowerrc \\\n && echo \"$LOG_TAG building zeppelin\" \\\n && cd ${Z_HOME}_src \\\n && git status \\\n && mv /tmp/patch_beam.patch . \\\n && git apply --ignore-space-change --ignore-whitespace patch_beam.patch \\\n && ./dev/change_scala_version.sh 2.11 \\\n && apt-get update -y \\\n && apt-get install --no-install-recommends git libfontconfig r-base-dev r-cran-evaluate wget grep curl sed -y \\\n && cd ${Z_HOME}_src/zeppelin-web \\\n && rm package-lock.json \\\n && mkdir -p /usr/local/lib/node_modules \\\n && npm install @angular/cli -g \\\n && npm install grunt-cli@1.4.3 bower@1.8.14 -g \\\n && bower install \\\n && cd ${Z_HOME}_src \\\n && export MAVEN_OPTS=\"-Xmx2g -Xss128M -XX:MetaspaceSize=512M -XX:MaxMetaspaceSize=1024M -XX:+CMSClassUnloadingEnabled\" \\\n && mvn -e -B package -DskipTests -Pscala-2.11 -Pbuild-distr \\\n && tar xvf ${Z_HOME}_src/zeppelin-distribution/target/zeppelin-0.9.0-SNAPSHOT.tar.gz \\\n && rm -rf ${Z_HOME}/* \\\n && mv zeppelin-0.9.0-SNAPSHOT ${Z_HOME}_dist \\\n && mv ${Z_HOME}_dist/* ${Z_HOME} \\\n && echo \"$LOG_TAG Cleanup\" \\\n && apt-get remove --purge -y r-base-dev r-cran-evaluate libfontconfig \\\n && npm uninstall -g @angular/cli grunt-cli bower \\\n && apt-get autoclean \\\n && apt-get autoremove -y \\\n && rm -rf ${Z_HOME}_dist \\\n && rm -rf ${Z_HOME}_src \\\n && rm -rf /root/.ivy2 \\\n && rm -rf /root/.m2 \\\n && rm -rf /root/.npm \\\n && rm -rf /root/.cache \\\n && rm -rf /tmp/*\nRUN echo \"$LOG_TAG install tini related packages\" \\\n && apt-get install --no-install-recommends wget curl grep sed dpkg -y \\\n && TINI_VERSION=`curl https://github.com/krallin/tini/releases/latest | grep -o \"/v.*\\\\\"\" | sed 's:^..\\\\(.*\\\\).$:\\\\1:' ` \\\n && curl -L \"https://github.com/krallin/tini/releases/download/v${TINI_VERSION}/tini_${TINI_VERSION}.deb\" > tini.deb \\\n && dpkg -i tini.deb \\\n && rm tini.deb\nRUN echo \"$LOG_TAG installing python related packages\" \\\n && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py \\\n && python get-pip.py \\\n && rm get-pip.py \\\n && apt-get install --no-install-recommends python-dev libpython3-dev build-essential pkg-config gfortran -y \\\n && pip install pip==23.1 setuptools==67.6.1 wheel==0.40.0 -U \\\n && pip install numpy==1.24.2 \\\n && pip install matplotlib==3.7.1 \\\n && pip install pandas==2.0.0 \\\n && apt-get update \\\n && apt-get upgrade -y \\\n && echo \"deb http://deb.debian.org/debian stretch main\" >> /etc/apt/sources.list \\\n && apt-get update \\\n && apt-get install --no-install-recommends g++ gcc-6 libstdc++-6-dev -y \\\n && echo \"$LOG_TAG Cleanup\" \\\n && apt-get purge -y --auto-remove build-essential pkg-config gfortran libpython3-dev \\\n && apt-get autoremove -y \\\n && apt-get autoclean \\\n && apt-get clean \\\n && rm -rf /root/.npm \\\n && rm -rf /root/.m2 \\\n && rm -rf /root/.cache \\\n && rm -rf /tmp/*\nENV APACHE_SPARK_VERSION=\"2.4.0\"\nENV HADOOP_VERSION=\"3.2.0\"\nENV HADOOP_GIT_COMMIT=\"release-3.2.0-RC1\"\nRUN echo \"$LOG_TAG Getting SPARK_HOME\" \\\n && mkdir -p /opt \\\n && cd /opt \\\n && curl http://apache.claz.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-without-hadoop.tgz | tar -xz \\\n && ln -s spark-${APACHE_SPARK_VERSION}-bin-without-hadoop spark \\\n && echo Spark ${APACHE_SPARK_VERSION} installed in /opt/spark \\\n && export SPARK_HOME=/opt/spark\nRUN echo \"$LOG_TAG building hadoop\" \\\n && apt-get update \\\n && apt-get install --no-install-recommends make -y \\\n && cd / \\\n && git clone https://github.com/apache/hadoop.git hadoop_src \\\n && mkdir /hadoop_deps \\\n && cd /hadoop_deps \\\n && wget https://github.com/protocolbuffers/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.bz2 \\\n && tar xvf protobuf-2.5.0.tar.bz2 \\\n && cd protobuf-2.5.0 \\\n && ./configure \\\n && make \\\n && make install \\\n && ldconfig \\\n && cd /hadoop_src \\\n && git checkout ${HADOOP_GIT_COMMIT} \\\n && mvn package -Pdist -DskipTests -Dtar \\\n && mv hadoop-dist/target/hadoop-${HADOOP_VERSION} /opt/hadoop \\\n && rm -r /hadoop_src \\\n && rm -rf /root/.ivy2 \\\n && rm -rf /root/.m2 \\\n && export HADOOP_HOME=/opt/hadoop \\\n && echo \"\\nexport HADOOP_CLASSPATH=/opt/hadoop/share/hadoop/tools/lib/*\" >> /opt/hadoop/etc/hadoop/hadoop-env.sh \\\n && echo Hadoop ${HADOOP_VERSION} installed in /opt/hadoop \\\n && apt-get purge -y --auto-remove g++ make build-essential autoconf automake \\\n && cd / \\\n && rm -rf /hadoop_deps\nRUN echo \"\\nSPARK_DIST_CLASSPATH=/jars:/jars/*:$( /opt/hadoop/bin/hadoop classpath ;)\" >> /opt/spark/conf/spark-env.sh\nENV HADOOP_HOME=\"/opt/hadoop\"\nCOPY jars /jars\n#   add notebooks\nCOPY mmlsparkExamples/ ${Z_HOME}/notebook/mmlspark/\nCOPY spark-defaults.conf /opt/spark/conf/spark-defaults.conf\nCOPY zeppelin-env.sh ${Z_HOME}/conf/\nEXPOSE 8080/tcp\nENTRYPOINT [\"/usr/bin/tini\", \"--\"]\nWORKDIR ${Z_HOME}\nCMD [\"sh\", \"-c\", \"echo\", \"'\\nspark.driver.host'\", \"$(\", \"hostname\", \"-i\", \";)\", \">>\", \"/opt/spark/conf/spark-defaults.conf\", \"&&\", \"bin/zeppelin.sh\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"FROM java:openjdk-8-jdk\nMAINTAINER Dalitso Banda <dalitsohb@gmail.com>\n#  `Z_VERSION` will be updated by `dev/change_zeppelin_version.sh`\nENV Z_VERSION=\"git_master\"\nENV Z_COMMIT=\"2ea945f548a4e41312026d5ee1070714c155a11e\"\nENV LOG_TAG=\"[ZEPPELIN_${Z_VERSION}]:\" \\\n    Z_HOME=\"/zeppelin\" \\\n    LANG=\"en_US.UTF-8\" \\\n    LC_ALL=\"en_US.UTF-8\"\nRUN echo \"$LOG_TAG Install essentials\" \\\n && apt-get update -y \\\n && apt-get install locales -y \\\n && locale-gen $LANG \\\n && apt-get install git wget grep curl sed -y \\\n && apt-get autoclean \\\n && apt-get autoremove\nRUN echo \"$LOG_TAG Getting maven\" \\\n && wget http://www.eu.apache.org/dist/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz \\\n && tar -zxf apache-maven-3.3.9-bin.tar.gz -C /usr/local/ \\\n && ln -s /usr/local/apache-maven-3.3.9/bin/mvn /usr/local/bin/mvn\nADD patch_beam.patch /tmp/patch_beam.patch\nRUN echo \"$LOG_TAG install nodejs\" \\\n && curl -sL https://deb.nodesource.com/setup_11.x | bash - \\\n && apt-get install nodejs -y \\\n && echo \"$LOG_TAG Download Zeppelin source\" \\\n && git clone https://github.com/apache/zeppelin.git /zeppelin-${Z_VERSION}-bin-all \\\n && mv /zeppelin-${Z_VERSION}-bin-all ${Z_HOME}_src \\\n && mkdir ${Z_HOME}/notebook/mmlspark -p \\\n && cd ${Z_HOME}_src \\\n && git checkout ${Z_COMMIT} \\\n && echo '{ \"allow_root\": true }' > /root/.bowerrc \\\n && echo \"$LOG_TAG building zeppelin\" \\\n && cd ${Z_HOME}_src \\\n && git status \\\n && mv /tmp/patch_beam.patch . \\\n && git apply --ignore-space-change --ignore-whitespace patch_beam.patch \\\n && ./dev/change_scala_version.sh 2.11 \\\n && apt-get update -y \\\n && apt-get install git libfontconfig r-base-dev r-cran-evaluate wget grep curl sed -y \\\n && cd ${Z_HOME}_src/zeppelin-web \\\n && rm package-lock.json \\\n && mkdir -p /usr/local/lib/node_modules \\\n && npm install @angular/cli -g \\\n && npm install grunt-cli bower -g \\\n && bower install \\\n && cd ${Z_HOME}_src \\\n && export MAVEN_OPTS=\"-Xmx2g -Xss128M -XX:MetaspaceSize=512M -XX:MaxMetaspaceSize=1024M -XX:+CMSClassUnloadingEnabled\" \\\n && mvn -e -B package -DskipTests -Pscala-2.11 -Pbuild-distr \\\n && tar xvf ${Z_HOME}_src/zeppelin-distribution/target/zeppelin-0.9.0-SNAPSHOT.tar.gz \\\n && rm -rf ${Z_HOME}/* \\\n && mv zeppelin-0.9.0-SNAPSHOT ${Z_HOME}_dist \\\n && mv ${Z_HOME}_dist/* ${Z_HOME} \\\n && echo \"$LOG_TAG Cleanup\" \\\n && apt-get remove --purge -y r-base-dev r-cran-evaluate libfontconfig \\\n && npm uninstall -g @angular/cli grunt-cli bower \\\n && apt-get autoclean \\\n && apt-get autoremove -y \\\n && rm -rf ${Z_HOME}_dist \\\n && rm -rf ${Z_HOME}_src \\\n && rm -rf /root/.ivy2 \\\n && rm -rf /root/.m2 \\\n && rm -rf /root/.npm \\\n && rm -rf /root/.cache \\\n && rm -rf /tmp/*\nRUN echo \"$LOG_TAG install tini related packages\" \\\n && apt-get install wget curl grep sed dpkg -y \\\n && TINI_VERSION=`curl https://github.com/krallin/tini/releases/latest | grep -o \"/v.*\\\\\"\" | sed 's:^..\\\\(.*\\\\).$:\\\\1:' ` \\\n && curl -L \"https://github.com/krallin/tini/releases/download/v${TINI_VERSION}/tini_${TINI_VERSION}.deb\" > tini.deb \\\n && dpkg -i tini.deb \\\n && rm tini.deb\nRUN echo \"$LOG_TAG installing python related packages\" \\\n && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py \\\n && python get-pip.py \\\n && rm get-pip.py \\\n && apt-get install python-dev libpython3-dev build-essential pkg-config gfortran -y \\\n && pip install pip setuptools wheel -U \\\n && pip install numpy \\\n && pip install matplotlib \\\n && pip install pandas \\\n && apt-get update \\\n && apt-get upgrade -y \\\n && echo \"deb http://deb.debian.org/debian stretch main\" >> /etc/apt/sources.list \\\n && apt-get update \\\n && apt-get install g++ gcc-6 libstdc++-6-dev -y \\\n && echo \"$LOG_TAG Cleanup\" \\\n && apt-get purge -y --auto-remove build-essential pkg-config gfortran libpython3-dev \\\n && apt-get autoremove -y \\\n && apt-get autoclean \\\n && apt-get clean \\\n && rm -rf /root/.npm \\\n && rm -rf /root/.m2 \\\n && rm -rf /root/.cache \\\n && rm -rf /tmp/*\nENV APACHE_SPARK_VERSION=\"2.4.0\"\nENV HADOOP_VERSION=\"3.2.0\"\nENV HADOOP_GIT_COMMIT=\"release-3.2.0-RC1\"\nRUN echo \"$LOG_TAG Getting SPARK_HOME\" \\\n && mkdir -p /opt \\\n && cd /opt \\\n && curl http://apache.claz.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-without-hadoop.tgz | tar -xz \\\n && ln -s spark-${APACHE_SPARK_VERSION}-bin-without-hadoop spark \\\n && echo Spark ${APACHE_SPARK_VERSION} installed in /opt/spark \\\n && export SPARK_HOME=/opt/spark\nRUN echo \"$LOG_TAG building hadoop\" \\\n && apt-get update \\\n && apt-get install make -y \\\n && cd / \\\n && git clone https://github.com/apache/hadoop.git hadoop_src \\\n && mkdir /hadoop_deps \\\n && cd /hadoop_deps \\\n && wget https://github.com/protocolbuffers/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.bz2 \\\n && tar xvf protobuf-2.5.0.tar.bz2 \\\n && cd protobuf-2.5.0 \\\n && ./configure \\\n && make \\\n && make install \\\n && ldconfig \\\n && cd /hadoop_src \\\n && git checkout ${HADOOP_GIT_COMMIT} \\\n && mvn package -Pdist -DskipTests -Dtar \\\n && mv hadoop-dist/target/hadoop-${HADOOP_VERSION} /opt/hadoop \\\n && rm -r /hadoop_src \\\n && rm -rf /root/.ivy2 \\\n && rm -rf /root/.m2 \\\n && export HADOOP_HOME=/opt/hadoop \\\n && echo \"\\nexport HADOOP_CLASSPATH=/opt/hadoop/share/hadoop/tools/lib/*\" >> /opt/hadoop/etc/hadoop/hadoop-env.sh \\\n && echo Hadoop ${HADOOP_VERSION} installed in /opt/hadoop \\\n && apt-get purge -y --auto-remove g++ make build-essential autoconf automake \\\n && cd / \\\n && rm -rf /hadoop_deps\nRUN echo \"\\nSPARK_DIST_CLASSPATH=/jars:/jars/*:$( /opt/hadoop/bin/hadoop classpath ;)\" >> /opt/spark/conf/spark-env.sh\nENV HADOOP_HOME=\"/opt/hadoop\"\nADD jars /jars\n#  add notebooks\nADD mmlsparkExamples/ ${Z_HOME}/notebook/mmlspark/\nADD spark-defaults.conf /opt/spark/conf/spark-defaults.conf\nADD zeppelin-env.sh ${Z_HOME}/conf/\nEXPOSE 8080/tcp\nENTRYPOINT [\"/usr/bin/tini\", \"--\"]\nWORKDIR ${Z_HOME}\nCMD [\"sh\", \"-c\", \"echo\", \"'\\nspark.driver.host'\", \"$(\", \"hostname\", \"-i\", \";)\", \">>\", \"/opt/spark/conf/spark-defaults.conf\", \"&&\", \"bin/zeppelin.sh\"]\n","injectedSmells":[],"originalDockerfileHash":"0c084328ca6d14ba94e8610fc2ab55b1","successfullyInjectedSmells":[],"originalDockerfileUglified":"FROM java:openjdk-8-jdk\nMAINTAINER Dalitso Banda <dalitsohb@gmail.com>\n#   `Z_VERSION` will be updated by `dev/change_zeppelin_version.sh`\nENV Z_VERSION=\"git_master\"\nENV Z_COMMIT=\"2ea945f548a4e41312026d5ee1070714c155a11e\"\nENV LOG_TAG=\"[ZEPPELIN_${Z_VERSION}]:\" \\\n    Z_HOME=\"/zeppelin\" \\\n    LANG=\"en_US.UTF-8\" \\\n    LC_ALL=\"en_US.UTF-8\"\nRUN echo \"$LOG_TAG Install essentials\" \\\n && apt-get update -y \\\n && apt-get install locales -y \\\n && locale-gen $LANG \\\n && apt-get install git wget grep curl sed -y \\\n && apt-get autoclean \\\n && apt-get autoremove\nRUN echo \"$LOG_TAG Getting maven\" \\\n && wget http://www.eu.apache.org/dist/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz \\\n && tar -zxf apache-maven-3.3.9-bin.tar.gz -C /usr/local/ \\\n && ln -s /usr/local/apache-maven-3.3.9/bin/mvn /usr/local/bin/mvn\nADD patch_beam.patch /tmp/patch_beam.patch\nRUN echo \"$LOG_TAG install nodejs\" \\\n && curl -sL https://deb.nodesource.com/setup_11.x | bash - \\\n && apt-get install nodejs -y \\\n && echo \"$LOG_TAG Download Zeppelin source\" \\\n && git clone https://github.com/apache/zeppelin.git /zeppelin-${Z_VERSION}-bin-all \\\n && mv /zeppelin-${Z_VERSION}-bin-all ${Z_HOME}_src \\\n && mkdir ${Z_HOME}/notebook/mmlspark -p \\\n && cd ${Z_HOME}_src \\\n && git checkout ${Z_COMMIT} \\\n && echo '{ \"allow_root\": true }' > /root/.bowerrc \\\n && echo \"$LOG_TAG building zeppelin\" \\\n && cd ${Z_HOME}_src \\\n && git status \\\n && mv /tmp/patch_beam.patch . \\\n && git apply --ignore-space-change --ignore-whitespace patch_beam.patch \\\n && ./dev/change_scala_version.sh 2.11 \\\n && apt-get update -y \\\n && apt-get install git libfontconfig r-base-dev r-cran-evaluate wget grep curl sed -y \\\n && cd ${Z_HOME}_src/zeppelin-web \\\n && rm package-lock.json \\\n && mkdir -p /usr/local/lib/node_modules \\\n && npm install @angular/cli -g \\\n && npm install grunt-cli bower -g \\\n && bower install \\\n && cd ${Z_HOME}_src \\\n && export MAVEN_OPTS=\"-Xmx2g -Xss128M -XX:MetaspaceSize=512M -XX:MaxMetaspaceSize=1024M -XX:+CMSClassUnloadingEnabled\" \\\n && mvn -e -B package -DskipTests -Pscala-2.11 -Pbuild-distr \\\n && tar xvf ${Z_HOME}_src/zeppelin-distribution/target/zeppelin-0.9.0-SNAPSHOT.tar.gz \\\n && rm -rf ${Z_HOME}/* \\\n && mv zeppelin-0.9.0-SNAPSHOT ${Z_HOME}_dist \\\n && mv ${Z_HOME}_dist/* ${Z_HOME} \\\n && echo \"$LOG_TAG Cleanup\" \\\n && apt-get remove --purge -y r-base-dev r-cran-evaluate libfontconfig \\\n && npm uninstall -g @angular/cli grunt-cli bower \\\n && apt-get autoclean \\\n && apt-get autoremove -y \\\n && rm -rf ${Z_HOME}_dist \\\n && rm -rf ${Z_HOME}_src \\\n && rm -rf /root/.ivy2 \\\n && rm -rf /root/.m2 \\\n && rm -rf /root/.npm \\\n && rm -rf /root/.cache \\\n && rm -rf /tmp/*\nRUN echo \"$LOG_TAG install tini related packages\" \\\n && apt-get install wget curl grep sed dpkg -y \\\n && TINI_VERSION=`curl https://github.com/krallin/tini/releases/latest | grep -o \"/v.*\\\\\"\" | sed 's:^..\\\\(.*\\\\).$:\\\\1:' ` \\\n && curl -L \"https://github.com/krallin/tini/releases/download/v${TINI_VERSION}/tini_${TINI_VERSION}.deb\" > tini.deb \\\n && dpkg -i tini.deb \\\n && rm tini.deb\nRUN echo \"$LOG_TAG installing python related packages\" \\\n && curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py \\\n && python get-pip.py \\\n && rm get-pip.py \\\n && apt-get install python-dev libpython3-dev build-essential pkg-config gfortran -y \\\n && pip install pip setuptools wheel -U \\\n && pip install numpy \\\n && pip install matplotlib \\\n && pip install pandas \\\n && apt-get update \\\n && apt-get upgrade -y \\\n && echo \"deb http://deb.debian.org/debian stretch main\" >> /etc/apt/sources.list \\\n && apt-get update \\\n && apt-get install g++ gcc-6 libstdc++-6-dev -y \\\n && echo \"$LOG_TAG Cleanup\" \\\n && apt-get purge -y --auto-remove build-essential pkg-config gfortran libpython3-dev \\\n && apt-get autoremove -y \\\n && apt-get autoclean \\\n && apt-get clean \\\n && rm -rf /root/.npm \\\n && rm -rf /root/.m2 \\\n && rm -rf /root/.cache \\\n && rm -rf /tmp/*\nENV APACHE_SPARK_VERSION=\"2.4.0\"\nENV HADOOP_VERSION=\"3.2.0\"\nENV HADOOP_GIT_COMMIT=\"release-3.2.0-RC1\"\nRUN echo \"$LOG_TAG Getting SPARK_HOME\" \\\n && mkdir -p /opt \\\n && cd /opt \\\n && curl http://apache.claz.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-without-hadoop.tgz | tar -xz \\\n && ln -s spark-${APACHE_SPARK_VERSION}-bin-without-hadoop spark \\\n && echo Spark ${APACHE_SPARK_VERSION} installed in /opt/spark \\\n && export SPARK_HOME=/opt/spark\nRUN echo \"$LOG_TAG building hadoop\" \\\n && apt-get update \\\n && apt-get install make -y \\\n && cd / \\\n && git clone https://github.com/apache/hadoop.git hadoop_src \\\n && mkdir /hadoop_deps \\\n && cd /hadoop_deps \\\n && wget https://github.com/protocolbuffers/protobuf/releases/download/v2.5.0/protobuf-2.5.0.tar.bz2 \\\n && tar xvf protobuf-2.5.0.tar.bz2 \\\n && cd protobuf-2.5.0 \\\n && ./configure \\\n && make \\\n && make install \\\n && ldconfig \\\n && cd /hadoop_src \\\n && git checkout ${HADOOP_GIT_COMMIT} \\\n && mvn package -Pdist -DskipTests -Dtar \\\n && mv hadoop-dist/target/hadoop-${HADOOP_VERSION} /opt/hadoop \\\n && rm -r /hadoop_src \\\n && rm -rf /root/.ivy2 \\\n && rm -rf /root/.m2 \\\n && export HADOOP_HOME=/opt/hadoop \\\n && echo \"\\nexport HADOOP_CLASSPATH=/opt/hadoop/share/hadoop/tools/lib/*\" >> /opt/hadoop/etc/hadoop/hadoop-env.sh \\\n && echo Hadoop ${HADOOP_VERSION} installed in /opt/hadoop \\\n && apt-get purge -y --auto-remove g++ make build-essential autoconf automake \\\n && cd / \\\n && rm -rf /hadoop_deps\nRUN echo \"\\nSPARK_DIST_CLASSPATH=/jars:/jars/*:$( /opt/hadoop/bin/hadoop classpath ;)\" >> /opt/spark/conf/spark-env.sh\nENV HADOOP_HOME=\"/opt/hadoop\"\nADD jars /jars\n#   add notebooks\nADD mmlsparkExamples/ ${Z_HOME}/notebook/mmlspark/\nADD spark-defaults.conf /opt/spark/conf/spark-defaults.conf\nADD zeppelin-env.sh ${Z_HOME}/conf/\nEXPOSE 8080/tcp\nENTRYPOINT [\"/usr/bin/tini\", \"--\"]\nWORKDIR ${Z_HOME}\nCMD [\"sh\", \"-c\", \"echo\", \"'\\nspark.driver.host'\", \"$(\", \"hostname\", \"-i\", \";)\", \">>\", \"/opt/spark/conf/spark-defaults.conf\", \"&&\", \"bin/zeppelin.sh\"]\n","originalDockerfileUglifiedHash":"f99782e911e12a7f58807df0dd4dc5cb","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/185743ee1a2ba7523a717412ea41c51fa74205f5.dockerfile"}