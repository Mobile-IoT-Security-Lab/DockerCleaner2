{"seed":1814925791,"processedDockerfileHash":"c011edfd3d5e25aa709b749fb89653b2","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-pip","have-a-healthcheck","have-a-user"],"processedDockerfile":"FROM nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04\nRUN apt-get update \\\n && apt-get install --no-install-recommends build-essential curl git libfreetype6-dev libpng12-dev libzmq3-dev pkg-config python-dev python-numpy python-pip software-properties-common swig zip zlib1g-dev libcurl3-dev -y \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\nRUN curl -fSsL -O https://bootstrap.pypa.io/get-pip.py \\\n && python get-pip.py \\\n && rm get-pip.py\n#   Set up grpc\nRUN pip install enum34==1.1.10 futures==3.4.0 mock==5.0.2 six==1.16.0 \\\n && pip install 'protobuf>=3.0.0a3' --pre \\\n && pip install grpcio==1.53.0 -i https://testpypi.python.org/simple --pre\n#   Set up Bazel.\n#   We need to add a custom PPA to pick up JDK8, since trusty doesn't\n#   have an openjdk8 backport.  openjdk-r is maintained by a reliable contributor:\n#   Matthias Klose (https://launchpad.net/~doko).  It will do until\n#   we either update the base image beyond 14.04 or openjdk-8 is\n#   finally backported to trusty; see e.g.\n#     https://bugs.launchpad.net/trusty-backports/+bug/1368094\nRUN add-apt-repository -y ppa:openjdk-r/ppa \\\n && apt-get update \\\n && apt-get install --no-install-recommends openjdk-8-jdk openjdk-8-jre-headless -y \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   Running bazel inside a `docker build` command causes trouble, cf:\n#     https://github.com/bazelbuild/bazel/issues/134\n#   The easiest solution is to set up a bazelrc file forcing --batch.\nRUN echo \"startup --batch\" >> /root/.bazelrc\n#   Similarly, we need to workaround sandboxing issues:\n#     https://github.com/bazelbuild/bazel/issues/418\nRUN echo \"build --spawn_strategy=standalone --genrule_strategy=standalone\" >> /root/.bazelrc\nENV BAZELRC=\"/root/.bazelrc\"\n#   Install the most recent bazel release.\nENV BAZEL_VERSION=\"0.5.4\"\nWORKDIR /\nRUN mkdir /bazel \\\n && cd /bazel \\\n && curl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && curl -fSsL -o /bazel/LICENSE https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE \\\n && chmod +x bazel-*.sh \\\n && ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && cd / \\\n && rm -f /bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh\n#   Download TensorFlow Serving\nRUN git clone --recurse-submodules https://github.com/tensorflow/serving \\\n && cd serving \\\n && git checkout\n#   Build TensorFlow with the CUDA configuration\nENV CI_BUILD_PYTHON=\"python\"\nENV LD_LIBRARY_PATH=\"/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\"\nENV TF_NEED_CUDA=\"1\"\nENV TF_CUDA_COMPUTE_CAPABILITIES=\"3.0,3.5,5.2,6.0,6.1\"\n#   Fix paths so that CUDNN can be found\n#   See https://github.com/tensorflow/tensorflow/issues/8264\nRUN ls -lah /usr/local/cuda/lib64/*\nRUN mkdir /usr/lib/x86_64-linux-gnu/include/ \\\n && ln -s /usr/lib/x86_64-linux-gnu/include/cudnn.h /usr/lib/x86_64-linux-gnu/include/cudnn.h \\\n && ln -s /usr/include/cudnn.h /usr/local/cuda/include/cudnn.h \\\n && ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so /usr/local/cuda/lib64/libcudnn.so \\\n && ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so.6 /usr/local/cuda/lib64/libcudnn.so.6\n#   Fix from https://github.com/tensorflow/serving/issues/327#issuecomment-282207825\nWORKDIR /\nRUN git clone https://github.com/NVIDIA/nccl.git \\\n && cd nccl/ \\\n && make CUDA_HOME=/usr/local/cuda \\\n && make install \\\n && mkdir -p /usr/local/include/external/nccl_archive/src \\\n && ln -s /usr/local/include/nccl.h /usr/local/include/external/nccl_archive/src/nccl.h\n#   Configure Tensorflow to use the GPU\nWORKDIR /serving/tensorflow\nRUN tensorflow/tools/ci_build/builds/configured GPU\n#   Build TensorFlow Serving and Install it in /usr/local/bin\nWORKDIR /serving\nRUN bazel build -c opt --config=cuda --crosstool_top=@local_config_cuda//crosstool:toolchain tensorflow_serving/model_servers:tensorflow_model_server \\\n && cp bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server /usr/local/bin/ \\\n && bazel clean --expunge\nCMD [\"/bin/bash\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"FROM nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04\nRUN apt-get update \\\n && apt-get install build-essential curl git libfreetype6-dev libpng12-dev libzmq3-dev pkg-config python-dev python-numpy python-pip software-properties-common swig zip zlib1g-dev libcurl3-dev -y \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\nRUN curl -fSsL -O https://bootstrap.pypa.io/get-pip.py \\\n && python get-pip.py \\\n && rm get-pip.py\n#  Set up grpc\nRUN pip install enum34 futures mock six \\\n && pip install 'protobuf>=3.0.0a3' --pre \\\n && pip install grpcio -i https://testpypi.python.org/simple --pre\n#  Set up Bazel.\n#  We need to add a custom PPA to pick up JDK8, since trusty doesn't\n#  have an openjdk8 backport.  openjdk-r is maintained by a reliable contributor:\n#  Matthias Klose (https://launchpad.net/~doko).  It will do until\n#  we either update the base image beyond 14.04 or openjdk-8 is\n#  finally backported to trusty; see e.g.\n#    https://bugs.launchpad.net/trusty-backports/+bug/1368094\nRUN add-apt-repository -y ppa:openjdk-r/ppa \\\n && apt-get update \\\n && apt-get install openjdk-8-jdk openjdk-8-jre-headless -y \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#  Running bazel inside a `docker build` command causes trouble, cf:\n#    https://github.com/bazelbuild/bazel/issues/134\n#  The easiest solution is to set up a bazelrc file forcing --batch.\nRUN echo \"startup --batch\" >> /root/.bazelrc\n#  Similarly, we need to workaround sandboxing issues:\n#    https://github.com/bazelbuild/bazel/issues/418\nRUN echo \"build --spawn_strategy=standalone --genrule_strategy=standalone\" >> /root/.bazelrc\nENV BAZELRC=\"/root/.bazelrc\"\n#  Install the most recent bazel release.\nENV BAZEL_VERSION=\"0.5.4\"\nWORKDIR /\nRUN mkdir /bazel \\\n && cd /bazel \\\n && curl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && curl -fSsL -o /bazel/LICENSE https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE \\\n && chmod +x bazel-*.sh \\\n && ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && cd / \\\n && rm -f /bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh\n#  Download TensorFlow Serving\nRUN git clone --recurse-submodules https://github.com/tensorflow/serving \\\n && cd serving \\\n && git checkout\n#  Build TensorFlow with the CUDA configuration\nENV CI_BUILD_PYTHON=\"python\"\nENV LD_LIBRARY_PATH=\"/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\"\nENV TF_NEED_CUDA=\"1\"\nENV TF_CUDA_COMPUTE_CAPABILITIES=\"3.0,3.5,5.2,6.0,6.1\"\n#  Fix paths so that CUDNN can be found\n#  See https://github.com/tensorflow/tensorflow/issues/8264\nRUN ls -lah /usr/local/cuda/lib64/*\nRUN mkdir /usr/lib/x86_64-linux-gnu/include/ \\\n && ln -s /usr/lib/x86_64-linux-gnu/include/cudnn.h /usr/lib/x86_64-linux-gnu/include/cudnn.h \\\n && ln -s /usr/include/cudnn.h /usr/local/cuda/include/cudnn.h \\\n && ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so /usr/local/cuda/lib64/libcudnn.so \\\n && ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so.6 /usr/local/cuda/lib64/libcudnn.so.6\n#  Fix from https://github.com/tensorflow/serving/issues/327#issuecomment-282207825\nWORKDIR /\nRUN git clone https://github.com/NVIDIA/nccl.git \\\n && cd nccl/ \\\n && make CUDA_HOME=/usr/local/cuda \\\n && make install \\\n && mkdir -p /usr/local/include/external/nccl_archive/src \\\n && ln -s /usr/local/include/nccl.h /usr/local/include/external/nccl_archive/src/nccl.h\n#  Configure Tensorflow to use the GPU\nWORKDIR /serving/tensorflow\nRUN tensorflow/tools/ci_build/builds/configured GPU\n#  Build TensorFlow Serving and Install it in /usr/local/bin\nWORKDIR /serving\nRUN bazel build -c opt --config=cuda --crosstool_top=@local_config_cuda//crosstool:toolchain tensorflow_serving/model_servers:tensorflow_model_server \\\n && cp bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server /usr/local/bin/ \\\n && bazel clean --expunge\nCMD [\"/bin/bash\"]\n","injectedSmells":[],"originalDockerfileHash":"a753b45e25035749215a850e6c2d91df","successfullyInjectedSmells":[],"originalDockerfileUglified":"FROM nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04\nRUN apt-get update \\\n && apt-get install build-essential curl git libfreetype6-dev libpng12-dev libzmq3-dev pkg-config python-dev python-numpy python-pip software-properties-common swig zip zlib1g-dev libcurl3-dev -y \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\nRUN curl -fSsL -O https://bootstrap.pypa.io/get-pip.py \\\n && python get-pip.py \\\n && rm get-pip.py\n#   Set up grpc\nRUN pip install enum34 futures mock six \\\n && pip install 'protobuf>=3.0.0a3' --pre \\\n && pip install grpcio -i https://testpypi.python.org/simple --pre\n#   Set up Bazel.\n#   We need to add a custom PPA to pick up JDK8, since trusty doesn't\n#   have an openjdk8 backport.  openjdk-r is maintained by a reliable contributor:\n#   Matthias Klose (https://launchpad.net/~doko).  It will do until\n#   we either update the base image beyond 14.04 or openjdk-8 is\n#   finally backported to trusty; see e.g.\n#     https://bugs.launchpad.net/trusty-backports/+bug/1368094\nRUN add-apt-repository -y ppa:openjdk-r/ppa \\\n && apt-get update \\\n && apt-get install openjdk-8-jdk openjdk-8-jre-headless -y \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   Running bazel inside a `docker build` command causes trouble, cf:\n#     https://github.com/bazelbuild/bazel/issues/134\n#   The easiest solution is to set up a bazelrc file forcing --batch.\nRUN echo \"startup --batch\" >> /root/.bazelrc\n#   Similarly, we need to workaround sandboxing issues:\n#     https://github.com/bazelbuild/bazel/issues/418\nRUN echo \"build --spawn_strategy=standalone --genrule_strategy=standalone\" >> /root/.bazelrc\nENV BAZELRC=\"/root/.bazelrc\"\n#   Install the most recent bazel release.\nENV BAZEL_VERSION=\"0.5.4\"\nWORKDIR /\nRUN mkdir /bazel \\\n && cd /bazel \\\n && curl -fSsL -O https://github.com/bazelbuild/bazel/releases/download/$BAZEL_VERSION/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && curl -fSsL -o /bazel/LICENSE https://raw.githubusercontent.com/bazelbuild/bazel/master/LICENSE \\\n && chmod +x bazel-*.sh \\\n && ./bazel-$BAZEL_VERSION-installer-linux-x86_64.sh \\\n && cd / \\\n && rm -f /bazel/bazel-$BAZEL_VERSION-installer-linux-x86_64.sh\n#   Download TensorFlow Serving\nRUN git clone --recurse-submodules https://github.com/tensorflow/serving \\\n && cd serving \\\n && git checkout\n#   Build TensorFlow with the CUDA configuration\nENV CI_BUILD_PYTHON=\"python\"\nENV LD_LIBRARY_PATH=\"/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\"\nENV TF_NEED_CUDA=\"1\"\nENV TF_CUDA_COMPUTE_CAPABILITIES=\"3.0,3.5,5.2,6.0,6.1\"\n#   Fix paths so that CUDNN can be found\n#   See https://github.com/tensorflow/tensorflow/issues/8264\nRUN ls -lah /usr/local/cuda/lib64/*\nRUN mkdir /usr/lib/x86_64-linux-gnu/include/ \\\n && ln -s /usr/lib/x86_64-linux-gnu/include/cudnn.h /usr/lib/x86_64-linux-gnu/include/cudnn.h \\\n && ln -s /usr/include/cudnn.h /usr/local/cuda/include/cudnn.h \\\n && ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so /usr/local/cuda/lib64/libcudnn.so \\\n && ln -s /usr/lib/x86_64-linux-gnu/libcudnn.so.6 /usr/local/cuda/lib64/libcudnn.so.6\n#   Fix from https://github.com/tensorflow/serving/issues/327#issuecomment-282207825\nWORKDIR /\nRUN git clone https://github.com/NVIDIA/nccl.git \\\n && cd nccl/ \\\n && make CUDA_HOME=/usr/local/cuda \\\n && make install \\\n && mkdir -p /usr/local/include/external/nccl_archive/src \\\n && ln -s /usr/local/include/nccl.h /usr/local/include/external/nccl_archive/src/nccl.h\n#   Configure Tensorflow to use the GPU\nWORKDIR /serving/tensorflow\nRUN tensorflow/tools/ci_build/builds/configured GPU\n#   Build TensorFlow Serving and Install it in /usr/local/bin\nWORKDIR /serving\nRUN bazel build -c opt --config=cuda --crosstool_top=@local_config_cuda//crosstool:toolchain tensorflow_serving/model_servers:tensorflow_model_server \\\n && cp bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server /usr/local/bin/ \\\n && bazel clean --expunge\nCMD [\"/bin/bash\"]\n","originalDockerfileUglifiedHash":"0f53e76cc9ab5fafcc75bf427ab747f9","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/9b351de876c35f8af95631bb4d32b59f521bd3e4.dockerfile"}