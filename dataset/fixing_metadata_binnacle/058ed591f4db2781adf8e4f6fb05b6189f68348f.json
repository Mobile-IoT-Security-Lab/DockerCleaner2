{"seed":3663442520,"processedDockerfileHash":"d5934f5ca6845a041da3092debecc92f","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["pin-package-manager-versions-apk","have-a-healthcheck","have-a-user"],"processedDockerfile":"ARG base_image=resin/raspberrypi3-alpine-python:3.6-slim-20180120\n#   Use this for local development on intel machines\n#   FROM resin/amd64-alpine-python:3.6-slim-20180123\n#   Use this for running on a robot\nFROM $base_image\n#   See compute/README.md for details. Make sure to keep them in sync\nRUN apk add util-linux=2.38.1-r1 vim=9.0.0999-r0 dropbear=2022.83-r0 dropbear-scp=2022.83-r0 gnupg=2.2.40-r0 openjdk8=8.362.09-r1 nginx=1.22.1-r0 libstdc++=12.2.1_git20220924-r4 g++=12.2.1_git20220924-r4 networkmanager=1.40.16-r0 py3-zmq py3-urwid=2.1.2-r2 py3-numpy=1.23.4-r0 avrdude=7.0-r1 ffmpeg=5.1.3-r0 mpg123=1.31.1-r0 --update \\\n && rm -rf /var/cache/apk/*\n#   Resin's python base container compiles python from scratch and doesn't have\n#   it installed as apk package. This results in py3- dependencies installing\n#   python3 package without being able to remove it (because py3- depend on it).\n#   To avoid ambiguity, we are copying all installed dependencies into original\n#   site-packages and cleaning up the one created by python3 package.\nRUN cp -r /usr/lib/python3.6/site-packages /usr/local/lib/python3.6/ \\\n && rm -rf /usr/lib/python3.6\nRUN pip install pipenv==9.0.3 jupyter==1.0.0 tornado==4.5.1 pyzmq==16.0.2 --force-reinstall\n#   Copy server files and data into the container. Note: any directories that\n#   you wish to copy into the container must be excluded from the .dockerignore\n#   file, or you will encounter a copy error\nCOPY ./compute/container_setup.sh /usr/local/bin/container_setup.sh\nCOPY ./audio/ /etc/audio\nCOPY ./shared-data/module /etc/module\nCOPY ./shared-data/pipette /etc/pipette\nCOPY ./shared-data/definitions /etc/labware\nCOPY ./api /tmp/api\n#   Make our shared data available for the api setup.py\nCOPY ./shared-data /tmp/shared-data\nCOPY ./update-server /tmp/update-server\nCOPY ./compute/avahi_tools /tmp/avahi_tools\n#   When adding more python packages make sure to use setuptools to keep\n#   packaging consistent across environments\nENV PIPENV_VENV_IN_PROJECT=\"true\"\nRUN pipenv install /tmp/api --system \\\n && pipenv install /tmp/update-server --system \\\n && pip install /tmp/avahi_tools \\\n && echo \"export OT_SYSTEM_VERSION=`python -c \"import json; print(json.load(open('/tmp/api/opentrons/package.json'))['version'])\" `\" | tee -a /etc/profile.d/opentrons.sh \\\n && rm -rf /tmp/api \\\n && rm -rf /tmp/update-server \\\n && rm -rf /tmp/shared-data \\\n && rm -rf /tmp/avahi_tools\n#   Redirect nginx logs to stdout and stderr\nRUN ln -sf /dev/stdout /var/log/nginx/access.log \\\n && ln -sf /dev/stderr /var/log/nginx/error.log\n#   Use udev rules file from opentrons_data\nRUN ln -sf /data/user_storage/opentrons_data/95-opentrons-modules.rules /etc/udev/rules.d/95-opentrons-modules.rules\n#   Logo for login shell\nCOPY ./compute/opentrons.motd /etc/motd\n#   Generate keys for dropbear\nCOPY ./compute/ssh_key_gen.sh /tmp/\nRUN /tmp/ssh_key_gen.sh\n#   Updates, HTTPS (for future use), API, SSH for link-local over USB\nEXPOSE 80/tcp 443/tcp 31950/tcp\nSTOPSIGNAL SIGTERM\n#   For backward compatibility, udev is enabled by default\nENV UDEV=\"on\"\n#   The one link we have to make in the dockerfile still to make sure we get our\n#   environment variables\nCOPY ./compute/find_python_module_path.py /usr/local/bin/\nCOPY ./compute/find_ot_resources.py /usr/local/bin\nRUN ln -sf /data/system/ot-environ.sh /etc/profile.d/00-persistent-ot-environ.sh \\\n && ln -sf `find_ot_resources.py `/ot-environ.sh /etc/profile.d/01-builtin-ot-environ.sh\n#   This configuration is used both by both the build and runtime so it has to\n#   be here. When building a container for local use, set this to 0. If set to\n#   0, ENABLE_VIRTUAL_SMOOTHIE will be set at runtime automatically\nARG running_on_pi='export RUNNING_ON_PI=1'\n#   Note: the quoting that defines the PATH echo is very specifically set up to\n#   get $PATH in the script literally so it is evaluated at container runtime.\nRUN echo \"export CONTAINER_ID=$( uuidgen ;)\" | tee -a /etc/profile.d/opentrons.sh \\\n && echo 'export PATH=$PATH:'\"`find_ot_resources.py `/scripts\" | tee -a /etc/profile.d/opentrons.sh \\\n && echo $running_on_pi | tee -a /etc/profile.d/opentrons.sh\nARG data_mkdir_path_slash_if_none=/\nRUN mkdir -p $data_mkdir_path_slash_if_none\n#   For interactive one-off use:\n#     docker run --name opentrons -it opentrons /bin/sh\n#   or uncomment:\n#   CMD [\"python\", \"-c\", \"while True: pass\"]\nCMD [\"bash\", \"-lc\", \"container_setup.sh\", \"&&\", \"setup.sh\", \"&&\", \"exec\", \"start.sh\"]\n#   Using Resin base image's default entrypoint and init system- tini\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"ARG base_image=resin/raspberrypi3-alpine-python:3.6-slim-20180120\n#  Use this for local development on intel machines\n#  FROM resin/amd64-alpine-python:3.6-slim-20180123\n#  Use this for running on a robot\nFROM $base_image\n#  See compute/README.md for details. Make sure to keep them in sync\nRUN apk add --update util-linux vim dropbear dropbear-scp gnupg openjdk8 nginx libstdc++ g++ networkmanager py3-zmq py3-urwid py3-numpy avrdude ffmpeg mpg123 \\\n && rm -rf /var/cache/apk/*\n#  Resin's python base container compiles python from scratch and doesn't have\n#  it installed as apk package. This results in py3- dependencies installing\n#  python3 package without being able to remove it (because py3- depend on it).\n#  To avoid ambiguity, we are copying all installed dependencies into original\n#  site-packages and cleaning up the one created by python3 package.\nRUN cp -r /usr/lib/python3.6/site-packages /usr/local/lib/python3.6/ \\\n && rm -rf /usr/lib/python3.6\nRUN pip install pipenv==9.0.3 jupyter==1.0.0 tornado==4.5.1 pyzmq==16.0.2 --force-reinstall\n#  Copy server files and data into the container. Note: any directories that\n#  you wish to copy into the container must be excluded from the .dockerignore\n#  file, or you will encounter a copy error\nCOPY ./compute/container_setup.sh /usr/local/bin/container_setup.sh\nCOPY ./audio/ /etc/audio\nCOPY ./shared-data/module /etc/module\nCOPY ./shared-data/pipette /etc/pipette\nCOPY ./shared-data/definitions /etc/labware\nCOPY ./api /tmp/api\n#  Make our shared data available for the api setup.py\nCOPY ./shared-data /tmp/shared-data\nCOPY ./update-server /tmp/update-server\nCOPY ./compute/avahi_tools /tmp/avahi_tools\n#  When adding more python packages make sure to use setuptools to keep\n#  packaging consistent across environments\nENV PIPENV_VENV_IN_PROJECT=\"true\"\nRUN pipenv install /tmp/api --system \\\n && pipenv install /tmp/update-server --system \\\n && pip install /tmp/avahi_tools \\\n && echo \"export OT_SYSTEM_VERSION=`python -c \"import json; print(json.load(open('/tmp/api/opentrons/package.json'))['version'])\" `\" | tee -a /etc/profile.d/opentrons.sh \\\n && rm -rf /tmp/api \\\n && rm -rf /tmp/update-server \\\n && rm -rf /tmp/shared-data \\\n && rm -rf /tmp/avahi_tools\n#  Redirect nginx logs to stdout and stderr\nRUN ln -sf /dev/stdout /var/log/nginx/access.log \\\n && ln -sf /dev/stderr /var/log/nginx/error.log\n#  Use udev rules file from opentrons_data\nRUN ln -sf /data/user_storage/opentrons_data/95-opentrons-modules.rules /etc/udev/rules.d/95-opentrons-modules.rules\n#  Logo for login shell\nCOPY ./compute/opentrons.motd /etc/motd\n#  Generate keys for dropbear\nCOPY ./compute/ssh_key_gen.sh /tmp/\nRUN /tmp/ssh_key_gen.sh\n#  Updates, HTTPS (for future use), API, SSH for link-local over USB\nEXPOSE 80/tcp 443/tcp 31950/tcp\nSTOPSIGNAL SIGTERM\n#  For backward compatibility, udev is enabled by default\nENV UDEV=\"on\"\n#  The one link we have to make in the dockerfile still to make sure we get our\n#  environment variables\nCOPY ./compute/find_python_module_path.py /usr/local/bin/\nCOPY ./compute/find_ot_resources.py /usr/local/bin\nRUN ln -sf /data/system/ot-environ.sh /etc/profile.d/00-persistent-ot-environ.sh \\\n && ln -sf `find_ot_resources.py `/ot-environ.sh /etc/profile.d/01-builtin-ot-environ.sh\n#  This configuration is used both by both the build and runtime so it has to\n#  be here. When building a container for local use, set this to 0. If set to\n#  0, ENABLE_VIRTUAL_SMOOTHIE will be set at runtime automatically\nARG running_on_pi='export RUNNING_ON_PI=1'\n#  Note: the quoting that defines the PATH echo is very specifically set up to\n#  get $PATH in the script literally so it is evaluated at container runtime.\nRUN echo \"export CONTAINER_ID=$( uuidgen ;)\" | tee -a /etc/profile.d/opentrons.sh \\\n && echo 'export PATH=$PATH:'\"`find_ot_resources.py `/scripts\" | tee -a /etc/profile.d/opentrons.sh \\\n && echo $running_on_pi | tee -a /etc/profile.d/opentrons.sh\nARG data_mkdir_path_slash_if_none=/\nRUN mkdir -p $data_mkdir_path_slash_if_none\n#  For interactive one-off use:\n#    docker run --name opentrons -it opentrons /bin/sh\n#  or uncomment:\n#  CMD [\"python\", \"-c\", \"while True: pass\"]\nCMD [\"bash\", \"-lc\", \"container_setup.sh\", \"&&\", \"setup.sh\", \"&&\", \"exec\", \"start.sh\"]\n#  Using Resin base image's default entrypoint and init system- tini\n","injectedSmells":[],"originalDockerfileHash":"71fcbe46193ca2466a18f5e8da5bb258","successfullyInjectedSmells":[],"originalDockerfileUglified":"ARG base_image=resin/raspberrypi3-alpine-python:3.6-slim-20180120\n#   Use this for local development on intel machines\n#   FROM resin/amd64-alpine-python:3.6-slim-20180123\n#   Use this for running on a robot\nFROM $base_image\n#   See compute/README.md for details. Make sure to keep them in sync\nRUN apk add --update util-linux vim dropbear dropbear-scp gnupg openjdk8 nginx libstdc++ g++ networkmanager py3-zmq py3-urwid py3-numpy avrdude ffmpeg mpg123 \\\n && rm -rf /var/cache/apk/*\n#   Resin's python base container compiles python from scratch and doesn't have\n#   it installed as apk package. This results in py3- dependencies installing\n#   python3 package without being able to remove it (because py3- depend on it).\n#   To avoid ambiguity, we are copying all installed dependencies into original\n#   site-packages and cleaning up the one created by python3 package.\nRUN cp -r /usr/lib/python3.6/site-packages /usr/local/lib/python3.6/ \\\n && rm -rf /usr/lib/python3.6\nRUN pip install pipenv==9.0.3 jupyter==1.0.0 tornado==4.5.1 pyzmq==16.0.2 --force-reinstall\n#   Copy server files and data into the container. Note: any directories that\n#   you wish to copy into the container must be excluded from the .dockerignore\n#   file, or you will encounter a copy error\nCOPY ./compute/container_setup.sh /usr/local/bin/container_setup.sh\nCOPY ./audio/ /etc/audio\nCOPY ./shared-data/module /etc/module\nCOPY ./shared-data/pipette /etc/pipette\nCOPY ./shared-data/definitions /etc/labware\nCOPY ./api /tmp/api\n#   Make our shared data available for the api setup.py\nCOPY ./shared-data /tmp/shared-data\nCOPY ./update-server /tmp/update-server\nCOPY ./compute/avahi_tools /tmp/avahi_tools\n#   When adding more python packages make sure to use setuptools to keep\n#   packaging consistent across environments\nENV PIPENV_VENV_IN_PROJECT=\"true\"\nRUN pipenv install /tmp/api --system \\\n && pipenv install /tmp/update-server --system \\\n && pip install /tmp/avahi_tools \\\n && echo \"export OT_SYSTEM_VERSION=`python -c \"import json; print(json.load(open('/tmp/api/opentrons/package.json'))['version'])\" `\" | tee -a /etc/profile.d/opentrons.sh \\\n && rm -rf /tmp/api \\\n && rm -rf /tmp/update-server \\\n && rm -rf /tmp/shared-data \\\n && rm -rf /tmp/avahi_tools\n#   Redirect nginx logs to stdout and stderr\nRUN ln -sf /dev/stdout /var/log/nginx/access.log \\\n && ln -sf /dev/stderr /var/log/nginx/error.log\n#   Use udev rules file from opentrons_data\nRUN ln -sf /data/user_storage/opentrons_data/95-opentrons-modules.rules /etc/udev/rules.d/95-opentrons-modules.rules\n#   Logo for login shell\nCOPY ./compute/opentrons.motd /etc/motd\n#   Generate keys for dropbear\nCOPY ./compute/ssh_key_gen.sh /tmp/\nRUN /tmp/ssh_key_gen.sh\n#   Updates, HTTPS (for future use), API, SSH for link-local over USB\nEXPOSE 80/tcp 443/tcp 31950/tcp\nSTOPSIGNAL SIGTERM\n#   For backward compatibility, udev is enabled by default\nENV UDEV=\"on\"\n#   The one link we have to make in the dockerfile still to make sure we get our\n#   environment variables\nCOPY ./compute/find_python_module_path.py /usr/local/bin/\nCOPY ./compute/find_ot_resources.py /usr/local/bin\nRUN ln -sf /data/system/ot-environ.sh /etc/profile.d/00-persistent-ot-environ.sh \\\n && ln -sf `find_ot_resources.py `/ot-environ.sh /etc/profile.d/01-builtin-ot-environ.sh\n#   This configuration is used both by both the build and runtime so it has to\n#   be here. When building a container for local use, set this to 0. If set to\n#   0, ENABLE_VIRTUAL_SMOOTHIE will be set at runtime automatically\nARG running_on_pi='export RUNNING_ON_PI=1'\n#   Note: the quoting that defines the PATH echo is very specifically set up to\n#   get $PATH in the script literally so it is evaluated at container runtime.\nRUN echo \"export CONTAINER_ID=$( uuidgen ;)\" | tee -a /etc/profile.d/opentrons.sh \\\n && echo 'export PATH=$PATH:'\"`find_ot_resources.py `/scripts\" | tee -a /etc/profile.d/opentrons.sh \\\n && echo $running_on_pi | tee -a /etc/profile.d/opentrons.sh\nARG data_mkdir_path_slash_if_none=/\nRUN mkdir -p $data_mkdir_path_slash_if_none\n#   For interactive one-off use:\n#     docker run --name opentrons -it opentrons /bin/sh\n#   or uncomment:\n#   CMD [\"python\", \"-c\", \"while True: pass\"]\nCMD [\"bash\", \"-lc\", \"container_setup.sh\", \"&&\", \"setup.sh\", \"&&\", \"exec\", \"start.sh\"]\n#   Using Resin base image's default entrypoint and init system- tini\n","originalDockerfileUglifiedHash":"162127ec5d65ef99d233ed806d98dba4","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/058ed591f4db2781adf8e4f6fb05b6189f68348f.dockerfile"}