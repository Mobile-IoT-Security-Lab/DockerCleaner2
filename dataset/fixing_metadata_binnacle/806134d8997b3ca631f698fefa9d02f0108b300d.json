{"seed":4224278823,"processedDockerfileHash":"74da0fdc8989a888a825885524e149a8","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","use-copy-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"processedDockerfile":"#  ###############################################################################\n#   Licensed to the Apache Software Foundation (ASF) under one\n#   or more contributor license agreements.  See the NOTICE file\n#   distributed with this work for additional information\n#   regarding copyright ownership.  The ASF licenses this file\n#   to you under the Apache License, Version 2.0 (the\n#   \"License\"); you may not use this file except in compliance\n#   with the License.  You may obtain a copy of the License at\n#\n#       http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#  ###############################################################################\n#\n#   This image is modified version of Knappek/docker-hadoop-secure\n#     * Knappek/docker-hadoop-secure <https://github.com/Knappek/docker-hadoop-secure>\n#\n#   With bits and pieces added from Lewuathe/docker-hadoop-cluster to extend it to start a proper kerberized Hadoop cluster:\n#     * Lewuathe/docker-hadoop-cluster <https://github.com/Lewuathe/docker-hadoop-cluster>\n#\n#   Creates multi-node, kerberized Hadoop cluster on Docker\nFROM sequenceiq/pam:ubuntu-14.04\nRUN set -x \\\n && addgroup hadoop \\\n && useradd -d /home/hdfs -ms /bin/bash -G hadoop -p hdfs hdfs \\\n && useradd -d /home/yarn -ms /bin/bash -G hadoop -p yarn yarn \\\n && useradd -d /home/mapred -ms /bin/bash -G hadoop -p mapred mapred \\\n && useradd -d /home/hadoop-user -ms /bin/bash -p hadoop-user hadoop-user\n#   install dev tools\nRUN set -x \\\n && apt-get update \\\n && apt-get install --no-install-recommends curl tar sudo openssh-server openssh-client rsync unzip krb5-user -y\n#   Kerberos client\nRUN set -x \\\n && mkdir -p /var/log/kerberos \\\n && touch /var/log/kerberos/kadmind.log\n#   passwordless ssh\nRUN set -x \\\n && rm -f /etc/ssh/ssh_host_dsa_key /etc/ssh/ssh_host_rsa_key /root/.ssh/id_rsa \\\n && ssh-keygen -q -N \"\" -t dsa -f /etc/ssh/ssh_host_dsa_key \\\n && ssh-keygen -q -N \"\" -t rsa -f /etc/ssh/ssh_host_rsa_key \\\n && ssh-keygen -q -N \"\" -t rsa -f /root/.ssh/id_rsa \\\n && cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys\n#   java\nRUN set -x \\\n && mkdir -p /usr/java/default \\\n && curl -Ls 'http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz' -H 'Cookie: oraclelicense=accept-securebackup-cookie' | tar --strip-components=1 -xz -C /usr/java/default/\nENV JAVA_HOME=\"/usr/java/default\"\nENV PATH=\"$PATH:$JAVA_HOME/bin\"\nRUN set -x \\\n && curl -LOH 'Cookie: oraclelicense=accept-securebackup-cookie' 'http://download.oracle.com/otn-pub/java/jce/8/jce_policy-8.zip' \\\n && unzip jce_policy-8.zip \\\n && cp /UnlimitedJCEPolicyJDK8/local_policy.jar /UnlimitedJCEPolicyJDK8/US_export_policy.jar $JAVA_HOME/jre/lib/security\nARG HADOOP_VERSION=2.8.4\nENV HADOOP_URL=\"http://archive.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz\"\nRUN set -x \\\n && curl -fSL \"$HADOOP_URL\" -o /tmp/hadoop.tar.gz \\\n && tar -xf /tmp/hadoop.tar.gz -C /usr/local/ \\\n && rm /tmp/hadoop.tar.gz*\nWORKDIR /usr/local\nRUN set -x \\\n && ln -s /usr/local/hadoop-${HADOOP_VERSION} /usr/local/hadoop \\\n && chown root:root -R /usr/local/hadoop-${HADOOP_VERSION}/ \\\n && chown root:root -R /usr/local/hadoop/ \\\n && chown root:yarn /usr/local/hadoop/bin/container-executor \\\n && chmod 6050 /usr/local/hadoop/bin/container-executor \\\n && mkdir -p /hadoop-data/nm-local-dirs \\\n && mkdir -p /hadoop-data/nm-log-dirs \\\n && chown yarn:yarn /hadoop-data \\\n && chown yarn:yarn /hadoop-data/nm-local-dirs \\\n && chown yarn:yarn /hadoop-data/nm-log-dirs \\\n && chmod 755 /hadoop-data \\\n && chmod 755 /hadoop-data/nm-local-dirs \\\n && chmod 755 /hadoop-data/nm-log-dirs\nENV HADOOP_HOME=\"/usr/local/hadoop\"\nENV HADOOP_COMMON_HOME=\"/usr/local/hadoop\"\nENV HADOOP_HDFS_HOME=\"/usr/local/hadoop\"\nENV HADOOP_MAPRED_HOME=\"/usr/local/hadoop\"\nENV HADOOP_YARN_HOME=\"/usr/local/hadoop\"\nENV HADOOP_CONF_DIR=\"/usr/local/hadoop/etc/hadoop\"\nENV YARN_CONF_DIR=\"/usr/local/hadoop/etc/hadoop\"\nENV HADOOP_LOG_DIR=\"/var/log/hadoop\"\nENV HADOOP_BIN_HOME=\"$HADOOP_HOME/bin\"\nENV PATH=\"$PATH:$HADOOP_BIN_HOME\"\nENV KRB_REALM=\"EXAMPLE.COM\"\nENV DOMAIN_REALM=\"example.com\"\nENV KERBEROS_ADMIN=\"admin/admin\"\n# A secret has been removed here. Please do not provide secrets from the Dockerfile as these will leak into the metadata of the resulting docker image. To provide secrets the --secret flag of the docker build command can be used (https://docs.docker.com/develop/develop-images/build_enhancements/#new-docker-build-secret-information).\nENV KEYTAB_DIR=\"/etc/security/keytabs\"\nRUN mkdir /var/log/hadoop\nCOPY config/core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml\nCOPY config/hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml\nCOPY config/mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml\nCOPY config/yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml\nCOPY config/container-executor.cfg $HADOOP_HOME/etc/hadoop/container-executor.cfg\nCOPY config/krb5.conf /etc/krb5.conf\nCOPY config/ssl-server.xml $HADOOP_HOME/etc/hadoop/ssl-server.xml\nCOPY config/ssl-client.xml $HADOOP_HOME/etc/hadoop/ssl-client.xml\nCOPY config/keystore.jks $HADOOP_HOME/lib/keystore.jks\nRUN set -x \\\n && chmod 400 $HADOOP_HOME/etc/hadoop/container-executor.cfg \\\n && chown root:yarn $HADOOP_HOME/etc/hadoop/container-executor.cfg\nCOPY config/ssh_config /root/.ssh/config\nRUN set -x \\\n && chmod 600 /root/.ssh/config \\\n && chown root:root /root/.ssh/config\n#   workingaround docker.io build error\nRUN set -x \\\n && ls -la /usr/local/hadoop/etc/hadoop/*-env.sh \\\n && chmod +x /usr/local/hadoop/etc/hadoop/*-env.sh \\\n && ls -la /usr/local/hadoop/etc/hadoop/*-env.sh\n#   fix the 254 error code\nRUN set -x \\\n && sed -i \"/^[^#]*UsePAM/ s/.*/#&/\" /etc/ssh/sshd_config \\\n && echo \"UsePAM no\" >> /etc/ssh/sshd_config \\\n && echo \"Port 2122\" >> /etc/ssh/sshd_config\n#   Hdfs ports\nEXPOSE 50470/tcp 9000/tcp 50010/tcp 50020/tcp 50070/tcp 50075/tcp 50090/tcp 50475/tcp 50091/tcp 8020/tcp\n#   Mapred ports\nEXPOSE 19888/tcp\n#   Yarn ports\nEXPOSE 8030/tcp 8031/tcp 8032/tcp 8033/tcp 8040/tcp 8042/tcp 8088/tcp 8188/tcp\n#   Other ports\nEXPOSE 49707/tcp 2122/tcp\nCOPY bootstrap.sh /etc/bootstrap.sh\nRUN chown root:root /etc/bootstrap.sh\nRUN chmod 700 /etc/bootstrap.sh\nENV BOOTSTRAP=\"/etc/bootstrap.sh\"\nENTRYPOINT [\"/etc/bootstrap.sh\"]\nCMD [\"-h\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"# ###############################################################################\n#  Licensed to the Apache Software Foundation (ASF) under one\n#  or more contributor license agreements.  See the NOTICE file\n#  distributed with this work for additional information\n#  regarding copyright ownership.  The ASF licenses this file\n#  to you under the Apache License, Version 2.0 (the\n#  \"License\"); you may not use this file except in compliance\n#  with the License.  You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n#  Unless required by applicable law or agreed to in writing, software\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#  See the License for the specific language governing permissions and\n#  limitations under the License.\n# ###############################################################################\n#\n#  This image is modified version of Knappek/docker-hadoop-secure\n#    * Knappek/docker-hadoop-secure <https://github.com/Knappek/docker-hadoop-secure>\n#\n#  With bits and pieces added from Lewuathe/docker-hadoop-cluster to extend it to start a proper kerberized Hadoop cluster:\n#    * Lewuathe/docker-hadoop-cluster <https://github.com/Lewuathe/docker-hadoop-cluster>\n#\n#  Creates multi-node, kerberized Hadoop cluster on Docker\nFROM sequenceiq/pam:ubuntu-14.04\nRUN set -x \\\n && addgroup hadoop \\\n && useradd -d /home/hdfs -ms /bin/bash -G hadoop -p hdfs hdfs \\\n && useradd -d /home/yarn -ms /bin/bash -G hadoop -p yarn yarn \\\n && useradd -d /home/mapred -ms /bin/bash -G hadoop -p mapred mapred \\\n && useradd -d /home/hadoop-user -ms /bin/bash -p hadoop-user hadoop-user\n#  install dev tools\nRUN set -x \\\n && apt-get update \\\n && apt-get install curl tar sudo openssh-server openssh-client rsync unzip krb5-user -y\n#  Kerberos client\nRUN set -x \\\n && mkdir -p /var/log/kerberos \\\n && touch /var/log/kerberos/kadmind.log\n#  passwordless ssh\nRUN set -x \\\n && rm -f /etc/ssh/ssh_host_dsa_key /etc/ssh/ssh_host_rsa_key /root/.ssh/id_rsa \\\n && ssh-keygen -q -N \"\" -t dsa -f /etc/ssh/ssh_host_dsa_key \\\n && ssh-keygen -q -N \"\" -t rsa -f /etc/ssh/ssh_host_rsa_key \\\n && ssh-keygen -q -N \"\" -t rsa -f /root/.ssh/id_rsa \\\n && cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys\n#  java\nRUN set -x \\\n && mkdir -p /usr/java/default \\\n && curl -Ls 'http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz' -H 'Cookie: oraclelicense=accept-securebackup-cookie' | tar --strip-components=1 -xz -C /usr/java/default/\nENV JAVA_HOME=\"/usr/java/default\"\nENV PATH=\"$PATH:$JAVA_HOME/bin\"\nRUN set -x \\\n && curl -LOH 'Cookie: oraclelicense=accept-securebackup-cookie' 'http://download.oracle.com/otn-pub/java/jce/8/jce_policy-8.zip' \\\n && unzip jce_policy-8.zip \\\n && cp /UnlimitedJCEPolicyJDK8/local_policy.jar /UnlimitedJCEPolicyJDK8/US_export_policy.jar $JAVA_HOME/jre/lib/security\nARG HADOOP_VERSION=2.8.4\nENV HADOOP_URL=\"http://archive.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz\"\nRUN set -x \\\n && curl -fSL \"$HADOOP_URL\" -o /tmp/hadoop.tar.gz \\\n && tar -xf /tmp/hadoop.tar.gz -C /usr/local/ \\\n && rm /tmp/hadoop.tar.gz*\nWORKDIR /usr/local\nRUN set -x \\\n && ln -s /usr/local/hadoop-${HADOOP_VERSION} /usr/local/hadoop \\\n && chown root:root -R /usr/local/hadoop-${HADOOP_VERSION}/ \\\n && chown root:root -R /usr/local/hadoop/ \\\n && chown root:yarn /usr/local/hadoop/bin/container-executor \\\n && chmod 6050 /usr/local/hadoop/bin/container-executor \\\n && mkdir -p /hadoop-data/nm-local-dirs \\\n && mkdir -p /hadoop-data/nm-log-dirs \\\n && chown yarn:yarn /hadoop-data \\\n && chown yarn:yarn /hadoop-data/nm-local-dirs \\\n && chown yarn:yarn /hadoop-data/nm-log-dirs \\\n && chmod 755 /hadoop-data \\\n && chmod 755 /hadoop-data/nm-local-dirs \\\n && chmod 755 /hadoop-data/nm-log-dirs\nENV HADOOP_HOME=\"/usr/local/hadoop\"\nENV HADOOP_COMMON_HOME=\"/usr/local/hadoop\"\nENV HADOOP_HDFS_HOME=\"/usr/local/hadoop\"\nENV HADOOP_MAPRED_HOME=\"/usr/local/hadoop\"\nENV HADOOP_YARN_HOME=\"/usr/local/hadoop\"\nENV HADOOP_CONF_DIR=\"/usr/local/hadoop/etc/hadoop\"\nENV YARN_CONF_DIR=\"/usr/local/hadoop/etc/hadoop\"\nENV HADOOP_LOG_DIR=\"/var/log/hadoop\"\nENV HADOOP_BIN_HOME=\"$HADOOP_HOME/bin\"\nENV PATH=\"$PATH:$HADOOP_BIN_HOME\"\nENV KRB_REALM=\"EXAMPLE.COM\"\nENV DOMAIN_REALM=\"example.com\"\nENV KERBEROS_ADMIN=\"admin/admin\"\nENV KERBEROS_ADMIN_PASSWORD=\"admin\"\nENV KEYTAB_DIR=\"/etc/security/keytabs\"\nRUN mkdir /var/log/hadoop\nADD config/core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml\nADD config/hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml\nADD config/mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml\nADD config/yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml\nADD config/container-executor.cfg $HADOOP_HOME/etc/hadoop/container-executor.cfg\nADD config/krb5.conf /etc/krb5.conf\nADD config/ssl-server.xml $HADOOP_HOME/etc/hadoop/ssl-server.xml\nADD config/ssl-client.xml $HADOOP_HOME/etc/hadoop/ssl-client.xml\nADD config/keystore.jks $HADOOP_HOME/lib/keystore.jks\nRUN set -x \\\n && chmod 400 $HADOOP_HOME/etc/hadoop/container-executor.cfg \\\n && chown root:yarn $HADOOP_HOME/etc/hadoop/container-executor.cfg\nADD config/ssh_config /root/.ssh/config\nRUN set -x \\\n && chmod 600 /root/.ssh/config \\\n && chown root:root /root/.ssh/config\n#  workingaround docker.io build error\nRUN set -x \\\n && ls -la /usr/local/hadoop/etc/hadoop/*-env.sh \\\n && chmod +x /usr/local/hadoop/etc/hadoop/*-env.sh \\\n && ls -la /usr/local/hadoop/etc/hadoop/*-env.sh\n#  fix the 254 error code\nRUN set -x \\\n && sed -i \"/^[^#]*UsePAM/ s/.*/#&/\" /etc/ssh/sshd_config \\\n && echo \"UsePAM no\" >> /etc/ssh/sshd_config \\\n && echo \"Port 2122\" >> /etc/ssh/sshd_config\n#  Hdfs ports\nEXPOSE 50470/tcp 9000/tcp 50010/tcp 50020/tcp 50070/tcp 50075/tcp 50090/tcp 50475/tcp 50091/tcp 8020/tcp\n#  Mapred ports\nEXPOSE 19888/tcp\n#  Yarn ports\nEXPOSE 8030/tcp 8031/tcp 8032/tcp 8033/tcp 8040/tcp 8042/tcp 8088/tcp 8188/tcp\n#  Other ports\nEXPOSE 49707/tcp 2122/tcp\nADD bootstrap.sh /etc/bootstrap.sh\nRUN chown root:root /etc/bootstrap.sh\nRUN chmod 700 /etc/bootstrap.sh\nENV BOOTSTRAP=\"/etc/bootstrap.sh\"\nENTRYPOINT [\"/etc/bootstrap.sh\"]\nCMD [\"-h\"]\n","injectedSmells":[],"originalDockerfileHash":"5f69f696ec3eb3facaa96a98fbc96127","successfullyInjectedSmells":[],"originalDockerfileUglified":"#  ###############################################################################\n#   Licensed to the Apache Software Foundation (ASF) under one\n#   or more contributor license agreements.  See the NOTICE file\n#   distributed with this work for additional information\n#   regarding copyright ownership.  The ASF licenses this file\n#   to you under the Apache License, Version 2.0 (the\n#   \"License\"); you may not use this file except in compliance\n#   with the License.  You may obtain a copy of the License at\n#\n#       http://www.apache.org/licenses/LICENSE-2.0\n#\n#   Unless required by applicable law or agreed to in writing, software\n#   distributed under the License is distributed on an \"AS IS\" BASIS,\n#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#   See the License for the specific language governing permissions and\n#   limitations under the License.\n#  ###############################################################################\n#\n#   This image is modified version of Knappek/docker-hadoop-secure\n#     * Knappek/docker-hadoop-secure <https://github.com/Knappek/docker-hadoop-secure>\n#\n#   With bits and pieces added from Lewuathe/docker-hadoop-cluster to extend it to start a proper kerberized Hadoop cluster:\n#     * Lewuathe/docker-hadoop-cluster <https://github.com/Lewuathe/docker-hadoop-cluster>\n#\n#   Creates multi-node, kerberized Hadoop cluster on Docker\nFROM sequenceiq/pam:ubuntu-14.04\nRUN set -x \\\n && addgroup hadoop \\\n && useradd -d /home/hdfs -ms /bin/bash -G hadoop -p hdfs hdfs \\\n && useradd -d /home/yarn -ms /bin/bash -G hadoop -p yarn yarn \\\n && useradd -d /home/mapred -ms /bin/bash -G hadoop -p mapred mapred \\\n && useradd -d /home/hadoop-user -ms /bin/bash -p hadoop-user hadoop-user\n#   install dev tools\nRUN set -x \\\n && apt-get update \\\n && apt-get install curl tar sudo openssh-server openssh-client rsync unzip krb5-user -y\n#   Kerberos client\nRUN set -x \\\n && mkdir -p /var/log/kerberos \\\n && touch /var/log/kerberos/kadmind.log\n#   passwordless ssh\nRUN set -x \\\n && rm -f /etc/ssh/ssh_host_dsa_key /etc/ssh/ssh_host_rsa_key /root/.ssh/id_rsa \\\n && ssh-keygen -q -N \"\" -t dsa -f /etc/ssh/ssh_host_dsa_key \\\n && ssh-keygen -q -N \"\" -t rsa -f /etc/ssh/ssh_host_rsa_key \\\n && ssh-keygen -q -N \"\" -t rsa -f /root/.ssh/id_rsa \\\n && cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys\n#   java\nRUN set -x \\\n && mkdir -p /usr/java/default \\\n && curl -Ls 'http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz' -H 'Cookie: oraclelicense=accept-securebackup-cookie' | tar --strip-components=1 -xz -C /usr/java/default/\nENV JAVA_HOME=\"/usr/java/default\"\nENV PATH=\"$PATH:$JAVA_HOME/bin\"\nRUN set -x \\\n && curl -LOH 'Cookie: oraclelicense=accept-securebackup-cookie' 'http://download.oracle.com/otn-pub/java/jce/8/jce_policy-8.zip' \\\n && unzip jce_policy-8.zip \\\n && cp /UnlimitedJCEPolicyJDK8/local_policy.jar /UnlimitedJCEPolicyJDK8/US_export_policy.jar $JAVA_HOME/jre/lib/security\nARG HADOOP_VERSION=2.8.4\nENV HADOOP_URL=\"http://archive.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz\"\nRUN set -x \\\n && curl -fSL \"$HADOOP_URL\" -o /tmp/hadoop.tar.gz \\\n && tar -xf /tmp/hadoop.tar.gz -C /usr/local/ \\\n && rm /tmp/hadoop.tar.gz*\nWORKDIR /usr/local\nRUN set -x \\\n && ln -s /usr/local/hadoop-${HADOOP_VERSION} /usr/local/hadoop \\\n && chown root:root -R /usr/local/hadoop-${HADOOP_VERSION}/ \\\n && chown root:root -R /usr/local/hadoop/ \\\n && chown root:yarn /usr/local/hadoop/bin/container-executor \\\n && chmod 6050 /usr/local/hadoop/bin/container-executor \\\n && mkdir -p /hadoop-data/nm-local-dirs \\\n && mkdir -p /hadoop-data/nm-log-dirs \\\n && chown yarn:yarn /hadoop-data \\\n && chown yarn:yarn /hadoop-data/nm-local-dirs \\\n && chown yarn:yarn /hadoop-data/nm-log-dirs \\\n && chmod 755 /hadoop-data \\\n && chmod 755 /hadoop-data/nm-local-dirs \\\n && chmod 755 /hadoop-data/nm-log-dirs\nENV HADOOP_HOME=\"/usr/local/hadoop\"\nENV HADOOP_COMMON_HOME=\"/usr/local/hadoop\"\nENV HADOOP_HDFS_HOME=\"/usr/local/hadoop\"\nENV HADOOP_MAPRED_HOME=\"/usr/local/hadoop\"\nENV HADOOP_YARN_HOME=\"/usr/local/hadoop\"\nENV HADOOP_CONF_DIR=\"/usr/local/hadoop/etc/hadoop\"\nENV YARN_CONF_DIR=\"/usr/local/hadoop/etc/hadoop\"\nENV HADOOP_LOG_DIR=\"/var/log/hadoop\"\nENV HADOOP_BIN_HOME=\"$HADOOP_HOME/bin\"\nENV PATH=\"$PATH:$HADOOP_BIN_HOME\"\nENV KRB_REALM=\"EXAMPLE.COM\"\nENV DOMAIN_REALM=\"example.com\"\nENV KERBEROS_ADMIN=\"admin/admin\"\nENV KERBEROS_ADMIN_PASSWORD=\"admin\"\nENV KEYTAB_DIR=\"/etc/security/keytabs\"\nRUN mkdir /var/log/hadoop\nADD config/core-site.xml $HADOOP_HOME/etc/hadoop/core-site.xml\nADD config/hdfs-site.xml $HADOOP_HOME/etc/hadoop/hdfs-site.xml\nADD config/mapred-site.xml $HADOOP_HOME/etc/hadoop/mapred-site.xml\nADD config/yarn-site.xml $HADOOP_HOME/etc/hadoop/yarn-site.xml\nADD config/container-executor.cfg $HADOOP_HOME/etc/hadoop/container-executor.cfg\nADD config/krb5.conf /etc/krb5.conf\nADD config/ssl-server.xml $HADOOP_HOME/etc/hadoop/ssl-server.xml\nADD config/ssl-client.xml $HADOOP_HOME/etc/hadoop/ssl-client.xml\nADD config/keystore.jks $HADOOP_HOME/lib/keystore.jks\nRUN set -x \\\n && chmod 400 $HADOOP_HOME/etc/hadoop/container-executor.cfg \\\n && chown root:yarn $HADOOP_HOME/etc/hadoop/container-executor.cfg\nADD config/ssh_config /root/.ssh/config\nRUN set -x \\\n && chmod 600 /root/.ssh/config \\\n && chown root:root /root/.ssh/config\n#   workingaround docker.io build error\nRUN set -x \\\n && ls -la /usr/local/hadoop/etc/hadoop/*-env.sh \\\n && chmod +x /usr/local/hadoop/etc/hadoop/*-env.sh \\\n && ls -la /usr/local/hadoop/etc/hadoop/*-env.sh\n#   fix the 254 error code\nRUN set -x \\\n && sed -i \"/^[^#]*UsePAM/ s/.*/#&/\" /etc/ssh/sshd_config \\\n && echo \"UsePAM no\" >> /etc/ssh/sshd_config \\\n && echo \"Port 2122\" >> /etc/ssh/sshd_config\n#   Hdfs ports\nEXPOSE 50470/tcp 9000/tcp 50010/tcp 50020/tcp 50070/tcp 50075/tcp 50090/tcp 50475/tcp 50091/tcp 8020/tcp\n#   Mapred ports\nEXPOSE 19888/tcp\n#   Yarn ports\nEXPOSE 8030/tcp 8031/tcp 8032/tcp 8033/tcp 8040/tcp 8042/tcp 8088/tcp 8188/tcp\n#   Other ports\nEXPOSE 49707/tcp 2122/tcp\nADD bootstrap.sh /etc/bootstrap.sh\nRUN chown root:root /etc/bootstrap.sh\nRUN chmod 700 /etc/bootstrap.sh\nENV BOOTSTRAP=\"/etc/bootstrap.sh\"\nENTRYPOINT [\"/etc/bootstrap.sh\"]\nCMD [\"-h\"]\n","originalDockerfileUglifiedHash":"dd1524002d33e5f66242b97c6b696c0f","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/806134d8997b3ca631f698fefa9d02f0108b300d.dockerfile"}