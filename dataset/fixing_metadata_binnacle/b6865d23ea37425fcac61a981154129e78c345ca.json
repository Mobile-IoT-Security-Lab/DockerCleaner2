{"seed":3959836460,"processedDockerfileHash":"5ad66ccba49668dd2a8f80d99c7c20e5","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-apt-get","pin-package-manager-versions-apk","use-copy-instead-of-add","have-a-healthcheck","have-a-user"],"processedDockerfile":"FROM debian AS compile-lkd\nMAINTAINER Marios Andreopoulos <marios@landoop.com>\nRUN apt-get update \\\n && apt-get install --no-install-recommends unzip=6.0-27ubuntu1 wget=1.21.3-1ubuntu1 -y \\\n && rm -rf /var/lib/apt/lists/* \\\n && echo \"progress = dot:giga\" | tee /etc/wgetrc \\\n && mkdir -p /mnt /opt /data \\\n && wget https://github.com/andmarios/duphard/releases/download/v1.0/duphard -O /bin/duphard \\\n && chmod +x /bin/duphard\nSHELL [\"/bin/bash\", \"-c\"]\nWORKDIR /\n#   Login args for development archives\nARG DEVARCH_USER\nARG DEVARCH_PASS\nARG ARCHIVE_SERVER=https://archive.landoop.com\nARG LKD_VERSION=2.0.1\n#  ###########\n#   Add kafka/\n#  ###########\n#   Add Apache Kafka (includes Connect and Zookeeper)\nARG KAFKA_VERSION=2.0.1\nARG KAFKA_LVERSION=\"${KAFKA_VERSION}-L0\"\nARG KAFKA_URL=\"${ARCHIVE_SERVER}/lkd/packages/kafka/kafka-2.12-${KAFKA_LVERSION}-lkd.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_URL\" -O /opt/kafka.tar.gz \\\n && tar --no-same-owner -xzf /opt/kafka.tar.gz -C /opt \\\n && mkdir /opt/landoop/kafka/logs \\\n && chmod 1777 /opt/landoop/kafka/logs \\\n && rm -rf /opt/kafka.tar.gz\n#   Add Schema Registry and REST Proxy\nARG REGISTRY_VERSION=5.0.1-lkd-r0\nARG REGISTRY_URL=\"${ARCHIVE_SERVER}/lkd/packages/schema-registry/schema-registry-${REGISTRY_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$REGISTRY_URL\" -O /opt/registry.tar.gz \\\n && tar --no-same-owner -xzf /opt/registry.tar.gz -C /opt/ \\\n && rm -rf /opt/registry.tar.gz\nARG REST_VERSION=5.0.1-lkd-r0\nARG REST_URL=\"${ARCHIVE_SERVER}/lkd/packages/rest-proxy/rest-proxy-${REST_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$REST_URL\" -O /opt/rest.tar.gz \\\n && tar --no-same-owner -xzf /opt/rest.tar.gz -C /opt/ \\\n && rm -rf /opt/rest.tar.gz\n#   Configure Connect and Confluent Components to support CORS\nRUN echo -e 'access.control.allow.methods=GET,POST,PUT,DELETE,OPTIONS\\naccess.control.allow.origin=*' | tee -a /opt/landoop/kafka/etc/schema-registry/schema-registry.properties | tee -a /opt/landoop/kafka/etc/kafka-rest/kafka-rest.properties | tee -a /opt/landoop/kafka/etc/schema-registry/connect-avro-distributed.properties\n#  ################\n#   Add connectors/\n#  ################\n#   Add Stream Reactor and needed components\nARG STREAM_REACTOR_VERSION=1.2.0\nARG KAFKA_VERSION_4SR=2.0.0\nARG STREAM_REACTOR_URL=\"https://archive.landoop.com/lkd/packages/connectors/stream-reactor/stream-reactor-${STREAM_REACTOR_VERSION}_connect${KAFKA_VERSION_4SR}.tar.gz\"\nARG ELASTICSEARCH_2X_VERSION=2.4.6\nARG ACTIVEMQ_VERSION=5.12.3\nARG CALCITE_LINQ4J_VERSION=1.12.0\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"${STREAM_REACTOR_URL}\" -O /stream-reactor.tar.gz \\\n && mkdir -p /opt/landoop/connectors/stream-reactor \\\n && tar -xf /stream-reactor.tar.gz --no-same-owner --strip-components=1 -C /opt/landoop/connectors/stream-reactor \\\n && rm /stream-reactor.tar.gz \\\n && wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/${ELASTICSEARCH_2X_VERSION}/elasticsearch-${ELASTICSEARCH_2X_VERSION}.tar.gz -O /elasticsearch.tar.gz \\\n && mkdir /elasticsearch \\\n && tar -xf /elasticsearch.tar.gz --no-same-owner --strip-components=1 -C /elasticsearch \\\n && rm -f /elasticsearch/lib/apache-log4j-extras* \\\n && mv /elasticsearch/lib/*.jar /opt/landoop/connectors/stream-reactor/kafka-connect-elastic/ \\\n && rm -rf /elasticsearch* \\\n && wget http://central.maven.org/maven2/org/apache/activemq/activemq-all/${ACTIVEMQ_VERSION}/activemq-all-${ACTIVEMQ_VERSION}.jar -P /opt/landoop/connectors/stream-reactor/kafka-connect-jms \\\n && wget http://central.maven.org/maven2/org/apache/calcite/calcite-linq4j/${CALCITE_LINQ4J_VERSION}/calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar -O /calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar \\\n && for path in /opt/landoop/connectors/stream-reactor/kafka-connect-*; do cp /calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar $path/ ; done \\\n && rm /calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar \\\n && mkdir -p /opt/landoop/kafka/share/java/landoop-common \\\n && for file in $( find /opt/landoop/connectors/stream-reactor -maxdepth 2 -type f -exec basename {} | grep -Ev \"scala-logging|kafka-connect-common|scala-\" | sort | uniq -c | grep -E \"^\\s+22 \" | awk '{print $2}' ;); do cp /opt/landoop/connectors/stream-reactor/kafka-connect-elastic/$file /opt/landoop/kafka/share/java/landoop-common/ ;rm -f /opt/landoop/connectors/stream-reactor/kafka-connect-*/$file ; done \\\n && for file in $( find /opt/landoop/kafka/share/java/{kafka,landoop-common} -maxdepth 1 -type f -exec basename {} | sort | uniq -c | grep -E \"^\\s+2 \" | awk '{print $2}' ;); do echo \"Removing duplicate /opt/landoop/kafka/share/java/landoop-common/$file.\" ;rm -f /opt/landoop/kafka/share/java/landoop-common/$file ; done \\\n && rm -f /opt/landoop/connectors/stream-reactor/*/*{javadoc,scaladoc,sources}.jar \\\n && echo \"plugin.path=/opt/landoop/connectors/stream-reactor,/opt/landoop/connectors/third-party\" >> /opt/landoop/kafka/etc/schema-registry/connect-avro-distributed.properties\n#   RUN echo \"plugin.path=/opt/landoop/connectors/stream-reactor,/opt/landoop/connectors/third-party\" \\\n#          >> /opt/landoop/kafka/etc/schema-registry/connect-avro-distributed.properties \\\n#       && mkdir -p /opt/landoop/connectors/stream-reactor\n#   Add Third Party Connectors\n#  # Twitter\nARG TWITTER_CONNECTOR_URL=\"https://archive.landoop.com/third-party/kafka-connect-twitter/kafka-connect-twitter-0.1-master-33331ea-connect-1.0.0-jar-with-dependencies.jar\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-twitter \\\n && wget \"$TWITTER_CONNECTOR_URL\" -P /opt/landoop/connectors/third-party/kafka-connect-twitter\n#  # Kafka Connect JDBC\nARG KAFKA_CONNECT_JDBC_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_JDBC_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-jdbc/kafka-connect-jdbc-${KAFKA_CONNECT_JDBC_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_JDBC_URL\" -O /opt/kafka-connect-jdbc.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-jdbc.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-jdbc.tar.gz\n#  # Kafka Connect ELASTICSEARCH\nARG KAFKA_CONNECT_ELASTICSEARCH_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_ELASTICSEARCH_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-elasticsearch/kafka-connect-elasticsearch-${KAFKA_CONNECT_ELASTICSEARCH_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_ELASTICSEARCH_URL\" -O /opt/kafka-connect-elasticsearch.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-elasticsearch.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-elasticsearch.tar.gz\n#  # Kafka Connect HDFS\nARG KAFKA_CONNECT_HDFS_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_HDFS_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-hdfs/kafka-connect-hdfs-${KAFKA_CONNECT_HDFS_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_HDFS_URL\" -O /opt/kafka-connect-hdfs.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-hdfs.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-hdfs.tar.gz\n#   Kafka Connect S3\nARG KAFKA_CONNECT_S3_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_S3_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-s3/kafka-connect-s3-${KAFKA_CONNECT_S3_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_S3_URL\" -O /opt/kafka-connect-s3.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-s3.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-s3.tar.gz\n#   Kafka Connect Couchbase\nARG KAFKA_CONNECT_COUCHBASE_VERSION=3.2.2\nARG KAFKA_CONNECT_COUCHBASE_URL=\"http://packages.couchbase.com/clients/kafka/${KAFKA_CONNECT_COUCHBASE_VERSION}/kafka-connect-couchbase-${KAFKA_CONNECT_COUCHBASE_VERSION}.zip\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_COUCHBASE_URL\" -O /couchbase.zip \\\n && mkdir -p /couchbase /opt/landoop/connectors/third-party/kafka-connect-couchbase \\\n && unzip /couchbase.zip -d /couchbase \\\n && cp -ax /couchbase/kafka-connect-couchbase-${KAFKA_CONNECT_COUCHBASE_VERSION}/* /opt/landoop/connectors/third-party/kafka-connect-couchbase \\\n && chown -R root:root /opt/landoop/connectors/third-party/kafka-connect-couchbase \\\n && rm -rf /couchbase.zip /couchbase\n#   Kafka Connect Dbvisit Replicate\nARG KAFKA_CONNECT_DBVISITREPLICATE_VERSION=2.0.0-SNAPSHOT\nARG KAFKA_CONNECT_DBVISITREPLICATE_URL=\"https://www.dropbox.com/s/nhs8v3lwmigpks1/kafka-connect-dbvisitreplicate-${KAFKA_CONNECT_DBVISITREPLICATE_VERSION}.jar?dl=0\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-dbvisitreplicate \\\n && wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_DBVISITREPLICATE_URL\" -O /opt/landoop/connectors/third-party/kafka-connect-dbvisitreplicate/kafka-connect-dbvisitreplicate-${KAFKA_CONNECT_DBVISITREPLICATE_VERSION}.jar\n#   Kafka Connect Debezium MongoDB / MySQL / Postgres\nARG KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION=0.8.3.Final\nARG KAFKA_CONNECT_DEBEZIUM_MONGODB_URL=\"https://search.maven.org/remotecontent?filepath=io/debezium/debezium-connector-mongodb/${KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION}/debezium-connector-mongodb-${KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION}-plugin.tar.gz\"\nARG KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION=0.8.3.Final\nARG KAFKA_CONNECT_DEBEZIUM_MYSQL_URL=\"https://search.maven.org/remotecontent?filepath=io/debezium/debezium-connector-mysql/${KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION}/debezium-connector-mysql-${KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION}-plugin.tar.gz\"\nARG KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION=0.8.3.Final\nARG KAFKA_CONNECT_DEBEZIUM_POSTGRES_URL=\"https://search.maven.org/remotecontent?filepath=io/debezium/debezium-connector-postgres/${KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION}/debezium-connector-postgres-${KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION}-plugin.tar.gz\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-debezium-{mongodb,mysql,postgres} \\\n && wget \"$KAFKA_CONNECT_DEBEZIUM_MONGODB_URL\" -O /debezium-mongodb.tgz \\\n && tar -xf /debezium-mongodb.tgz --owner=root --group=root --strip-components=1 -C /opt/landoop/connectors/third-party/kafka-connect-debezium-mongodb \\\n && wget \"$KAFKA_CONNECT_DEBEZIUM_MYSQL_URL\" -O /debezium-mysql.tgz \\\n && tar -xf /debezium-mysql.tgz --owner=root --group=root --strip-components=1 -C /opt/landoop/connectors/third-party/kafka-connect-debezium-mysql \\\n && wget \"$KAFKA_CONNECT_DEBEZIUM_POSTGRES_URL\" -O /debezium-postgres.tgz \\\n && tar -xf /debezium-postgres.tgz --owner=root --group=root --strip-components=1 -C /opt/landoop/connectors/third-party/kafka-connect-debezium-postgres \\\n && rm -rf /debezium-{mongodb,mysql,postgres}.tgz\n#   Kafka Connect Splunk\nARG KAFKA_CONNECT_SPLUNK_VERSION=\"1.1.0\"\nARG KAFKA_CONNECT_SPLUNK_URL=\"https://github.com/splunk/kafka-connect-splunk/releases/download/v${KAFKA_CONNECT_SPLUNK_VERSION}/splunk-kafka-connect-v${KAFKA_CONNECT_SPLUNK_VERSION}.jar\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-splunk \\\n && wget \"$KAFKA_CONNECT_SPLUNK_URL\" -O /opt/landoop/connectors/third-party/kafka-connect-splunk/splunk-kafka-connect-v${KAFKA_CONNECT_SPLUNK_VERSION}.jar\n#  ###########\n#   Add tools/\n#  ###########\n#   Add Coyote\nARG COYOTE_VERSION=1.5\nARG COYOTE_URL=\"https://github.com/Landoop/coyote/releases/download/v${COYOTE_VERSION}/coyote-${COYOTE_VERSION}\"\nRUN mkdir -p /opt/landoop/tools/bin/win /opt/landoop/tools/bin/mac /opt/landoop/tools/share/coyote/examples \\\n && wget \"$COYOTE_URL\"-linux-amd64 -O /opt/landoop/tools/bin/coyote \\\n && wget \"$COYOTE_URL\"-darwin-amd64 -O /opt/landoop/tools/bin/mac/coyote \\\n && wget \"$COYOTE_URL\"-windows-amd64.exe -O /opt/landoop/tools/bin/win/coyote \\\n && chmod +x /opt/landoop/tools/bin/coyote /opt/landoop/tools/bin/mac/coyote\nCOPY lkd/simple-integration-tests.yml /opt/landoop/tools/share/coyote/examples/\n#   Add Kafka Topic UI, Schema Registry UI, Kafka Connect UI\nARG KAFKA_TOPICS_UI_VERSION=0.9.4\nARG KAFKA_TOPICS_UI_URL=\"https://github.com/Landoop/kafka-topics-ui/releases/download/v${KAFKA_TOPICS_UI_VERSION}/kafka-topics-ui-${KAFKA_TOPICS_UI_VERSION}.tar.gz\"\nARG SCHEMA_REGISTRY_UI_VERSION=0.9.5\nARG SCHEMA_REGISTRY_UI_URL=\"https://github.com/Landoop/schema-registry-ui/releases/download/v.${SCHEMA_REGISTRY_UI_VERSION}/schema-registry-ui-${SCHEMA_REGISTRY_UI_VERSION}.tar.gz\"\nARG KAFKA_CONNECT_UI_VERSION=0.9.7\nARG KAFKA_CONNECT_UI_URL=\"https://github.com/Landoop/kafka-connect-ui/releases/download/v.${KAFKA_CONNECT_UI_VERSION}/kafka-connect-ui-${KAFKA_CONNECT_UI_VERSION}.tar.gz\"\nRUN mkdir -p /opt/landoop/tools/share/kafka-topics-ui/ /opt/landoop/tools/share/schema-registry-ui/ /opt/landoop/tools/share/kafka-connect-ui/ \\\n && wget \"$KAFKA_TOPICS_UI_URL\" -O /opt/landoop/tools/share/kafka-topics-ui/kafka-topics-ui.tar.gz \\\n && wget \"$SCHEMA_REGISTRY_UI_URL\" -O /opt/landoop/tools/share/schema-registry-ui/schema-registry-ui.tar.gz \\\n && wget \"$KAFKA_CONNECT_UI_URL\" -O /opt/landoop/tools/share/kafka-connect-ui/kafka-connect-ui.tar.gz\n#   Add Kafka Autocomplete\nARG KAFKA_AUTOCOMPLETE_VERSION=0.3\nARG KAFKA_AUTOCOMPLETE_URL=\"https://github.com/Landoop/kafka-autocomplete/releases/download/${KAFKA_AUTOCOMPLETE_VERSION}/kafka\"\nRUN mkdir -p /opt/landoop/tools/share/kafka-autocomplete /opt/landoop/tools/share/bash-completion/completions \\\n && wget \"$KAFKA_AUTOCOMPLETE_URL\" -O /opt/landoop/tools/share/kafka-autocomplete/kafka \\\n && wget \"$KAFKA_AUTOCOMPLETE_URL\" -O /opt/landoop/tools/share/bash-completion/completions/kafka\n#   Enable jline for Zookeeper\nRUN TJLINE=\"$( find /opt/landoop/kafka -name \"jline-0*.jar\" | head -n1 ;)\" \\\n && if [[ -n $TJLINE ]] ; then sed \"s|^exec.*|export CLASSPATH=\\\"$CLASSPATH:$TJLINE\\\"\\n&|\" -i /opt/landoop/kafka/bin/zookeeper-shell ; fi\n#   Add normcat\nARG NORMCAT_VERSION=1.1.1\nARG NORMCAT_URL=\"https://github.com/andmarios/normcat/releases/download/${NORMCAT_VERSION}/normcat-${NORMCAT_VERSION}\"\nRUN mkdir -p /opt/landoop/tools/bin/win /opt/landoop/tools/bin/mac \\\n && wget \"$NORMCAT_URL\"-linux-amd64-lowmem.tar.gz -O /normcat-linux.tgz \\\n && tar -xf /normcat-linux.tgz -C /opt/landoop/tools/bin \\\n && wget \"$NORMCAT_URL\"-darwin-amd64.zip -O /normcat-mac.zip \\\n && unzip /normcat-mac.zip -d /opt/landoop/tools/bin/mac \\\n && wget \"$NORMCAT_URL\"-windows-amd64.zip -O /normcat-win.zip \\\n && unzip /normcat-win.zip -d /opt/landoop/tools/bin/win \\\n && chmod +x /opt/landoop/tools/bin/coyote /opt/landoop/tools/bin/mac/coyote \\\n && rm -f /normcat-linux.tg /normcat-mac.zip /normcat-win.zip\n#  #########\n#   Finalize\n#  #########\nRUN echo \"LKD_VERSION=${LKD_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_VERSION=${KAFKA_LVERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"CONNECT_VERSION=${KAFKA_LVERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"SCHEMA_REGISTRY_VERSION=${REGISTRY_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"REST_PROXY_VERSION=${REST_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"STREAM_REACTOR_VERSION=${STREAM_REACTOR_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_JDBC_VERSION=${KAFKA_CONNECT_JDBC_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_ELASTICSEARCH_VERSION=${KAFKA_CONNECT_ELASTICSEARCH_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_HDFS_VERSION=${KAFKA_CONNECT_HDFS_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_S3_VERSION=${KAFKA_CONNECT_S3_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_COUCHBASE_VERSION=${KAFKA_CONNECT_COUCHBASE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DBVISITREPLICATE_VERSION=${KAFKA_CONNECT_DBVISITREPLICATE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION=${KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION=${KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION=${KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_SPLUNK_VERSION=${KAFKA_CONNECT_SPLUNK_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_TOPICS_UI_VERSION=${KAFKA_TOPICS_UI_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"SCHEMA_REGISTRY_UI_VERSION=${SCHEMA_REGISTRY_UI_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_UI_VERSION=${KAFKA_CONNECT_UI_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"COYOTE_VERSION=${COYOTE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_AUTOCOMPLETE_VERSION=${KAFKA_AUTOCOMPLETE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"NORMCAT_VERSION=${NORMCAT_VERSION}\" | tee -a /opt/landoop/build.info\n#   duphard (replace duplicates with hard links) and create archive\n#   We run as two separate commands because otherwise the build fails in docker hub (but not locally)\nRUN duphard -d=0 /opt/landoop\nRUN tar -czf /LKD-${LKD_VERSION}.tar.gz --owner=root --group=root -C /opt landoop \\\n && rm -rf /opt/landoop\n#   Unfortunately we have to make this a separate step in order for docker to understand the change to hardlinks\n#   Good thing: final image that people download is much smaller (~200MB).\nRUN tar xf /LKD-${LKD_VERSION}.tar.gz -C /opt \\\n && rm /LKD-${LKD_VERSION}.tar.gz\nENV LKD_VERSION=\"${LKD_VERSION}\"\n#   If this stage is run as container and you mount `/mnt`, we will create the LKD archive there.\nCMD [\"bash\", \"-c\", \"tar\", \"-czf\", \"/mnt/LKD-${LKD_VERSION}.tar.gz\", \"-C\", \"/opt\", \"landoop\", \";\", \"chown\", \"--reference=/mnt\", \"/mnt/LKD-${LKD_VERSION}.tar.gz\"]\nFROM alpine\nMAINTAINER Marios Andreopoulos <marios@landoop.com>\nCOPY --from=compile-lkd /opt /opt\n#   Update, install tooling and some basic setup\nRUN apk add bash=5.2.15-r0 bash-completion=2.11-r4 bzip2=1.0.8-r4 coreutils=9.1-r0 curl=7.88.1-r1 dumb-init=1.2.5-r2 gettext=0.21.1-r1 gzip=1.12-r0 jq=1.6-r2 libstdc++=12.2.1_git20220924-r4 nss=3.85-r1 openjdk8-jre-base=8.362.09-r1 openssl=3.0.8-r3 sqlite=3.40.1-r0 supervisor=4.2.4-r0 tar=1.34-r2 tzdata=2023c-r0 wget=1.21.3-r2 --no-cache \\\n && echo \"progress = dot:giga\" | tee /etc/wgetrc \\\n && mkdir -p /opt \\\n && mkdir /extra-connect-jars /connectors \\\n && mkdir /etc/supervisord.d /etc/supervisord.templates.d\nSHELL [\"/bin/bash\", \"-c\"]\nWORKDIR /\n#   Install external tooling\n#   checkport: checks for ports that are already in use, useful when we run with\n#              '--net=host so we have an easy way to detect if our ports are free\n#   quickcert: a small tool we use to create a CA and key-cert pairs so we can easily\n#              setup SSL on the brokers with autogenerated keys and certs\n#   glibc    : alpine linux has an embedded libc which misses some functions that are\n#              needed by some apps (e.g jvm's rocksdb jni — HDFS connector, Lenses, etc),\n#              so we add glibc to make them work. Also now we can add en_US.UTF-8 locale.\n#              https://github.com/sgerrand/alpine-pkg-glibc\n#   caddy    : an excellent web server we use to serve fast-data-dev UI, proxy various REST\n#              endpoints, etc\n#              https://github.com/mholt/caddy\nARG CHECKPORT_URL=\"https://gitlab.com/andmarios/checkport/uploads/3903dcaeae16cd2d6156213d22f23509/checkport\"\nARG QUICKCERT_URL=\"https://github.com/andmarios/quickcert/releases/download/1.0/quickcert-1.0-linux-amd64-alpine\"\nARG GLIBC_INST_VERSION=\"2.27-r0\"\nARG CADDY_URL=https://github.com/mholt/caddy/releases/download/v0.10.10/caddy_v0.10.10_linux_amd64.tar.gz\nRUN wget \"$CHECKPORT_URL\" -O /usr/local/bin/checkport \\\n && wget \"$QUICKCERT_URL\" -O /usr/local/bin/quickcert \\\n && chmod 0755 /usr/local/bin/quickcert /usr/local/bin/checkport \\\n && wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_INST_VERSION}/glibc-${GLIBC_INST_VERSION}.apk \\\n && wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_INST_VERSION}/glibc-bin-${GLIBC_INST_VERSION}.apk \\\n && wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_INST_VERSION}/glibc-i18n-${GLIBC_INST_VERSION}.apk \\\n && apk add glibc-${GLIBC_INST_VERSION}.apk glibc-bin-${GLIBC_INST_VERSION}.apk glibc-i18n-${GLIBC_INST_VERSION}.apk --no-cache --allow-untrusted \\\n && rm -f glibc-${GLIBC_INST_VERSION}.apk glibc-bin-${GLIBC_INST_VERSION}.apk glibc-i18n-${GLIBC_INST_VERSION}.apk \\\n && wget \"$CADDY_URL\" -O /caddy.tgz \\\n && mkdir -p /opt/caddy \\\n && tar xzf /caddy.tgz -C /opt/caddy \\\n && rm -f /caddy.tgz \\\n && /usr/glibc-compat/bin/localedef -i en_US -f UTF-8 en_US.UTF-8\nENV LANG=\"en_US.UTF-8\" \\\n    LANGUAGE=\"en_US.UTF-8\" \\\n    LC_ALL=\"en_US.UTF-8\"\nCOPY /filesystem /\nRUN chmod +x /usr/local/bin/{smoke-tests,logs-to-kafka,nullsink}.sh /usr/local/share/landoop/sample-data/*.sh\n#   Create system symlinks to Kafka binaries\nRUN bash -c 'for i in $(find /opt/landoop/kafka/bin /opt/landoop/tools/bin -maxdepth 1 -type f); do ln -s $i /usr/local/bin/$(echo $i | sed -e \"s>.*/>>\"); done'\n#   Add kafka ssl principal builder\nRUN wget https://archive.landoop.com/third-party/kafka-custom-principal-builder/kafka-custom-principal-builder-1.0-SNAPSHOT.jar -P /opt/landoop/kafka/share/java/kafka \\\n && mkdir -p /opt/landoop/kafka/share/docs/kafka-custom-principal-builder \\\n && wget https://archive.landoop.com/third-party/kafka-custom-principal-builder/LICENSE -P /opt/landoop/kafka/share/docs/kafka-custom-principal-builder \\\n && wget https://archive.landoop.com/third-party/kafka-custom-principal-builder/README.md -P /opt/landoop/kafka/share/docs/kafka-custom-principal-builder\n#   Setup Kafka Topics UI, Schema Registry UI, Kafka Connect UI\nRUN mkdir -p /var/www/kafka-topics-ui /var/www/schema-registry-ui /var/www/kafka-connect-ui \\\n && tar -xf /opt/landoop/tools/share/kafka-topics-ui/kafka-topics-ui.tar.gz -C /var/www/kafka-topics-ui --exclude=env.js \\\n && tar -xf /opt/landoop/tools/share/schema-registry-ui/schema-registry-ui.tar.gz -C /var/www/schema-registry-ui --exclude=env.js \\\n && tar -xf /opt/landoop/tools/share/kafka-connect-ui/kafka-connect-ui.tar.gz -C /var/www/kafka-connect-ui --exclude=env.js\nRUN ln -s /var/log /var/www/logs\n#   Add executables, settings and configuration\nCOPY setup-and-run.sh /usr/local/bin/\nRUN chmod +x /usr/local/bin/setup-and-run.sh \\\n && ln -s /usr/local/share/landoop/etc/bashrc /root/.bashrc\nVOLUME [\"/data\"]\nARG BUILD_BRANCH\nARG BUILD_COMMIT\nARG BUILD_TIME\nARG DOCKER_REPO=local\nRUN echo \"BUILD_BRANCH=${BUILD_BRANCH}\" | tee /build.info \\\n && echo \"BUILD_COMMIT=${BUILD_COMMIT}\" | tee -a /build.info \\\n && echo \"BUILD_TIME=${BUILD_TIME}\" | tee -a /build.info \\\n && echo \"DOCKER_REPO=${DOCKER_REPO}\" | tee -a /build.info \\\n && sed -e 's/^/FDD_/' /opt/landoop/build.info | tee -a /build.info\nEXPOSE 2181/tcp 3030/tcp 3031/tcp 8081/tcp 8082/tcp 8083/tcp 9092/tcp\nENTRYPOINT [\"/usr/bin/dumb-init\", \"--\"]\nCMD [\"/usr/local/bin/setup-and-run.sh\"]\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"FROM debian AS compile-lkd\nMAINTAINER Marios Andreopoulos <marios@landoop.com>\nRUN apt-get update \\\n && apt-get install unzip wget -y \\\n && rm -rf /var/lib/apt/lists/* \\\n && echo \"progress = dot:giga\" | tee /etc/wgetrc \\\n && mkdir -p /mnt /opt /data \\\n && wget https://github.com/andmarios/duphard/releases/download/v1.0/duphard -O /bin/duphard \\\n && chmod +x /bin/duphard\nSHELL [\"/bin/bash\", \"-c\"]\nWORKDIR /\n#  Login args for development archives\nARG DEVARCH_USER\nARG DEVARCH_PASS\nARG ARCHIVE_SERVER=https://archive.landoop.com\nARG LKD_VERSION=2.0.1\n# ###########\n#  Add kafka/\n# ###########\n#  Add Apache Kafka (includes Connect and Zookeeper)\nARG KAFKA_VERSION=2.0.1\nARG KAFKA_LVERSION=\"${KAFKA_VERSION}-L0\"\nARG KAFKA_URL=\"${ARCHIVE_SERVER}/lkd/packages/kafka/kafka-2.12-${KAFKA_LVERSION}-lkd.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_URL\" -O /opt/kafka.tar.gz \\\n && tar --no-same-owner -xzf /opt/kafka.tar.gz -C /opt \\\n && mkdir /opt/landoop/kafka/logs \\\n && chmod 1777 /opt/landoop/kafka/logs \\\n && rm -rf /opt/kafka.tar.gz\n#  Add Schema Registry and REST Proxy\nARG REGISTRY_VERSION=5.0.1-lkd-r0\nARG REGISTRY_URL=\"${ARCHIVE_SERVER}/lkd/packages/schema-registry/schema-registry-${REGISTRY_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$REGISTRY_URL\" -O /opt/registry.tar.gz \\\n && tar --no-same-owner -xzf /opt/registry.tar.gz -C /opt/ \\\n && rm -rf /opt/registry.tar.gz\nARG REST_VERSION=5.0.1-lkd-r0\nARG REST_URL=\"${ARCHIVE_SERVER}/lkd/packages/rest-proxy/rest-proxy-${REST_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$REST_URL\" -O /opt/rest.tar.gz \\\n && tar --no-same-owner -xzf /opt/rest.tar.gz -C /opt/ \\\n && rm -rf /opt/rest.tar.gz\n#  Configure Connect and Confluent Components to support CORS\nRUN echo -e 'access.control.allow.methods=GET,POST,PUT,DELETE,OPTIONS\\naccess.control.allow.origin=*' | tee -a /opt/landoop/kafka/etc/schema-registry/schema-registry.properties | tee -a /opt/landoop/kafka/etc/kafka-rest/kafka-rest.properties | tee -a /opt/landoop/kafka/etc/schema-registry/connect-avro-distributed.properties\n# ################\n#  Add connectors/\n# ################\n#  Add Stream Reactor and needed components\nARG STREAM_REACTOR_VERSION=1.2.0\nARG KAFKA_VERSION_4SR=2.0.0\nARG STREAM_REACTOR_URL=\"https://archive.landoop.com/lkd/packages/connectors/stream-reactor/stream-reactor-${STREAM_REACTOR_VERSION}_connect${KAFKA_VERSION_4SR}.tar.gz\"\nARG ELASTICSEARCH_2X_VERSION=2.4.6\nARG ACTIVEMQ_VERSION=5.12.3\nARG CALCITE_LINQ4J_VERSION=1.12.0\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"${STREAM_REACTOR_URL}\" -O /stream-reactor.tar.gz \\\n && mkdir -p /opt/landoop/connectors/stream-reactor \\\n && tar -xf /stream-reactor.tar.gz --no-same-owner --strip-components=1 -C /opt/landoop/connectors/stream-reactor \\\n && rm /stream-reactor.tar.gz \\\n && wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/${ELASTICSEARCH_2X_VERSION}/elasticsearch-${ELASTICSEARCH_2X_VERSION}.tar.gz -O /elasticsearch.tar.gz \\\n && mkdir /elasticsearch \\\n && tar -xf /elasticsearch.tar.gz --no-same-owner --strip-components=1 -C /elasticsearch \\\n && rm -f /elasticsearch/lib/apache-log4j-extras* \\\n && mv /elasticsearch/lib/*.jar /opt/landoop/connectors/stream-reactor/kafka-connect-elastic/ \\\n && rm -rf /elasticsearch* \\\n && wget http://central.maven.org/maven2/org/apache/activemq/activemq-all/${ACTIVEMQ_VERSION}/activemq-all-${ACTIVEMQ_VERSION}.jar -P /opt/landoop/connectors/stream-reactor/kafka-connect-jms \\\n && wget http://central.maven.org/maven2/org/apache/calcite/calcite-linq4j/${CALCITE_LINQ4J_VERSION}/calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar -O /calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar \\\n && for path in /opt/landoop/connectors/stream-reactor/kafka-connect-*; do cp /calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar $path/ ; done \\\n && rm /calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar \\\n && mkdir -p /opt/landoop/kafka/share/java/landoop-common \\\n && for file in $( find /opt/landoop/connectors/stream-reactor -maxdepth 2 -type f -exec basename {} | grep -Ev \"scala-logging|kafka-connect-common|scala-\" | sort | uniq -c | grep -E \"^\\s+22 \" | awk '{print $2}' ;); do cp /opt/landoop/connectors/stream-reactor/kafka-connect-elastic/$file /opt/landoop/kafka/share/java/landoop-common/ ;rm -f /opt/landoop/connectors/stream-reactor/kafka-connect-*/$file ; done \\\n && for file in $( find /opt/landoop/kafka/share/java/{kafka,landoop-common} -maxdepth 1 -type f -exec basename {} | sort | uniq -c | grep -E \"^\\s+2 \" | awk '{print $2}' ;); do echo \"Removing duplicate /opt/landoop/kafka/share/java/landoop-common/$file.\" ;rm -f /opt/landoop/kafka/share/java/landoop-common/$file ; done \\\n && rm -f /opt/landoop/connectors/stream-reactor/*/*{javadoc,scaladoc,sources}.jar \\\n && echo \"plugin.path=/opt/landoop/connectors/stream-reactor,/opt/landoop/connectors/third-party\" >> /opt/landoop/kafka/etc/schema-registry/connect-avro-distributed.properties\n#  RUN echo \"plugin.path=/opt/landoop/connectors/stream-reactor,/opt/landoop/connectors/third-party\" \\\n#         >> /opt/landoop/kafka/etc/schema-registry/connect-avro-distributed.properties \\\n#      && mkdir -p /opt/landoop/connectors/stream-reactor\n#  Add Third Party Connectors\n# # Twitter\nARG TWITTER_CONNECTOR_URL=\"https://archive.landoop.com/third-party/kafka-connect-twitter/kafka-connect-twitter-0.1-master-33331ea-connect-1.0.0-jar-with-dependencies.jar\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-twitter \\\n && wget \"$TWITTER_CONNECTOR_URL\" -P /opt/landoop/connectors/third-party/kafka-connect-twitter\n# # Kafka Connect JDBC\nARG KAFKA_CONNECT_JDBC_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_JDBC_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-jdbc/kafka-connect-jdbc-${KAFKA_CONNECT_JDBC_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_JDBC_URL\" -O /opt/kafka-connect-jdbc.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-jdbc.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-jdbc.tar.gz\n# # Kafka Connect ELASTICSEARCH\nARG KAFKA_CONNECT_ELASTICSEARCH_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_ELASTICSEARCH_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-elasticsearch/kafka-connect-elasticsearch-${KAFKA_CONNECT_ELASTICSEARCH_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_ELASTICSEARCH_URL\" -O /opt/kafka-connect-elasticsearch.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-elasticsearch.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-elasticsearch.tar.gz\n# # Kafka Connect HDFS\nARG KAFKA_CONNECT_HDFS_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_HDFS_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-hdfs/kafka-connect-hdfs-${KAFKA_CONNECT_HDFS_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_HDFS_URL\" -O /opt/kafka-connect-hdfs.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-hdfs.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-hdfs.tar.gz\n#  Kafka Connect S3\nARG KAFKA_CONNECT_S3_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_S3_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-s3/kafka-connect-s3-${KAFKA_CONNECT_S3_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_S3_URL\" -O /opt/kafka-connect-s3.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-s3.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-s3.tar.gz\n#  Kafka Connect Couchbase\nARG KAFKA_CONNECT_COUCHBASE_VERSION=3.2.2\nARG KAFKA_CONNECT_COUCHBASE_URL=\"http://packages.couchbase.com/clients/kafka/${KAFKA_CONNECT_COUCHBASE_VERSION}/kafka-connect-couchbase-${KAFKA_CONNECT_COUCHBASE_VERSION}.zip\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_COUCHBASE_URL\" -O /couchbase.zip \\\n && mkdir -p /couchbase /opt/landoop/connectors/third-party/kafka-connect-couchbase \\\n && unzip /couchbase.zip -d /couchbase \\\n && cp -ax /couchbase/kafka-connect-couchbase-${KAFKA_CONNECT_COUCHBASE_VERSION}/* /opt/landoop/connectors/third-party/kafka-connect-couchbase \\\n && chown -R root:root /opt/landoop/connectors/third-party/kafka-connect-couchbase \\\n && rm -rf /couchbase.zip /couchbase\n#  Kafka Connect Dbvisit Replicate\nARG KAFKA_CONNECT_DBVISITREPLICATE_VERSION=2.0.0-SNAPSHOT\nARG KAFKA_CONNECT_DBVISITREPLICATE_URL=\"https://www.dropbox.com/s/nhs8v3lwmigpks1/kafka-connect-dbvisitreplicate-${KAFKA_CONNECT_DBVISITREPLICATE_VERSION}.jar?dl=0\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-dbvisitreplicate \\\n && wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_DBVISITREPLICATE_URL\" -O /opt/landoop/connectors/third-party/kafka-connect-dbvisitreplicate/kafka-connect-dbvisitreplicate-${KAFKA_CONNECT_DBVISITREPLICATE_VERSION}.jar\n#  Kafka Connect Debezium MongoDB / MySQL / Postgres\nARG KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION=0.8.3.Final\nARG KAFKA_CONNECT_DEBEZIUM_MONGODB_URL=\"https://search.maven.org/remotecontent?filepath=io/debezium/debezium-connector-mongodb/${KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION}/debezium-connector-mongodb-${KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION}-plugin.tar.gz\"\nARG KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION=0.8.3.Final\nARG KAFKA_CONNECT_DEBEZIUM_MYSQL_URL=\"https://search.maven.org/remotecontent?filepath=io/debezium/debezium-connector-mysql/${KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION}/debezium-connector-mysql-${KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION}-plugin.tar.gz\"\nARG KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION=0.8.3.Final\nARG KAFKA_CONNECT_DEBEZIUM_POSTGRES_URL=\"https://search.maven.org/remotecontent?filepath=io/debezium/debezium-connector-postgres/${KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION}/debezium-connector-postgres-${KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION}-plugin.tar.gz\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-debezium-{mongodb,mysql,postgres} \\\n && wget \"$KAFKA_CONNECT_DEBEZIUM_MONGODB_URL\" -O /debezium-mongodb.tgz \\\n && tar -xf /debezium-mongodb.tgz --owner=root --group=root --strip-components=1 -C /opt/landoop/connectors/third-party/kafka-connect-debezium-mongodb \\\n && wget \"$KAFKA_CONNECT_DEBEZIUM_MYSQL_URL\" -O /debezium-mysql.tgz \\\n && tar -xf /debezium-mysql.tgz --owner=root --group=root --strip-components=1 -C /opt/landoop/connectors/third-party/kafka-connect-debezium-mysql \\\n && wget \"$KAFKA_CONNECT_DEBEZIUM_POSTGRES_URL\" -O /debezium-postgres.tgz \\\n && tar -xf /debezium-postgres.tgz --owner=root --group=root --strip-components=1 -C /opt/landoop/connectors/third-party/kafka-connect-debezium-postgres \\\n && rm -rf /debezium-{mongodb,mysql,postgres}.tgz\n#  Kafka Connect Splunk\nARG KAFKA_CONNECT_SPLUNK_VERSION=\"1.1.0\"\nARG KAFKA_CONNECT_SPLUNK_URL=\"https://github.com/splunk/kafka-connect-splunk/releases/download/v${KAFKA_CONNECT_SPLUNK_VERSION}/splunk-kafka-connect-v${KAFKA_CONNECT_SPLUNK_VERSION}.jar\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-splunk \\\n && wget \"$KAFKA_CONNECT_SPLUNK_URL\" -O /opt/landoop/connectors/third-party/kafka-connect-splunk/splunk-kafka-connect-v${KAFKA_CONNECT_SPLUNK_VERSION}.jar\n# ###########\n#  Add tools/\n# ###########\n#  Add Coyote\nARG COYOTE_VERSION=1.5\nARG COYOTE_URL=\"https://github.com/Landoop/coyote/releases/download/v${COYOTE_VERSION}/coyote-${COYOTE_VERSION}\"\nRUN mkdir -p /opt/landoop/tools/bin/win /opt/landoop/tools/bin/mac /opt/landoop/tools/share/coyote/examples \\\n && wget \"$COYOTE_URL\"-linux-amd64 -O /opt/landoop/tools/bin/coyote \\\n && wget \"$COYOTE_URL\"-darwin-amd64 -O /opt/landoop/tools/bin/mac/coyote \\\n && wget \"$COYOTE_URL\"-windows-amd64.exe -O /opt/landoop/tools/bin/win/coyote \\\n && chmod +x /opt/landoop/tools/bin/coyote /opt/landoop/tools/bin/mac/coyote\nADD lkd/simple-integration-tests.yml /opt/landoop/tools/share/coyote/examples/\n#  Add Kafka Topic UI, Schema Registry UI, Kafka Connect UI\nARG KAFKA_TOPICS_UI_VERSION=0.9.4\nARG KAFKA_TOPICS_UI_URL=\"https://github.com/Landoop/kafka-topics-ui/releases/download/v${KAFKA_TOPICS_UI_VERSION}/kafka-topics-ui-${KAFKA_TOPICS_UI_VERSION}.tar.gz\"\nARG SCHEMA_REGISTRY_UI_VERSION=0.9.5\nARG SCHEMA_REGISTRY_UI_URL=\"https://github.com/Landoop/schema-registry-ui/releases/download/v.${SCHEMA_REGISTRY_UI_VERSION}/schema-registry-ui-${SCHEMA_REGISTRY_UI_VERSION}.tar.gz\"\nARG KAFKA_CONNECT_UI_VERSION=0.9.7\nARG KAFKA_CONNECT_UI_URL=\"https://github.com/Landoop/kafka-connect-ui/releases/download/v.${KAFKA_CONNECT_UI_VERSION}/kafka-connect-ui-${KAFKA_CONNECT_UI_VERSION}.tar.gz\"\nRUN mkdir -p /opt/landoop/tools/share/kafka-topics-ui/ /opt/landoop/tools/share/schema-registry-ui/ /opt/landoop/tools/share/kafka-connect-ui/ \\\n && wget \"$KAFKA_TOPICS_UI_URL\" -O /opt/landoop/tools/share/kafka-topics-ui/kafka-topics-ui.tar.gz \\\n && wget \"$SCHEMA_REGISTRY_UI_URL\" -O /opt/landoop/tools/share/schema-registry-ui/schema-registry-ui.tar.gz \\\n && wget \"$KAFKA_CONNECT_UI_URL\" -O /opt/landoop/tools/share/kafka-connect-ui/kafka-connect-ui.tar.gz\n#  Add Kafka Autocomplete\nARG KAFKA_AUTOCOMPLETE_VERSION=0.3\nARG KAFKA_AUTOCOMPLETE_URL=\"https://github.com/Landoop/kafka-autocomplete/releases/download/${KAFKA_AUTOCOMPLETE_VERSION}/kafka\"\nRUN mkdir -p /opt/landoop/tools/share/kafka-autocomplete /opt/landoop/tools/share/bash-completion/completions \\\n && wget \"$KAFKA_AUTOCOMPLETE_URL\" -O /opt/landoop/tools/share/kafka-autocomplete/kafka \\\n && wget \"$KAFKA_AUTOCOMPLETE_URL\" -O /opt/landoop/tools/share/bash-completion/completions/kafka\n#  Enable jline for Zookeeper\nRUN TJLINE=\"$( find /opt/landoop/kafka -name \"jline-0*.jar\" | head -n1 ;)\" \\\n && if [[ -n $TJLINE ]] ; then sed \"s|^exec.*|export CLASSPATH=\\\"$CLASSPATH:$TJLINE\\\"\\n&|\" -i /opt/landoop/kafka/bin/zookeeper-shell ; fi\n#  Add normcat\nARG NORMCAT_VERSION=1.1.1\nARG NORMCAT_URL=\"https://github.com/andmarios/normcat/releases/download/${NORMCAT_VERSION}/normcat-${NORMCAT_VERSION}\"\nRUN mkdir -p /opt/landoop/tools/bin/win /opt/landoop/tools/bin/mac \\\n && wget \"$NORMCAT_URL\"-linux-amd64-lowmem.tar.gz -O /normcat-linux.tgz \\\n && tar -xf /normcat-linux.tgz -C /opt/landoop/tools/bin \\\n && wget \"$NORMCAT_URL\"-darwin-amd64.zip -O /normcat-mac.zip \\\n && unzip /normcat-mac.zip -d /opt/landoop/tools/bin/mac \\\n && wget \"$NORMCAT_URL\"-windows-amd64.zip -O /normcat-win.zip \\\n && unzip /normcat-win.zip -d /opt/landoop/tools/bin/win \\\n && chmod +x /opt/landoop/tools/bin/coyote /opt/landoop/tools/bin/mac/coyote \\\n && rm -f /normcat-linux.tg /normcat-mac.zip /normcat-win.zip\n# #########\n#  Finalize\n# #########\nRUN echo \"LKD_VERSION=${LKD_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_VERSION=${KAFKA_LVERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"CONNECT_VERSION=${KAFKA_LVERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"SCHEMA_REGISTRY_VERSION=${REGISTRY_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"REST_PROXY_VERSION=${REST_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"STREAM_REACTOR_VERSION=${STREAM_REACTOR_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_JDBC_VERSION=${KAFKA_CONNECT_JDBC_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_ELASTICSEARCH_VERSION=${KAFKA_CONNECT_ELASTICSEARCH_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_HDFS_VERSION=${KAFKA_CONNECT_HDFS_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_S3_VERSION=${KAFKA_CONNECT_S3_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_COUCHBASE_VERSION=${KAFKA_CONNECT_COUCHBASE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DBVISITREPLICATE_VERSION=${KAFKA_CONNECT_DBVISITREPLICATE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION=${KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION=${KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION=${KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_SPLUNK_VERSION=${KAFKA_CONNECT_SPLUNK_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_TOPICS_UI_VERSION=${KAFKA_TOPICS_UI_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"SCHEMA_REGISTRY_UI_VERSION=${SCHEMA_REGISTRY_UI_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_UI_VERSION=${KAFKA_CONNECT_UI_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"COYOTE_VERSION=${COYOTE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_AUTOCOMPLETE_VERSION=${KAFKA_AUTOCOMPLETE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"NORMCAT_VERSION=${NORMCAT_VERSION}\" | tee -a /opt/landoop/build.info\n#  duphard (replace duplicates with hard links) and create archive\n#  We run as two separate commands because otherwise the build fails in docker hub (but not locally)\nRUN duphard -d=0 /opt/landoop\nRUN tar -czf /LKD-${LKD_VERSION}.tar.gz --owner=root --group=root -C /opt landoop \\\n && rm -rf /opt/landoop\n#  Unfortunately we have to make this a separate step in order for docker to understand the change to hardlinks\n#  Good thing: final image that people download is much smaller (~200MB).\nRUN tar xf /LKD-${LKD_VERSION}.tar.gz -C /opt \\\n && rm /LKD-${LKD_VERSION}.tar.gz\nENV LKD_VERSION=\"${LKD_VERSION}\"\n#  If this stage is run as container and you mount `/mnt`, we will create the LKD archive there.\nCMD [\"bash\", \"-c\", \"tar\", \"-czf\", \"/mnt/LKD-${LKD_VERSION}.tar.gz\", \"-C\", \"/opt\", \"landoop\", \";\", \"chown\", \"--reference=/mnt\", \"/mnt/LKD-${LKD_VERSION}.tar.gz\"]\nFROM alpine\nMAINTAINER Marios Andreopoulos <marios@landoop.com>\nCOPY --from=compile-lkd /opt /opt\n#  Update, install tooling and some basic setup\nRUN apk add --no-cache bash bash-completion bzip2 coreutils curl dumb-init gettext gzip jq libstdc++ nss openjdk8-jre-base openssl sqlite supervisor tar tzdata wget \\\n && echo \"progress = dot:giga\" | tee /etc/wgetrc \\\n && mkdir -p /opt \\\n && mkdir /extra-connect-jars /connectors \\\n && mkdir /etc/supervisord.d /etc/supervisord.templates.d\nSHELL [\"/bin/bash\", \"-c\"]\nWORKDIR /\n#  Install external tooling\n#  checkport: checks for ports that are already in use, useful when we run with\n#             '--net=host so we have an easy way to detect if our ports are free\n#  quickcert: a small tool we use to create a CA and key-cert pairs so we can easily\n#             setup SSL on the brokers with autogenerated keys and certs\n#  glibc    : alpine linux has an embedded libc which misses some functions that are\n#             needed by some apps (e.g jvm's rocksdb jni — HDFS connector, Lenses, etc),\n#             so we add glibc to make them work. Also now we can add en_US.UTF-8 locale.\n#             https://github.com/sgerrand/alpine-pkg-glibc\n#  caddy    : an excellent web server we use to serve fast-data-dev UI, proxy various REST\n#             endpoints, etc\n#             https://github.com/mholt/caddy\nARG CHECKPORT_URL=\"https://gitlab.com/andmarios/checkport/uploads/3903dcaeae16cd2d6156213d22f23509/checkport\"\nARG QUICKCERT_URL=\"https://github.com/andmarios/quickcert/releases/download/1.0/quickcert-1.0-linux-amd64-alpine\"\nARG GLIBC_INST_VERSION=\"2.27-r0\"\nARG CADDY_URL=https://github.com/mholt/caddy/releases/download/v0.10.10/caddy_v0.10.10_linux_amd64.tar.gz\nRUN wget \"$CHECKPORT_URL\" -O /usr/local/bin/checkport \\\n && wget \"$QUICKCERT_URL\" -O /usr/local/bin/quickcert \\\n && chmod 0755 /usr/local/bin/quickcert /usr/local/bin/checkport \\\n && wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_INST_VERSION}/glibc-${GLIBC_INST_VERSION}.apk \\\n && wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_INST_VERSION}/glibc-bin-${GLIBC_INST_VERSION}.apk \\\n && wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_INST_VERSION}/glibc-i18n-${GLIBC_INST_VERSION}.apk \\\n && apk add --no-cache --allow-untrusted glibc-${GLIBC_INST_VERSION}.apk glibc-bin-${GLIBC_INST_VERSION}.apk glibc-i18n-${GLIBC_INST_VERSION}.apk \\\n && rm -f glibc-${GLIBC_INST_VERSION}.apk glibc-bin-${GLIBC_INST_VERSION}.apk glibc-i18n-${GLIBC_INST_VERSION}.apk \\\n && wget \"$CADDY_URL\" -O /caddy.tgz \\\n && mkdir -p /opt/caddy \\\n && tar xzf /caddy.tgz -C /opt/caddy \\\n && rm -f /caddy.tgz \\\n && /usr/glibc-compat/bin/localedef -i en_US -f UTF-8 en_US.UTF-8\nENV LANG=\"en_US.UTF-8\" \\\n    LANGUAGE=\"en_US.UTF-8\" \\\n    LC_ALL=\"en_US.UTF-8\"\nCOPY /filesystem /\nRUN chmod +x /usr/local/bin/{smoke-tests,logs-to-kafka,nullsink}.sh /usr/local/share/landoop/sample-data/*.sh\n#  Create system symlinks to Kafka binaries\nRUN bash -c 'for i in $(find /opt/landoop/kafka/bin /opt/landoop/tools/bin -maxdepth 1 -type f); do ln -s $i /usr/local/bin/$(echo $i | sed -e \"s>.*/>>\"); done'\n#  Add kafka ssl principal builder\nRUN wget https://archive.landoop.com/third-party/kafka-custom-principal-builder/kafka-custom-principal-builder-1.0-SNAPSHOT.jar -P /opt/landoop/kafka/share/java/kafka \\\n && mkdir -p /opt/landoop/kafka/share/docs/kafka-custom-principal-builder \\\n && wget https://archive.landoop.com/third-party/kafka-custom-principal-builder/LICENSE -P /opt/landoop/kafka/share/docs/kafka-custom-principal-builder \\\n && wget https://archive.landoop.com/third-party/kafka-custom-principal-builder/README.md -P /opt/landoop/kafka/share/docs/kafka-custom-principal-builder\n#  Setup Kafka Topics UI, Schema Registry UI, Kafka Connect UI\nRUN mkdir -p /var/www/kafka-topics-ui /var/www/schema-registry-ui /var/www/kafka-connect-ui \\\n && tar -xf /opt/landoop/tools/share/kafka-topics-ui/kafka-topics-ui.tar.gz -C /var/www/kafka-topics-ui --exclude=env.js \\\n && tar -xf /opt/landoop/tools/share/schema-registry-ui/schema-registry-ui.tar.gz -C /var/www/schema-registry-ui --exclude=env.js \\\n && tar -xf /opt/landoop/tools/share/kafka-connect-ui/kafka-connect-ui.tar.gz -C /var/www/kafka-connect-ui --exclude=env.js\nRUN ln -s /var/log /var/www/logs\n#  Add executables, settings and configuration\nADD setup-and-run.sh /usr/local/bin/\nRUN chmod +x /usr/local/bin/setup-and-run.sh \\\n && ln -s /usr/local/share/landoop/etc/bashrc /root/.bashrc\nVOLUME [\"/data\"]\nARG BUILD_BRANCH\nARG BUILD_COMMIT\nARG BUILD_TIME\nARG DOCKER_REPO=local\nRUN echo \"BUILD_BRANCH=${BUILD_BRANCH}\" | tee /build.info \\\n && echo \"BUILD_COMMIT=${BUILD_COMMIT}\" | tee -a /build.info \\\n && echo \"BUILD_TIME=${BUILD_TIME}\" | tee -a /build.info \\\n && echo \"DOCKER_REPO=${DOCKER_REPO}\" | tee -a /build.info \\\n && sed -e 's/^/FDD_/' /opt/landoop/build.info | tee -a /build.info\nEXPOSE 2181/tcp 3030/tcp 3031/tcp 8081/tcp 8082/tcp 8083/tcp 9092/tcp\nENTRYPOINT [\"/usr/bin/dumb-init\", \"--\"]\nCMD [\"/usr/local/bin/setup-and-run.sh\"]\n","injectedSmells":[],"originalDockerfileHash":"865cb2cdfb46bfd7b04a4e8aec064f2c","successfullyInjectedSmells":[],"originalDockerfileUglified":"FROM debian AS compile-lkd\nMAINTAINER Marios Andreopoulos <marios@landoop.com>\nRUN apt-get update \\\n && apt-get install unzip wget -y \\\n && rm -rf /var/lib/apt/lists/* \\\n && echo \"progress = dot:giga\" | tee /etc/wgetrc \\\n && mkdir -p /mnt /opt /data \\\n && wget https://github.com/andmarios/duphard/releases/download/v1.0/duphard -O /bin/duphard \\\n && chmod +x /bin/duphard\nSHELL [\"/bin/bash\", \"-c\"]\nWORKDIR /\n#   Login args for development archives\nARG DEVARCH_USER\nARG DEVARCH_PASS\nARG ARCHIVE_SERVER=https://archive.landoop.com\nARG LKD_VERSION=2.0.1\n#  ###########\n#   Add kafka/\n#  ###########\n#   Add Apache Kafka (includes Connect and Zookeeper)\nARG KAFKA_VERSION=2.0.1\nARG KAFKA_LVERSION=\"${KAFKA_VERSION}-L0\"\nARG KAFKA_URL=\"${ARCHIVE_SERVER}/lkd/packages/kafka/kafka-2.12-${KAFKA_LVERSION}-lkd.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_URL\" -O /opt/kafka.tar.gz \\\n && tar --no-same-owner -xzf /opt/kafka.tar.gz -C /opt \\\n && mkdir /opt/landoop/kafka/logs \\\n && chmod 1777 /opt/landoop/kafka/logs \\\n && rm -rf /opt/kafka.tar.gz\n#   Add Schema Registry and REST Proxy\nARG REGISTRY_VERSION=5.0.1-lkd-r0\nARG REGISTRY_URL=\"${ARCHIVE_SERVER}/lkd/packages/schema-registry/schema-registry-${REGISTRY_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$REGISTRY_URL\" -O /opt/registry.tar.gz \\\n && tar --no-same-owner -xzf /opt/registry.tar.gz -C /opt/ \\\n && rm -rf /opt/registry.tar.gz\nARG REST_VERSION=5.0.1-lkd-r0\nARG REST_URL=\"${ARCHIVE_SERVER}/lkd/packages/rest-proxy/rest-proxy-${REST_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$REST_URL\" -O /opt/rest.tar.gz \\\n && tar --no-same-owner -xzf /opt/rest.tar.gz -C /opt/ \\\n && rm -rf /opt/rest.tar.gz\n#   Configure Connect and Confluent Components to support CORS\nRUN echo -e 'access.control.allow.methods=GET,POST,PUT,DELETE,OPTIONS\\naccess.control.allow.origin=*' | tee -a /opt/landoop/kafka/etc/schema-registry/schema-registry.properties | tee -a /opt/landoop/kafka/etc/kafka-rest/kafka-rest.properties | tee -a /opt/landoop/kafka/etc/schema-registry/connect-avro-distributed.properties\n#  ################\n#   Add connectors/\n#  ################\n#   Add Stream Reactor and needed components\nARG STREAM_REACTOR_VERSION=1.2.0\nARG KAFKA_VERSION_4SR=2.0.0\nARG STREAM_REACTOR_URL=\"https://archive.landoop.com/lkd/packages/connectors/stream-reactor/stream-reactor-${STREAM_REACTOR_VERSION}_connect${KAFKA_VERSION_4SR}.tar.gz\"\nARG ELASTICSEARCH_2X_VERSION=2.4.6\nARG ACTIVEMQ_VERSION=5.12.3\nARG CALCITE_LINQ4J_VERSION=1.12.0\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"${STREAM_REACTOR_URL}\" -O /stream-reactor.tar.gz \\\n && mkdir -p /opt/landoop/connectors/stream-reactor \\\n && tar -xf /stream-reactor.tar.gz --no-same-owner --strip-components=1 -C /opt/landoop/connectors/stream-reactor \\\n && rm /stream-reactor.tar.gz \\\n && wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/${ELASTICSEARCH_2X_VERSION}/elasticsearch-${ELASTICSEARCH_2X_VERSION}.tar.gz -O /elasticsearch.tar.gz \\\n && mkdir /elasticsearch \\\n && tar -xf /elasticsearch.tar.gz --no-same-owner --strip-components=1 -C /elasticsearch \\\n && rm -f /elasticsearch/lib/apache-log4j-extras* \\\n && mv /elasticsearch/lib/*.jar /opt/landoop/connectors/stream-reactor/kafka-connect-elastic/ \\\n && rm -rf /elasticsearch* \\\n && wget http://central.maven.org/maven2/org/apache/activemq/activemq-all/${ACTIVEMQ_VERSION}/activemq-all-${ACTIVEMQ_VERSION}.jar -P /opt/landoop/connectors/stream-reactor/kafka-connect-jms \\\n && wget http://central.maven.org/maven2/org/apache/calcite/calcite-linq4j/${CALCITE_LINQ4J_VERSION}/calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar -O /calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar \\\n && for path in /opt/landoop/connectors/stream-reactor/kafka-connect-*; do cp /calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar $path/ ; done \\\n && rm /calcite-linq4j-${CALCITE_LINQ4J_VERSION}.jar \\\n && mkdir -p /opt/landoop/kafka/share/java/landoop-common \\\n && for file in $( find /opt/landoop/connectors/stream-reactor -maxdepth 2 -type f -exec basename {} | grep -Ev \"scala-logging|kafka-connect-common|scala-\" | sort | uniq -c | grep -E \"^\\s+22 \" | awk '{print $2}' ;); do cp /opt/landoop/connectors/stream-reactor/kafka-connect-elastic/$file /opt/landoop/kafka/share/java/landoop-common/ ;rm -f /opt/landoop/connectors/stream-reactor/kafka-connect-*/$file ; done \\\n && for file in $( find /opt/landoop/kafka/share/java/{kafka,landoop-common} -maxdepth 1 -type f -exec basename {} | sort | uniq -c | grep -E \"^\\s+2 \" | awk '{print $2}' ;); do echo \"Removing duplicate /opt/landoop/kafka/share/java/landoop-common/$file.\" ;rm -f /opt/landoop/kafka/share/java/landoop-common/$file ; done \\\n && rm -f /opt/landoop/connectors/stream-reactor/*/*{javadoc,scaladoc,sources}.jar \\\n && echo \"plugin.path=/opt/landoop/connectors/stream-reactor,/opt/landoop/connectors/third-party\" >> /opt/landoop/kafka/etc/schema-registry/connect-avro-distributed.properties\n#   RUN echo \"plugin.path=/opt/landoop/connectors/stream-reactor,/opt/landoop/connectors/third-party\" \\\n#          >> /opt/landoop/kafka/etc/schema-registry/connect-avro-distributed.properties \\\n#       && mkdir -p /opt/landoop/connectors/stream-reactor\n#   Add Third Party Connectors\n#  # Twitter\nARG TWITTER_CONNECTOR_URL=\"https://archive.landoop.com/third-party/kafka-connect-twitter/kafka-connect-twitter-0.1-master-33331ea-connect-1.0.0-jar-with-dependencies.jar\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-twitter \\\n && wget \"$TWITTER_CONNECTOR_URL\" -P /opt/landoop/connectors/third-party/kafka-connect-twitter\n#  # Kafka Connect JDBC\nARG KAFKA_CONNECT_JDBC_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_JDBC_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-jdbc/kafka-connect-jdbc-${KAFKA_CONNECT_JDBC_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_JDBC_URL\" -O /opt/kafka-connect-jdbc.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-jdbc.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-jdbc.tar.gz\n#  # Kafka Connect ELASTICSEARCH\nARG KAFKA_CONNECT_ELASTICSEARCH_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_ELASTICSEARCH_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-elasticsearch/kafka-connect-elasticsearch-${KAFKA_CONNECT_ELASTICSEARCH_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_ELASTICSEARCH_URL\" -O /opt/kafka-connect-elasticsearch.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-elasticsearch.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-elasticsearch.tar.gz\n#  # Kafka Connect HDFS\nARG KAFKA_CONNECT_HDFS_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_HDFS_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-hdfs/kafka-connect-hdfs-${KAFKA_CONNECT_HDFS_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_HDFS_URL\" -O /opt/kafka-connect-hdfs.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-hdfs.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-hdfs.tar.gz\n#   Kafka Connect S3\nARG KAFKA_CONNECT_S3_VERSION=5.0.1-lkd-r0\nARG KAFKA_CONNECT_S3_URL=\"${ARCHIVE_SERVER}/lkd/packages/connectors/third-party/kafka-connect-s3/kafka-connect-s3-${KAFKA_CONNECT_S3_VERSION}.tar.gz\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_S3_URL\" -O /opt/kafka-connect-s3.tar.gz \\\n && mkdir -p /opt/landoop/connectors/third-party/ \\\n && tar --no-same-owner -xf /opt/kafka-connect-s3.tar.gz -C /opt/landoop/connectors/third-party/ \\\n && rm -rf /opt/kafka-connect-s3.tar.gz\n#   Kafka Connect Couchbase\nARG KAFKA_CONNECT_COUCHBASE_VERSION=3.2.2\nARG KAFKA_CONNECT_COUCHBASE_URL=\"http://packages.couchbase.com/clients/kafka/${KAFKA_CONNECT_COUCHBASE_VERSION}/kafka-connect-couchbase-${KAFKA_CONNECT_COUCHBASE_VERSION}.zip\"\nRUN wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_COUCHBASE_URL\" -O /couchbase.zip \\\n && mkdir -p /couchbase /opt/landoop/connectors/third-party/kafka-connect-couchbase \\\n && unzip /couchbase.zip -d /couchbase \\\n && cp -ax /couchbase/kafka-connect-couchbase-${KAFKA_CONNECT_COUCHBASE_VERSION}/* /opt/landoop/connectors/third-party/kafka-connect-couchbase \\\n && chown -R root:root /opt/landoop/connectors/third-party/kafka-connect-couchbase \\\n && rm -rf /couchbase.zip /couchbase\n#   Kafka Connect Dbvisit Replicate\nARG KAFKA_CONNECT_DBVISITREPLICATE_VERSION=2.0.0-SNAPSHOT\nARG KAFKA_CONNECT_DBVISITREPLICATE_URL=\"https://www.dropbox.com/s/nhs8v3lwmigpks1/kafka-connect-dbvisitreplicate-${KAFKA_CONNECT_DBVISITREPLICATE_VERSION}.jar?dl=0\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-dbvisitreplicate \\\n && wget $DEVARCH_USER $DEVARCH_PASS \"$KAFKA_CONNECT_DBVISITREPLICATE_URL\" -O /opt/landoop/connectors/third-party/kafka-connect-dbvisitreplicate/kafka-connect-dbvisitreplicate-${KAFKA_CONNECT_DBVISITREPLICATE_VERSION}.jar\n#   Kafka Connect Debezium MongoDB / MySQL / Postgres\nARG KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION=0.8.3.Final\nARG KAFKA_CONNECT_DEBEZIUM_MONGODB_URL=\"https://search.maven.org/remotecontent?filepath=io/debezium/debezium-connector-mongodb/${KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION}/debezium-connector-mongodb-${KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION}-plugin.tar.gz\"\nARG KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION=0.8.3.Final\nARG KAFKA_CONNECT_DEBEZIUM_MYSQL_URL=\"https://search.maven.org/remotecontent?filepath=io/debezium/debezium-connector-mysql/${KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION}/debezium-connector-mysql-${KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION}-plugin.tar.gz\"\nARG KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION=0.8.3.Final\nARG KAFKA_CONNECT_DEBEZIUM_POSTGRES_URL=\"https://search.maven.org/remotecontent?filepath=io/debezium/debezium-connector-postgres/${KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION}/debezium-connector-postgres-${KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION}-plugin.tar.gz\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-debezium-{mongodb,mysql,postgres} \\\n && wget \"$KAFKA_CONNECT_DEBEZIUM_MONGODB_URL\" -O /debezium-mongodb.tgz \\\n && tar -xf /debezium-mongodb.tgz --owner=root --group=root --strip-components=1 -C /opt/landoop/connectors/third-party/kafka-connect-debezium-mongodb \\\n && wget \"$KAFKA_CONNECT_DEBEZIUM_MYSQL_URL\" -O /debezium-mysql.tgz \\\n && tar -xf /debezium-mysql.tgz --owner=root --group=root --strip-components=1 -C /opt/landoop/connectors/third-party/kafka-connect-debezium-mysql \\\n && wget \"$KAFKA_CONNECT_DEBEZIUM_POSTGRES_URL\" -O /debezium-postgres.tgz \\\n && tar -xf /debezium-postgres.tgz --owner=root --group=root --strip-components=1 -C /opt/landoop/connectors/third-party/kafka-connect-debezium-postgres \\\n && rm -rf /debezium-{mongodb,mysql,postgres}.tgz\n#   Kafka Connect Splunk\nARG KAFKA_CONNECT_SPLUNK_VERSION=\"1.1.0\"\nARG KAFKA_CONNECT_SPLUNK_URL=\"https://github.com/splunk/kafka-connect-splunk/releases/download/v${KAFKA_CONNECT_SPLUNK_VERSION}/splunk-kafka-connect-v${KAFKA_CONNECT_SPLUNK_VERSION}.jar\"\nRUN mkdir -p /opt/landoop/connectors/third-party/kafka-connect-splunk \\\n && wget \"$KAFKA_CONNECT_SPLUNK_URL\" -O /opt/landoop/connectors/third-party/kafka-connect-splunk/splunk-kafka-connect-v${KAFKA_CONNECT_SPLUNK_VERSION}.jar\n#  ###########\n#   Add tools/\n#  ###########\n#   Add Coyote\nARG COYOTE_VERSION=1.5\nARG COYOTE_URL=\"https://github.com/Landoop/coyote/releases/download/v${COYOTE_VERSION}/coyote-${COYOTE_VERSION}\"\nRUN mkdir -p /opt/landoop/tools/bin/win /opt/landoop/tools/bin/mac /opt/landoop/tools/share/coyote/examples \\\n && wget \"$COYOTE_URL\"-linux-amd64 -O /opt/landoop/tools/bin/coyote \\\n && wget \"$COYOTE_URL\"-darwin-amd64 -O /opt/landoop/tools/bin/mac/coyote \\\n && wget \"$COYOTE_URL\"-windows-amd64.exe -O /opt/landoop/tools/bin/win/coyote \\\n && chmod +x /opt/landoop/tools/bin/coyote /opt/landoop/tools/bin/mac/coyote\nADD lkd/simple-integration-tests.yml /opt/landoop/tools/share/coyote/examples/\n#   Add Kafka Topic UI, Schema Registry UI, Kafka Connect UI\nARG KAFKA_TOPICS_UI_VERSION=0.9.4\nARG KAFKA_TOPICS_UI_URL=\"https://github.com/Landoop/kafka-topics-ui/releases/download/v${KAFKA_TOPICS_UI_VERSION}/kafka-topics-ui-${KAFKA_TOPICS_UI_VERSION}.tar.gz\"\nARG SCHEMA_REGISTRY_UI_VERSION=0.9.5\nARG SCHEMA_REGISTRY_UI_URL=\"https://github.com/Landoop/schema-registry-ui/releases/download/v.${SCHEMA_REGISTRY_UI_VERSION}/schema-registry-ui-${SCHEMA_REGISTRY_UI_VERSION}.tar.gz\"\nARG KAFKA_CONNECT_UI_VERSION=0.9.7\nARG KAFKA_CONNECT_UI_URL=\"https://github.com/Landoop/kafka-connect-ui/releases/download/v.${KAFKA_CONNECT_UI_VERSION}/kafka-connect-ui-${KAFKA_CONNECT_UI_VERSION}.tar.gz\"\nRUN mkdir -p /opt/landoop/tools/share/kafka-topics-ui/ /opt/landoop/tools/share/schema-registry-ui/ /opt/landoop/tools/share/kafka-connect-ui/ \\\n && wget \"$KAFKA_TOPICS_UI_URL\" -O /opt/landoop/tools/share/kafka-topics-ui/kafka-topics-ui.tar.gz \\\n && wget \"$SCHEMA_REGISTRY_UI_URL\" -O /opt/landoop/tools/share/schema-registry-ui/schema-registry-ui.tar.gz \\\n && wget \"$KAFKA_CONNECT_UI_URL\" -O /opt/landoop/tools/share/kafka-connect-ui/kafka-connect-ui.tar.gz\n#   Add Kafka Autocomplete\nARG KAFKA_AUTOCOMPLETE_VERSION=0.3\nARG KAFKA_AUTOCOMPLETE_URL=\"https://github.com/Landoop/kafka-autocomplete/releases/download/${KAFKA_AUTOCOMPLETE_VERSION}/kafka\"\nRUN mkdir -p /opt/landoop/tools/share/kafka-autocomplete /opt/landoop/tools/share/bash-completion/completions \\\n && wget \"$KAFKA_AUTOCOMPLETE_URL\" -O /opt/landoop/tools/share/kafka-autocomplete/kafka \\\n && wget \"$KAFKA_AUTOCOMPLETE_URL\" -O /opt/landoop/tools/share/bash-completion/completions/kafka\n#   Enable jline for Zookeeper\nRUN TJLINE=\"$( find /opt/landoop/kafka -name \"jline-0*.jar\" | head -n1 ;)\" \\\n && if [[ -n $TJLINE ]] ; then sed \"s|^exec.*|export CLASSPATH=\\\"$CLASSPATH:$TJLINE\\\"\\n&|\" -i /opt/landoop/kafka/bin/zookeeper-shell ; fi\n#   Add normcat\nARG NORMCAT_VERSION=1.1.1\nARG NORMCAT_URL=\"https://github.com/andmarios/normcat/releases/download/${NORMCAT_VERSION}/normcat-${NORMCAT_VERSION}\"\nRUN mkdir -p /opt/landoop/tools/bin/win /opt/landoop/tools/bin/mac \\\n && wget \"$NORMCAT_URL\"-linux-amd64-lowmem.tar.gz -O /normcat-linux.tgz \\\n && tar -xf /normcat-linux.tgz -C /opt/landoop/tools/bin \\\n && wget \"$NORMCAT_URL\"-darwin-amd64.zip -O /normcat-mac.zip \\\n && unzip /normcat-mac.zip -d /opt/landoop/tools/bin/mac \\\n && wget \"$NORMCAT_URL\"-windows-amd64.zip -O /normcat-win.zip \\\n && unzip /normcat-win.zip -d /opt/landoop/tools/bin/win \\\n && chmod +x /opt/landoop/tools/bin/coyote /opt/landoop/tools/bin/mac/coyote \\\n && rm -f /normcat-linux.tg /normcat-mac.zip /normcat-win.zip\n#  #########\n#   Finalize\n#  #########\nRUN echo \"LKD_VERSION=${LKD_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_VERSION=${KAFKA_LVERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"CONNECT_VERSION=${KAFKA_LVERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"SCHEMA_REGISTRY_VERSION=${REGISTRY_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"REST_PROXY_VERSION=${REST_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"STREAM_REACTOR_VERSION=${STREAM_REACTOR_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_JDBC_VERSION=${KAFKA_CONNECT_JDBC_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_ELASTICSEARCH_VERSION=${KAFKA_CONNECT_ELASTICSEARCH_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_HDFS_VERSION=${KAFKA_CONNECT_HDFS_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_S3_VERSION=${KAFKA_CONNECT_S3_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_COUCHBASE_VERSION=${KAFKA_CONNECT_COUCHBASE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DBVISITREPLICATE_VERSION=${KAFKA_CONNECT_DBVISITREPLICATE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION=${KAFKA_CONNECT_DEBEZIUM_MONGODB_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION=${KAFKA_CONNECT_DEBEZIUM_MYSQL_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION=${KAFKA_CONNECT_DEBEZIUM_POSTGRES_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_SPLUNK_VERSION=${KAFKA_CONNECT_SPLUNK_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_TOPICS_UI_VERSION=${KAFKA_TOPICS_UI_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"SCHEMA_REGISTRY_UI_VERSION=${SCHEMA_REGISTRY_UI_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_CONNECT_UI_VERSION=${KAFKA_CONNECT_UI_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"COYOTE_VERSION=${COYOTE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"KAFKA_AUTOCOMPLETE_VERSION=${KAFKA_AUTOCOMPLETE_VERSION}\" | tee -a /opt/landoop/build.info \\\n && echo \"NORMCAT_VERSION=${NORMCAT_VERSION}\" | tee -a /opt/landoop/build.info\n#   duphard (replace duplicates with hard links) and create archive\n#   We run as two separate commands because otherwise the build fails in docker hub (but not locally)\nRUN duphard -d=0 /opt/landoop\nRUN tar -czf /LKD-${LKD_VERSION}.tar.gz --owner=root --group=root -C /opt landoop \\\n && rm -rf /opt/landoop\n#   Unfortunately we have to make this a separate step in order for docker to understand the change to hardlinks\n#   Good thing: final image that people download is much smaller (~200MB).\nRUN tar xf /LKD-${LKD_VERSION}.tar.gz -C /opt \\\n && rm /LKD-${LKD_VERSION}.tar.gz\nENV LKD_VERSION=\"${LKD_VERSION}\"\n#   If this stage is run as container and you mount `/mnt`, we will create the LKD archive there.\nCMD [\"bash\", \"-c\", \"tar\", \"-czf\", \"/mnt/LKD-${LKD_VERSION}.tar.gz\", \"-C\", \"/opt\", \"landoop\", \";\", \"chown\", \"--reference=/mnt\", \"/mnt/LKD-${LKD_VERSION}.tar.gz\"]\nFROM alpine\nMAINTAINER Marios Andreopoulos <marios@landoop.com>\nCOPY --from=compile-lkd /opt /opt\n#   Update, install tooling and some basic setup\nRUN apk add --no-cache bash bash-completion bzip2 coreutils curl dumb-init gettext gzip jq libstdc++ nss openjdk8-jre-base openssl sqlite supervisor tar tzdata wget \\\n && echo \"progress = dot:giga\" | tee /etc/wgetrc \\\n && mkdir -p /opt \\\n && mkdir /extra-connect-jars /connectors \\\n && mkdir /etc/supervisord.d /etc/supervisord.templates.d\nSHELL [\"/bin/bash\", \"-c\"]\nWORKDIR /\n#   Install external tooling\n#   checkport: checks for ports that are already in use, useful when we run with\n#              '--net=host so we have an easy way to detect if our ports are free\n#   quickcert: a small tool we use to create a CA and key-cert pairs so we can easily\n#              setup SSL on the brokers with autogenerated keys and certs\n#   glibc    : alpine linux has an embedded libc which misses some functions that are\n#              needed by some apps (e.g jvm's rocksdb jni — HDFS connector, Lenses, etc),\n#              so we add glibc to make them work. Also now we can add en_US.UTF-8 locale.\n#              https://github.com/sgerrand/alpine-pkg-glibc\n#   caddy    : an excellent web server we use to serve fast-data-dev UI, proxy various REST\n#              endpoints, etc\n#              https://github.com/mholt/caddy\nARG CHECKPORT_URL=\"https://gitlab.com/andmarios/checkport/uploads/3903dcaeae16cd2d6156213d22f23509/checkport\"\nARG QUICKCERT_URL=\"https://github.com/andmarios/quickcert/releases/download/1.0/quickcert-1.0-linux-amd64-alpine\"\nARG GLIBC_INST_VERSION=\"2.27-r0\"\nARG CADDY_URL=https://github.com/mholt/caddy/releases/download/v0.10.10/caddy_v0.10.10_linux_amd64.tar.gz\nRUN wget \"$CHECKPORT_URL\" -O /usr/local/bin/checkport \\\n && wget \"$QUICKCERT_URL\" -O /usr/local/bin/quickcert \\\n && chmod 0755 /usr/local/bin/quickcert /usr/local/bin/checkport \\\n && wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_INST_VERSION}/glibc-${GLIBC_INST_VERSION}.apk \\\n && wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_INST_VERSION}/glibc-bin-${GLIBC_INST_VERSION}.apk \\\n && wget https://github.com/sgerrand/alpine-pkg-glibc/releases/download/${GLIBC_INST_VERSION}/glibc-i18n-${GLIBC_INST_VERSION}.apk \\\n && apk add --no-cache --allow-untrusted glibc-${GLIBC_INST_VERSION}.apk glibc-bin-${GLIBC_INST_VERSION}.apk glibc-i18n-${GLIBC_INST_VERSION}.apk \\\n && rm -f glibc-${GLIBC_INST_VERSION}.apk glibc-bin-${GLIBC_INST_VERSION}.apk glibc-i18n-${GLIBC_INST_VERSION}.apk \\\n && wget \"$CADDY_URL\" -O /caddy.tgz \\\n && mkdir -p /opt/caddy \\\n && tar xzf /caddy.tgz -C /opt/caddy \\\n && rm -f /caddy.tgz \\\n && /usr/glibc-compat/bin/localedef -i en_US -f UTF-8 en_US.UTF-8\nENV LANG=\"en_US.UTF-8\" \\\n    LANGUAGE=\"en_US.UTF-8\" \\\n    LC_ALL=\"en_US.UTF-8\"\nCOPY /filesystem /\nRUN chmod +x /usr/local/bin/{smoke-tests,logs-to-kafka,nullsink}.sh /usr/local/share/landoop/sample-data/*.sh\n#   Create system symlinks to Kafka binaries\nRUN bash -c 'for i in $(find /opt/landoop/kafka/bin /opt/landoop/tools/bin -maxdepth 1 -type f); do ln -s $i /usr/local/bin/$(echo $i | sed -e \"s>.*/>>\"); done'\n#   Add kafka ssl principal builder\nRUN wget https://archive.landoop.com/third-party/kafka-custom-principal-builder/kafka-custom-principal-builder-1.0-SNAPSHOT.jar -P /opt/landoop/kafka/share/java/kafka \\\n && mkdir -p /opt/landoop/kafka/share/docs/kafka-custom-principal-builder \\\n && wget https://archive.landoop.com/third-party/kafka-custom-principal-builder/LICENSE -P /opt/landoop/kafka/share/docs/kafka-custom-principal-builder \\\n && wget https://archive.landoop.com/third-party/kafka-custom-principal-builder/README.md -P /opt/landoop/kafka/share/docs/kafka-custom-principal-builder\n#   Setup Kafka Topics UI, Schema Registry UI, Kafka Connect UI\nRUN mkdir -p /var/www/kafka-topics-ui /var/www/schema-registry-ui /var/www/kafka-connect-ui \\\n && tar -xf /opt/landoop/tools/share/kafka-topics-ui/kafka-topics-ui.tar.gz -C /var/www/kafka-topics-ui --exclude=env.js \\\n && tar -xf /opt/landoop/tools/share/schema-registry-ui/schema-registry-ui.tar.gz -C /var/www/schema-registry-ui --exclude=env.js \\\n && tar -xf /opt/landoop/tools/share/kafka-connect-ui/kafka-connect-ui.tar.gz -C /var/www/kafka-connect-ui --exclude=env.js\nRUN ln -s /var/log /var/www/logs\n#   Add executables, settings and configuration\nADD setup-and-run.sh /usr/local/bin/\nRUN chmod +x /usr/local/bin/setup-and-run.sh \\\n && ln -s /usr/local/share/landoop/etc/bashrc /root/.bashrc\nVOLUME [\"/data\"]\nARG BUILD_BRANCH\nARG BUILD_COMMIT\nARG BUILD_TIME\nARG DOCKER_REPO=local\nRUN echo \"BUILD_BRANCH=${BUILD_BRANCH}\" | tee /build.info \\\n && echo \"BUILD_COMMIT=${BUILD_COMMIT}\" | tee -a /build.info \\\n && echo \"BUILD_TIME=${BUILD_TIME}\" | tee -a /build.info \\\n && echo \"DOCKER_REPO=${DOCKER_REPO}\" | tee -a /build.info \\\n && sed -e 's/^/FDD_/' /opt/landoop/build.info | tee -a /build.info\nEXPOSE 2181/tcp 3030/tcp 3031/tcp 8081/tcp 8082/tcp 8083/tcp 9092/tcp\nENTRYPOINT [\"/usr/bin/dumb-init\", \"--\"]\nCMD [\"/usr/local/bin/setup-and-run.sh\"]\n","originalDockerfileUglifiedHash":"27964f61796203d81afc9d9fdd80361a","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/b6865d23ea37425fcac61a981154129e78c345ca.dockerfile"}