{"seed":1086131864,"processedDockerfileHash":"36d787bfabc6ed1a64481d14d42b3ad7","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","have-a-healthcheck","have-a-user"],"processedDockerfile":"FROM nvidia/cuda:10.0-devel-ubuntu16.04\n#   TensorFlow v1.13 is coupled to CUDA10.\nENV TENSORFLOW_VERSION=\"r1.13\"\nENV CUDNN_VERSION=\"7.4.2.24-1+cuda10.0\"\nENV NCCL_VERSION=\"2.4.2-1+cuda10.0\"\nENV BAZEL_VERSION=\"0.21.0\"\n#   Python 2.7 or 3.5 is supported by Ubuntu Xenial out of the box\nARG python=3.5\nENV PYTHON_VERSION=\"${python}\"\nRUN apt-get update \\\n && apt-get install --no-install-recommends build-essential cmake git curl vim wget pkg-config zip g++ zlib1g-dev unzip ca-certificates libjpeg-dev libpng-dev libcudnn7=${CUDNN_VERSION} libcudnn7-dev=${CUDNN_VERSION} libnccl2=${NCCL_VERSION} libnccl-dev=${NCCL_VERSION} python${PYTHON_VERSION} python${PYTHON_VERSION}-dev -y\n#  RUN cp /usr/lib/x86_64-linux-gnu/libcudnn* /usr/local/cuda/lib64/ && \\\n#      find /usr/local/cuda-10.0/lib64/ -type f -name 'lib*_static.a' -not -name 'libcudart_static.a' -delete && \\\n#      rm /usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a && \\\n#      rm /usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudnn.so.7 && \\\n#      ln -sf /usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudnn.so.7.4.2 /usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudnn.so.7\nRUN ln -s /usr/bin/python${PYTHON_VERSION} /usr/bin/python\nRUN curl -O https://bootstrap.pypa.io/get-pip.py \\\n && python get-pip.py \\\n && rm get-pip.py\n#   Running bazel inside a `docker build` command causes trouble, cf:\n#     https://github.com/bazelbuild/bazel/issues/134\n#   The easiest solution is to set up a bazelrc file forcing --batch.\nRUN echo \"startup --batch\" >> /etc/bazel.bazelrc\nRUN echo \"build --spawn_strategy=standalone --genrule_strategy=standalone\" >> /etc/bazel.bazelrc\n#   Install bazel, bazel depends on pkg-config zip g++ zlib1g-dev unzip\nRUN wget \"https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh\" \\\n && chmod +x bazel-*.sh \\\n && ./bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh \\\n && rm bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh\n#   Install the TensorFlow pip package dependencies \nRUN pip install six==1.16.0 numpy==1.24.2 wheel==0.40.0 mock==5.0.2 h5py==3.8.0\nRUN pip install keras_applications==1.0.6 --no-deps\nRUN pip install keras_preprocessing==1.0.5 --no-deps\nRUN git clone --branch ${TENSORFLOW_VERSION} --depth=1 https://github.com/tensorflow/tensorflow.git /root/tensorflow\nWORKDIR \"/root/tensorflow\"\n#   Configure the Tensorflow build\n#  https://github.com/tensorflow/tensorflow/issues/26001 config for python\nENV CI_BUILD_PYTHON=\"python\" \\\n    LD_LIBRARY_PATH=\"/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\" \\\n    TF_NEED_CUDA=\"1\" \\\n    TF_NEED_MKL=\"1\" \\\n    TF_DOWNLOAD_MKL=\"1\" \\\n    TF_ENABLE_XLA=\"0\" \\\n    CUDA_TOOLKIT_PATH=\"/usr/local/cuda\" \\\n    CUDNN_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\" \\\n    NCCL_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\" \\\n    NCCL_HDR_PATH=\"/usr/include\" \\\n    TF_CUDA_VERSION=\"10.0\" \\\n    TF_CUDNN_VERSION=\"7\" \\\n    TF_NCCL_VERSION=\"2.4.2\" \\\n    TF_CUDA_COMPUTE_CAPABILITIES=\"5.2,6.0,6.1,7.0\"\n#  RUN sed -i '/toco/s/^/#/' /root/tensorflow/tensorflow/tools/pip_package/BUILD\n#  RUN sed -i '/toco/s/^/#/' /root/tensorflow/tensorflow/tools/pip_package/build_pip_package.sh\n#   ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs && \\\n#  https://github.com/tensorflow/tensorflow/issues/10289\nRUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 \\\n && LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs/:${LD_LIBRARY_PATH} tensorflow/tools/ci_build/builds/configured GPU bazel build -j 30 -c opt --config=cuda --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --action_env LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}\" --verbose_failures //tensorflow/tools/pip_package:build_pip_package\nRUN bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip\nRUN pip install /tmp/pip/tensorflow-*.whl --upgrade\n#   Install Open MPI 4.0.0\nRUN mkdir /tmp/openmpi \\\n && cd /tmp/openmpi \\\n && wget https://download.open-mpi.org/release/open-mpi/v4.0/openmpi-4.0.0.tar.gz \\\n && tar zxf openmpi-4.0.0.tar.gz \\\n && cd openmpi-4.0.0 \\\n && ./configure --enable-orterun-prefix-by-default \\\n && make -j $( nproc ;) all \\\n && make install \\\n && ldconfig \\\n && rm -rf /tmp/openmpi\n#   Create a wrapper for OpenMPI to allow running as root by default\nRUN mv /usr/local/bin/mpirun /usr/local/bin/mpirun.real \\\n && echo '#!/bin/bash' > /usr/local/bin/mpirun \\\n && echo 'mpirun.real --allow-run-as-root \"$@\"' >> /usr/local/bin/mpirun \\\n && chmod a+x /usr/local/bin/mpirun\n#   Configure OpenMPI to run good defaults:\n#     --bind-to none --map-by slot --mca btl_tcp_if_exclude lo,docker0\nRUN echo \"hwloc_base_binding_policy = socket\" >> /usr/local/etc/openmpi-mca-params.conf \\\n && echo \"rmaps_base_mapping_policy = slot\" >> /usr/local/etc/openmpi-mca-params.conf \\\n && echo \"btl_tcp_if_exclude = lo,docker0\" >> /usr/local/etc/openmpi-mca-params.conf\n#   Install Horovod, temporarily using CUDA stubs, /usr/local/cuda links to /usr/local/cuda-10.0\n#   cd to root to avoid `sh: 0: getcwd() failed: No such file or directory` from last step\n#   Move Horovod Installation after OpenMPI to avoid failure `error: mpicxx -show failed (see error below), is MPI in $PATH?`\n#   https://github.com/horovod/horovod/issues/137 https://github.com/horovod/horovod/blob/master/docs/troubleshooting.md\nRUN cd ~/ \\\n && ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs \\\n && HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_WITH_TENSORFLOW=1 pip install --no-cache-dir horovod \\\n && ldconfig\n#   Set default NCCL parameters\nRUN echo NCCL_DEBUG=INFO >> /etc/nccl.conf\n#   Install OpenSSH for MPI to communicate between containers\nRUN apt-get install --no-install-recommends openssh-client openssh-server -y \\\n && mkdir -p /var/run/sshd\n#   Allow OpenSSH to talk to containers without asking for confirmation\nRUN cat /etc/ssh/ssh_config | grep -v StrictHostKeyChecking > /etc/ssh/ssh_config.new \\\n && echo \" StrictHostKeyChecking no\" >> /etc/ssh/ssh_config.new \\\n && mv /etc/ssh/ssh_config.new /etc/ssh/ssh_config\n#   My repo fix an issue on benchmark master which was not v1.13 compatible\nRUN mkdir /code \\\n && git clone https://github.com/aws-samples/deep-learning-models.git /code\nWORKDIR \"/code\"\nCMD mpirun python models/resnet/tensorflow/train_imagenet_resnet_hvd.py --batch_size=256 --model=resnet50 --num_batches=1000 --fp16 --lr_decay_mode=poly --synthetic\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"FROM nvidia/cuda:10.0-devel-ubuntu16.04\n#  TensorFlow v1.13 is coupled to CUDA10.\nENV TENSORFLOW_VERSION=\"r1.13\"\nENV CUDNN_VERSION=\"7.4.2.24-1+cuda10.0\"\nENV NCCL_VERSION=\"2.4.2-1+cuda10.0\"\nENV BAZEL_VERSION=\"0.21.0\"\n#  Python 2.7 or 3.5 is supported by Ubuntu Xenial out of the box\nARG python=3.5\nENV PYTHON_VERSION=\"${python}\"\nRUN apt-get update \\\n && apt-get install --no-install-recommends build-essential cmake git curl vim wget pkg-config zip g++ zlib1g-dev unzip ca-certificates libjpeg-dev libpng-dev libcudnn7=${CUDNN_VERSION} libcudnn7-dev=${CUDNN_VERSION} libnccl2=${NCCL_VERSION} libnccl-dev=${NCCL_VERSION} python${PYTHON_VERSION} python${PYTHON_VERSION}-dev -y\n# RUN cp /usr/lib/x86_64-linux-gnu/libcudnn* /usr/local/cuda/lib64/ && \\\n#     find /usr/local/cuda-10.0/lib64/ -type f -name 'lib*_static.a' -not -name 'libcudart_static.a' -delete && \\\n#     rm /usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a && \\\n#     rm /usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudnn.so.7 && \\\n#     ln -sf /usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudnn.so.7.4.2 /usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudnn.so.7\nRUN ln -s /usr/bin/python${PYTHON_VERSION} /usr/bin/python\nRUN curl -O https://bootstrap.pypa.io/get-pip.py \\\n && python get-pip.py \\\n && rm get-pip.py\n#  Running bazel inside a `docker build` command causes trouble, cf:\n#    https://github.com/bazelbuild/bazel/issues/134\n#  The easiest solution is to set up a bazelrc file forcing --batch.\nRUN echo \"startup --batch\" >> /etc/bazel.bazelrc\nRUN echo \"build --spawn_strategy=standalone --genrule_strategy=standalone\" >> /etc/bazel.bazelrc\n#  Install bazel, bazel depends on pkg-config zip g++ zlib1g-dev unzip\nRUN wget \"https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh\" \\\n && chmod +x bazel-*.sh \\\n && ./bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh \\\n && rm bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh\n#  Install the TensorFlow pip package dependencies \nRUN pip install six numpy wheel mock h5py\nRUN pip install keras_applications==1.0.6 --no-deps\nRUN pip install keras_preprocessing==1.0.5 --no-deps\nRUN git clone --branch ${TENSORFLOW_VERSION} --depth=1 https://github.com/tensorflow/tensorflow.git /root/tensorflow\nWORKDIR \"/root/tensorflow\"\n#  Configure the Tensorflow build\n# https://github.com/tensorflow/tensorflow/issues/26001 config for python\nENV CI_BUILD_PYTHON=\"python\" \\\n    LD_LIBRARY_PATH=\"/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\" \\\n    TF_NEED_CUDA=\"1\" \\\n    TF_NEED_MKL=\"1\" \\\n    TF_DOWNLOAD_MKL=\"1\" \\\n    TF_ENABLE_XLA=\"0\" \\\n    CUDA_TOOLKIT_PATH=\"/usr/local/cuda\" \\\n    CUDNN_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\" \\\n    NCCL_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\" \\\n    NCCL_HDR_PATH=\"/usr/include\" \\\n    TF_CUDA_VERSION=\"10.0\" \\\n    TF_CUDNN_VERSION=\"7\" \\\n    TF_NCCL_VERSION=\"2.4.2\" \\\n    TF_CUDA_COMPUTE_CAPABILITIES=\"5.2,6.0,6.1,7.0\"\n# RUN sed -i '/toco/s/^/#/' /root/tensorflow/tensorflow/tools/pip_package/BUILD\n# RUN sed -i '/toco/s/^/#/' /root/tensorflow/tensorflow/tools/pip_package/build_pip_package.sh\n#  ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs && \\\n# https://github.com/tensorflow/tensorflow/issues/10289\nRUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 \\\n && LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs/:${LD_LIBRARY_PATH} tensorflow/tools/ci_build/builds/configured GPU bazel build -j 30 -c opt --config=cuda --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --action_env LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}\" --verbose_failures //tensorflow/tools/pip_package:build_pip_package\nRUN bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip\nRUN pip install /tmp/pip/tensorflow-*.whl --upgrade\n#  Install Open MPI 4.0.0\nRUN mkdir /tmp/openmpi \\\n && cd /tmp/openmpi \\\n && wget https://download.open-mpi.org/release/open-mpi/v4.0/openmpi-4.0.0.tar.gz \\\n && tar zxf openmpi-4.0.0.tar.gz \\\n && cd openmpi-4.0.0 \\\n && ./configure --enable-orterun-prefix-by-default \\\n && make -j $( nproc ;) all \\\n && make install \\\n && ldconfig \\\n && rm -rf /tmp/openmpi\n#  Create a wrapper for OpenMPI to allow running as root by default\nRUN mv /usr/local/bin/mpirun /usr/local/bin/mpirun.real \\\n && echo '#!/bin/bash' > /usr/local/bin/mpirun \\\n && echo 'mpirun.real --allow-run-as-root \"$@\"' >> /usr/local/bin/mpirun \\\n && chmod a+x /usr/local/bin/mpirun\n#  Configure OpenMPI to run good defaults:\n#    --bind-to none --map-by slot --mca btl_tcp_if_exclude lo,docker0\nRUN echo \"hwloc_base_binding_policy = socket\" >> /usr/local/etc/openmpi-mca-params.conf \\\n && echo \"rmaps_base_mapping_policy = slot\" >> /usr/local/etc/openmpi-mca-params.conf \\\n && echo \"btl_tcp_if_exclude = lo,docker0\" >> /usr/local/etc/openmpi-mca-params.conf\n#  Install Horovod, temporarily using CUDA stubs, /usr/local/cuda links to /usr/local/cuda-10.0\n#  cd to root to avoid `sh: 0: getcwd() failed: No such file or directory` from last step\n#  Move Horovod Installation after OpenMPI to avoid failure `error: mpicxx -show failed (see error below), is MPI in $PATH?`\n#  https://github.com/horovod/horovod/issues/137 https://github.com/horovod/horovod/blob/master/docs/troubleshooting.md\nRUN cd ~/ \\\n && ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs \\\n && HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_WITH_TENSORFLOW=1 pip install --no-cache-dir horovod \\\n && ldconfig\n#  Set default NCCL parameters\nRUN echo NCCL_DEBUG=INFO >> /etc/nccl.conf\n#  Install OpenSSH for MPI to communicate between containers\nRUN apt-get install --no-install-recommends openssh-client openssh-server -y \\\n && mkdir -p /var/run/sshd\n#  Allow OpenSSH to talk to containers without asking for confirmation\nRUN cat /etc/ssh/ssh_config | grep -v StrictHostKeyChecking > /etc/ssh/ssh_config.new \\\n && echo \" StrictHostKeyChecking no\" >> /etc/ssh/ssh_config.new \\\n && mv /etc/ssh/ssh_config.new /etc/ssh/ssh_config\n#  My repo fix an issue on benchmark master which was not v1.13 compatible\nRUN mkdir /code \\\n && git clone https://github.com/aws-samples/deep-learning-models.git /code\nWORKDIR \"/code\"\nCMD mpirun python models/resnet/tensorflow/train_imagenet_resnet_hvd.py --batch_size=256 --model=resnet50 --num_batches=1000 --fp16 --lr_decay_mode=poly --synthetic\n","injectedSmells":[],"originalDockerfileHash":"5ffa9a997b3eedb458b03cee40bd0e98","successfullyInjectedSmells":[],"originalDockerfileUglified":"FROM nvidia/cuda:10.0-devel-ubuntu16.04\n#   TensorFlow v1.13 is coupled to CUDA10.\nENV TENSORFLOW_VERSION=\"r1.13\"\nENV CUDNN_VERSION=\"7.4.2.24-1+cuda10.0\"\nENV NCCL_VERSION=\"2.4.2-1+cuda10.0\"\nENV BAZEL_VERSION=\"0.21.0\"\n#   Python 2.7 or 3.5 is supported by Ubuntu Xenial out of the box\nARG python=3.5\nENV PYTHON_VERSION=\"${python}\"\nRUN apt-get update \\\n && apt-get install --no-install-recommends build-essential cmake git curl vim wget pkg-config zip g++ zlib1g-dev unzip ca-certificates libjpeg-dev libpng-dev libcudnn7=${CUDNN_VERSION} libcudnn7-dev=${CUDNN_VERSION} libnccl2=${NCCL_VERSION} libnccl-dev=${NCCL_VERSION} python${PYTHON_VERSION} python${PYTHON_VERSION}-dev -y\n#  RUN cp /usr/lib/x86_64-linux-gnu/libcudnn* /usr/local/cuda/lib64/ && \\\n#      find /usr/local/cuda-10.0/lib64/ -type f -name 'lib*_static.a' -not -name 'libcudart_static.a' -delete && \\\n#      rm /usr/lib/x86_64-linux-gnu/libcudnn_static_v7.a && \\\n#      rm /usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudnn.so.7 && \\\n#      ln -sf /usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudnn.so.7.4.2 /usr/local/cuda-10.0/targets/x86_64-linux/lib/libcudnn.so.7\nRUN ln -s /usr/bin/python${PYTHON_VERSION} /usr/bin/python\nRUN curl -O https://bootstrap.pypa.io/get-pip.py \\\n && python get-pip.py \\\n && rm get-pip.py\n#   Running bazel inside a `docker build` command causes trouble, cf:\n#     https://github.com/bazelbuild/bazel/issues/134\n#   The easiest solution is to set up a bazelrc file forcing --batch.\nRUN echo \"startup --batch\" >> /etc/bazel.bazelrc\nRUN echo \"build --spawn_strategy=standalone --genrule_strategy=standalone\" >> /etc/bazel.bazelrc\n#   Install bazel, bazel depends on pkg-config zip g++ zlib1g-dev unzip\nRUN wget \"https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh\" \\\n && chmod +x bazel-*.sh \\\n && ./bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh \\\n && rm bazel-${BAZEL_VERSION}-installer-linux-x86_64.sh\n#   Install the TensorFlow pip package dependencies \nRUN pip install six numpy wheel mock h5py\nRUN pip install keras_applications==1.0.6 --no-deps\nRUN pip install keras_preprocessing==1.0.5 --no-deps\nRUN git clone --branch ${TENSORFLOW_VERSION} --depth=1 https://github.com/tensorflow/tensorflow.git /root/tensorflow\nWORKDIR \"/root/tensorflow\"\n#   Configure the Tensorflow build\n#  https://github.com/tensorflow/tensorflow/issues/26001 config for python\nENV CI_BUILD_PYTHON=\"python\" \\\n    LD_LIBRARY_PATH=\"/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\" \\\n    TF_NEED_CUDA=\"1\" \\\n    TF_NEED_MKL=\"1\" \\\n    TF_DOWNLOAD_MKL=\"1\" \\\n    TF_ENABLE_XLA=\"0\" \\\n    CUDA_TOOLKIT_PATH=\"/usr/local/cuda\" \\\n    CUDNN_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\" \\\n    NCCL_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\" \\\n    NCCL_HDR_PATH=\"/usr/include\" \\\n    TF_CUDA_VERSION=\"10.0\" \\\n    TF_CUDNN_VERSION=\"7\" \\\n    TF_NCCL_VERSION=\"2.4.2\" \\\n    TF_CUDA_COMPUTE_CAPABILITIES=\"5.2,6.0,6.1,7.0\"\n#  RUN sed -i '/toco/s/^/#/' /root/tensorflow/tensorflow/tools/pip_package/BUILD\n#  RUN sed -i '/toco/s/^/#/' /root/tensorflow/tensorflow/tools/pip_package/build_pip_package.sh\n#   ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs && \\\n#  https://github.com/tensorflow/tensorflow/issues/10289\nRUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 \\\n && LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs/:${LD_LIBRARY_PATH} tensorflow/tools/ci_build/builds/configured GPU bazel build -j 30 -c opt --config=cuda --config=mkl --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --action_env LD_LIBRARY_PATH=\"${LD_LIBRARY_PATH}\" --verbose_failures //tensorflow/tools/pip_package:build_pip_package\nRUN bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip\nRUN pip install /tmp/pip/tensorflow-*.whl --upgrade\n#   Install Open MPI 4.0.0\nRUN mkdir /tmp/openmpi \\\n && cd /tmp/openmpi \\\n && wget https://download.open-mpi.org/release/open-mpi/v4.0/openmpi-4.0.0.tar.gz \\\n && tar zxf openmpi-4.0.0.tar.gz \\\n && cd openmpi-4.0.0 \\\n && ./configure --enable-orterun-prefix-by-default \\\n && make -j $( nproc ;) all \\\n && make install \\\n && ldconfig \\\n && rm -rf /tmp/openmpi\n#   Create a wrapper for OpenMPI to allow running as root by default\nRUN mv /usr/local/bin/mpirun /usr/local/bin/mpirun.real \\\n && echo '#!/bin/bash' > /usr/local/bin/mpirun \\\n && echo 'mpirun.real --allow-run-as-root \"$@\"' >> /usr/local/bin/mpirun \\\n && chmod a+x /usr/local/bin/mpirun\n#   Configure OpenMPI to run good defaults:\n#     --bind-to none --map-by slot --mca btl_tcp_if_exclude lo,docker0\nRUN echo \"hwloc_base_binding_policy = socket\" >> /usr/local/etc/openmpi-mca-params.conf \\\n && echo \"rmaps_base_mapping_policy = slot\" >> /usr/local/etc/openmpi-mca-params.conf \\\n && echo \"btl_tcp_if_exclude = lo,docker0\" >> /usr/local/etc/openmpi-mca-params.conf\n#   Install Horovod, temporarily using CUDA stubs, /usr/local/cuda links to /usr/local/cuda-10.0\n#   cd to root to avoid `sh: 0: getcwd() failed: No such file or directory` from last step\n#   Move Horovod Installation after OpenMPI to avoid failure `error: mpicxx -show failed (see error below), is MPI in $PATH?`\n#   https://github.com/horovod/horovod/issues/137 https://github.com/horovod/horovod/blob/master/docs/troubleshooting.md\nRUN cd ~/ \\\n && ldconfig /usr/local/cuda/targets/x86_64-linux/lib/stubs \\\n && HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_WITH_TENSORFLOW=1 pip install --no-cache-dir horovod \\\n && ldconfig\n#   Set default NCCL parameters\nRUN echo NCCL_DEBUG=INFO >> /etc/nccl.conf\n#   Install OpenSSH for MPI to communicate between containers\nRUN apt-get install --no-install-recommends openssh-client openssh-server -y \\\n && mkdir -p /var/run/sshd\n#   Allow OpenSSH to talk to containers without asking for confirmation\nRUN cat /etc/ssh/ssh_config | grep -v StrictHostKeyChecking > /etc/ssh/ssh_config.new \\\n && echo \" StrictHostKeyChecking no\" >> /etc/ssh/ssh_config.new \\\n && mv /etc/ssh/ssh_config.new /etc/ssh/ssh_config\n#   My repo fix an issue on benchmark master which was not v1.13 compatible\nRUN mkdir /code \\\n && git clone https://github.com/aws-samples/deep-learning-models.git /code\nWORKDIR \"/code\"\nCMD mpirun python models/resnet/tensorflow/train_imagenet_resnet_hvd.py --batch_size=256 --model=resnet50 --num_batches=1000 --fp16 --lr_decay_mode=poly --synthetic\n","originalDockerfileUglifiedHash":"26eb98dbf05665ed38255ea40618d81f","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/e471573c356e01f147cfc315300a9678101d96f4.dockerfile"}