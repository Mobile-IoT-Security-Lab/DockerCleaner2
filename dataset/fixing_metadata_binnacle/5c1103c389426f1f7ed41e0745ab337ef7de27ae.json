{"seed":548866279,"processedDockerfileHash":"eb368b13e707f61701a4eb4b267651c5","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["use-no-install-recommends","pin-package-manager-versions-apt-get","have-a-healthcheck","have-a-user"],"processedDockerfile":"#   ch-test-scope: full\nFROM debian9\n#   A key goal of this Dockerfile is to demonstrate best practices for building\n#   OpenMPI for use inside a container.\n#\n#   This OpenMPI aspires to work close to optimally on clusters with any of the\n#   following interconnects:\n#\n#      - Ethernet (TCP/IP)\n#      - InfiniBand (IB)\n#      - Omni-Path (OPA)\n#      - RDMA over Converged Ethernet (RoCE) interconnects\n#\n#   with no environment variables, command line arguments, or additional\n#   configuration files. Thus, we try to implement decisions at build time.\n#\n#   This is a work in progress, and we're very interested in feedback.\n#\n#   OpenMPI has numerous ways to communicate messages [1]. The ones relevant to\n#   this build and the interconnects they support are:\n#\n#     Module        Eth   IB    OPA   RoCE    note  decision\n#     ------------  ----  ----  ----  ----    ----  --------\n#\n#     ob1 : tcp      Y*    X     X     X      a     include\n#     ob1 : openib   N     Y     Y     Y      b,c   exclude\n#     cm  : psm2     N     N     Y*    N            include\n#         : ucx      Y?    Y*    N     Y?     b,d   include\n#\n#     Y : supported\n#     Y*: best choice for that interconnect\n#     X : supported but sub-optimal\n#\n#     a : No RDMA, so performance will suffer.\n#     b : Uses libibverbs.\n#     c : Will be removed in OpenMPI 4.\n#     d : Uses Mellanox libraries if available in preference to libibverbs.\n#\n#   You can check what's available with:\n#\n#     $ ch-run /var/tmp/openmpi -- ompi_info | egrep '(btl|mtl|pml)'\n#\n#   The other build decisions are:\n#\n#     1. PMI/PMIx: Include these so that we can use srun or any other PMI[x]\n#        provider, with no matching OpenMPI needed on the host.\n#\n#     2. --disable-pty-support to avoid \"pipe function call failed when\n#        setting up I/O forwarding subsystem\".\n#\n#     3. --enable-mca-no-build=plm-slurm to support launching processes using\n#        the host's srun (i.e., the container OpenMPI needs to talk to the host\n#        Slurm's PMI) but prevent OpenMPI from invoking srun itself from within\n#        the container, where srun is not installed (the error messages from\n#        this are inscrutable).\n#\n#   [1]: https://github.com/open-mpi/ompi/blob/master/README\n#   OS packages needed to build this stuff.\nRUN apt-get install --no-install-recommends autoconf=2.71-3 file=1:5.44-3 flex=2.6.4-8.1 g++=4:12.2.0-3ubuntu1 gcc=4:12.2.0-3ubuntu1 gfortran=4:12.2.0-3ubuntu1 git=1:2.39.2-1ubuntu1 hwloc-nox=2.9.0-1 less=590-1.2 libdb5.3-dev=5.3.28+dfsg2-1 libhwloc-dev=2.9.0-1 libnl-3-200=3.7.0-0.2 libnl-route-3-200=3.7.0-0.2 libnl-route-3-dev=3.7.0-0.2 libnuma1=2.0.16-1 libpmi2-0-dev=22.05.8-3 make=4.3-4.1build1 wget=1.21.3-1ubuntu1 udev=252.5-2ubuntu3 -y --no-install-suggests\nWORKDIR /usr/local/src\n#   Use the Buster versions of libpsm2 (not present in Stretch) and libibverbs\n#   (too old in Stretch). Download manually because I'm too lazy to set up\n#   package pinning.\n#\n#   Note that libpsm2 is x86-64 only:\n#     https://packages.debian.org/buster/libpsm2-2\n#     https://lists.debian.org/debian-hpc/2017/12/msg00015.html\nENV DEB_URL=\"http://snapshot.debian.org/archive/debian/20181126T030749Z/pool/main\"\nENV PSM2_VERSION=\"11.2.68-3\"\nRUN if [ \"$( dpkg --print-architecture ;)\" = \"amd64\" ] ; then wget -nv ${DEB_URL}/libp/libpsm2/libpsm2-2_${PSM2_VERSION}_amd64.deb ${DEB_URL}/libp/libpsm2/libpsm2-dev_${PSM2_VERSION}_amd64.deb ; fi\n#   As of 5/2/2019, this is not the newest libibverbs. However, it is the\n#   newest that doesn't crash on our test systems.\nENV IBVERBS_VERSION=\"20.0-1\"\nRUN for i in ibacm ibverbs-providers ibverbs-utils libibumad-dev libibumad3 libibverbs-dev libibverbs1 librdmacm-dev librdmacm1 rdma-core rdmacm-utils; do wget -nv ${DEB_URL}/r/rdma-core/${i}_${IBVERBS_VERSION}_$( dpkg --print-architecture ;).deb ; done\n#   Install the .debs we collected. UCX needs these.\nRUN dpkg --install *.deb\n#   UCX. There is stuff to build Debian packages, but it seems not too polished.\nENV UCX_VERSION=\"1.3.1\"\nRUN git clone --branch v${UCX_VERSION} --depth 1 https://github.com/openucx/ucx.git\nRUN cd ucx \\\n && ./autogen.sh \\\n && ./contrib/configure-release --prefix=/usr/local \\\n && make -j$( getconf _NPROCESSORS_ONLN ;) install\n#   OpenMPI.\n#\n#   Patch OpenMPI to disable UCX plugin on systems with Intel or Cray HSNs. UCX\n#   has inferior performance than PSM2/uGNI but higher priority.\nENV MPI_URL=\"https://www.open-mpi.org/software/ompi/v3.1/downloads\"\nENV MPI_VERSION=\"3.1.4\"\nRUN wget -nv ${MPI_URL}/openmpi-${MPI_VERSION}.tar.gz\nRUN tar xf openmpi-${MPI_VERSION}.tar.gz\nCOPY dont-init-ucx-on-intel-cray.patch ./openmpi-${MPI_VERSION}\nRUN cd openmpi-${MPI_VERSION} \\\n && git apply dont-init-ucx-on-intel-cray.patch\nRUN cd openmpi-${MPI_VERSION} \\\n && CFLAGS=-O3 CXXFLAGS=-O3 ./configure --prefix=/usr/local --sysconfdir=/mnt/0 --with-slurm --with-pmi --with-pmix --with-ucx --disable-pty-support --enable-mca-no-build=btl-openib,plm-slurm \\\n && make -j$( getconf _NPROCESSORS_ONLN ;) install\nRUN ldconfig\nRUN rm -Rf openmpi-${MPI_VERSION}*\n#   OpenMPI expects this program to exist, even if it's not used. Default is\n#   \"ssh : rsh\", but that's not installed.\nRUN echo 'plm_rsh_agent = false' >> /mnt/0/openmpi-mca-params.conf\nRUN groupadd --system docker-user ; useradd --system --gid docker-user docker-user\nUSER docker-user\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"#  ch-test-scope: full\nFROM debian9\n#  A key goal of this Dockerfile is to demonstrate best practices for building\n#  OpenMPI for use inside a container.\n#\n#  This OpenMPI aspires to work close to optimally on clusters with any of the\n#  following interconnects:\n#\n#     - Ethernet (TCP/IP)\n#     - InfiniBand (IB)\n#     - Omni-Path (OPA)\n#     - RDMA over Converged Ethernet (RoCE) interconnects\n#\n#  with no environment variables, command line arguments, or additional\n#  configuration files. Thus, we try to implement decisions at build time.\n#\n#  This is a work in progress, and we're very interested in feedback.\n#\n#  OpenMPI has numerous ways to communicate messages [1]. The ones relevant to\n#  this build and the interconnects they support are:\n#\n#    Module        Eth   IB    OPA   RoCE    note  decision\n#    ------------  ----  ----  ----  ----    ----  --------\n#\n#    ob1 : tcp      Y*    X     X     X      a     include\n#    ob1 : openib   N     Y     Y     Y      b,c   exclude\n#    cm  : psm2     N     N     Y*    N            include\n#        : ucx      Y?    Y*    N     Y?     b,d   include\n#\n#    Y : supported\n#    Y*: best choice for that interconnect\n#    X : supported but sub-optimal\n#\n#    a : No RDMA, so performance will suffer.\n#    b : Uses libibverbs.\n#    c : Will be removed in OpenMPI 4.\n#    d : Uses Mellanox libraries if available in preference to libibverbs.\n#\n#  You can check what's available with:\n#\n#    $ ch-run /var/tmp/openmpi -- ompi_info | egrep '(btl|mtl|pml)'\n#\n#  The other build decisions are:\n#\n#    1. PMI/PMIx: Include these so that we can use srun or any other PMI[x]\n#       provider, with no matching OpenMPI needed on the host.\n#\n#    2. --disable-pty-support to avoid \"pipe function call failed when\n#       setting up I/O forwarding subsystem\".\n#\n#    3. --enable-mca-no-build=plm-slurm to support launching processes using\n#       the host's srun (i.e., the container OpenMPI needs to talk to the host\n#       Slurm's PMI) but prevent OpenMPI from invoking srun itself from within\n#       the container, where srun is not installed (the error messages from\n#       this are inscrutable).\n#\n#  [1]: https://github.com/open-mpi/ompi/blob/master/README\n#  OS packages needed to build this stuff.\nRUN apt-get install autoconf file flex g++ gcc gfortran git hwloc-nox less libdb5.3-dev libhwloc-dev libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnuma1 libpmi2-0-dev make wget udev -y --no-install-suggests\nWORKDIR /usr/local/src\n#  Use the Buster versions of libpsm2 (not present in Stretch) and libibverbs\n#  (too old in Stretch). Download manually because I'm too lazy to set up\n#  package pinning.\n#\n#  Note that libpsm2 is x86-64 only:\n#    https://packages.debian.org/buster/libpsm2-2\n#    https://lists.debian.org/debian-hpc/2017/12/msg00015.html\nENV DEB_URL=\"http://snapshot.debian.org/archive/debian/20181126T030749Z/pool/main\"\nENV PSM2_VERSION=\"11.2.68-3\"\nRUN if [ \"$( dpkg --print-architecture ;)\" = \"amd64\" ] ; then wget -nv ${DEB_URL}/libp/libpsm2/libpsm2-2_${PSM2_VERSION}_amd64.deb ${DEB_URL}/libp/libpsm2/libpsm2-dev_${PSM2_VERSION}_amd64.deb ; fi\n#  As of 5/2/2019, this is not the newest libibverbs. However, it is the\n#  newest that doesn't crash on our test systems.\nENV IBVERBS_VERSION=\"20.0-1\"\nRUN for i in ibacm ibverbs-providers ibverbs-utils libibumad-dev libibumad3 libibverbs-dev libibverbs1 librdmacm-dev librdmacm1 rdma-core rdmacm-utils; do wget -nv ${DEB_URL}/r/rdma-core/${i}_${IBVERBS_VERSION}_$( dpkg --print-architecture ;).deb ; done\n#  Install the .debs we collected. UCX needs these.\nRUN dpkg --install *.deb\n#  UCX. There is stuff to build Debian packages, but it seems not too polished.\nENV UCX_VERSION=\"1.3.1\"\nRUN git clone --branch v${UCX_VERSION} --depth 1 https://github.com/openucx/ucx.git\nRUN cd ucx \\\n && ./autogen.sh \\\n && ./contrib/configure-release --prefix=/usr/local \\\n && make -j$( getconf _NPROCESSORS_ONLN ;) install\n#  OpenMPI.\n#\n#  Patch OpenMPI to disable UCX plugin on systems with Intel or Cray HSNs. UCX\n#  has inferior performance than PSM2/uGNI but higher priority.\nENV MPI_URL=\"https://www.open-mpi.org/software/ompi/v3.1/downloads\"\nENV MPI_VERSION=\"3.1.4\"\nRUN wget -nv ${MPI_URL}/openmpi-${MPI_VERSION}.tar.gz\nRUN tar xf openmpi-${MPI_VERSION}.tar.gz\nCOPY dont-init-ucx-on-intel-cray.patch ./openmpi-${MPI_VERSION}\nRUN cd openmpi-${MPI_VERSION} \\\n && git apply dont-init-ucx-on-intel-cray.patch\nRUN cd openmpi-${MPI_VERSION} \\\n && CFLAGS=-O3 CXXFLAGS=-O3 ./configure --prefix=/usr/local --sysconfdir=/mnt/0 --with-slurm --with-pmi --with-pmix --with-ucx --disable-pty-support --enable-mca-no-build=btl-openib,plm-slurm \\\n && make -j$( getconf _NPROCESSORS_ONLN ;) install\nRUN ldconfig\nRUN rm -Rf openmpi-${MPI_VERSION}*\n#  OpenMPI expects this program to exist, even if it's not used. Default is\n#  \"ssh : rsh\", but that's not installed.\nRUN echo 'plm_rsh_agent = false' >> /mnt/0/openmpi-mca-params.conf\n","injectedSmells":[],"originalDockerfileHash":"dd1f841877c3d887f36cd15e20b708e7","successfullyInjectedSmells":[],"originalDockerfileUglified":"#   ch-test-scope: full\nFROM debian9\n#   A key goal of this Dockerfile is to demonstrate best practices for building\n#   OpenMPI for use inside a container.\n#\n#   This OpenMPI aspires to work close to optimally on clusters with any of the\n#   following interconnects:\n#\n#      - Ethernet (TCP/IP)\n#      - InfiniBand (IB)\n#      - Omni-Path (OPA)\n#      - RDMA over Converged Ethernet (RoCE) interconnects\n#\n#   with no environment variables, command line arguments, or additional\n#   configuration files. Thus, we try to implement decisions at build time.\n#\n#   This is a work in progress, and we're very interested in feedback.\n#\n#   OpenMPI has numerous ways to communicate messages [1]. The ones relevant to\n#   this build and the interconnects they support are:\n#\n#     Module        Eth   IB    OPA   RoCE    note  decision\n#     ------------  ----  ----  ----  ----    ----  --------\n#\n#     ob1 : tcp      Y*    X     X     X      a     include\n#     ob1 : openib   N     Y     Y     Y      b,c   exclude\n#     cm  : psm2     N     N     Y*    N            include\n#         : ucx      Y?    Y*    N     Y?     b,d   include\n#\n#     Y : supported\n#     Y*: best choice for that interconnect\n#     X : supported but sub-optimal\n#\n#     a : No RDMA, so performance will suffer.\n#     b : Uses libibverbs.\n#     c : Will be removed in OpenMPI 4.\n#     d : Uses Mellanox libraries if available in preference to libibverbs.\n#\n#   You can check what's available with:\n#\n#     $ ch-run /var/tmp/openmpi -- ompi_info | egrep '(btl|mtl|pml)'\n#\n#   The other build decisions are:\n#\n#     1. PMI/PMIx: Include these so that we can use srun or any other PMI[x]\n#        provider, with no matching OpenMPI needed on the host.\n#\n#     2. --disable-pty-support to avoid \"pipe function call failed when\n#        setting up I/O forwarding subsystem\".\n#\n#     3. --enable-mca-no-build=plm-slurm to support launching processes using\n#        the host's srun (i.e., the container OpenMPI needs to talk to the host\n#        Slurm's PMI) but prevent OpenMPI from invoking srun itself from within\n#        the container, where srun is not installed (the error messages from\n#        this are inscrutable).\n#\n#   [1]: https://github.com/open-mpi/ompi/blob/master/README\n#   OS packages needed to build this stuff.\nRUN apt-get install autoconf file flex g++ gcc gfortran git hwloc-nox less libdb5.3-dev libhwloc-dev libnl-3-200 libnl-route-3-200 libnl-route-3-dev libnuma1 libpmi2-0-dev make wget udev -y --no-install-suggests\nWORKDIR /usr/local/src\n#   Use the Buster versions of libpsm2 (not present in Stretch) and libibverbs\n#   (too old in Stretch). Download manually because I'm too lazy to set up\n#   package pinning.\n#\n#   Note that libpsm2 is x86-64 only:\n#     https://packages.debian.org/buster/libpsm2-2\n#     https://lists.debian.org/debian-hpc/2017/12/msg00015.html\nENV DEB_URL=\"http://snapshot.debian.org/archive/debian/20181126T030749Z/pool/main\"\nENV PSM2_VERSION=\"11.2.68-3\"\nRUN if [ \"$( dpkg --print-architecture ;)\" = \"amd64\" ] ; then wget -nv ${DEB_URL}/libp/libpsm2/libpsm2-2_${PSM2_VERSION}_amd64.deb ${DEB_URL}/libp/libpsm2/libpsm2-dev_${PSM2_VERSION}_amd64.deb ; fi\n#   As of 5/2/2019, this is not the newest libibverbs. However, it is the\n#   newest that doesn't crash on our test systems.\nENV IBVERBS_VERSION=\"20.0-1\"\nRUN for i in ibacm ibverbs-providers ibverbs-utils libibumad-dev libibumad3 libibverbs-dev libibverbs1 librdmacm-dev librdmacm1 rdma-core rdmacm-utils; do wget -nv ${DEB_URL}/r/rdma-core/${i}_${IBVERBS_VERSION}_$( dpkg --print-architecture ;).deb ; done\n#   Install the .debs we collected. UCX needs these.\nRUN dpkg --install *.deb\n#   UCX. There is stuff to build Debian packages, but it seems not too polished.\nENV UCX_VERSION=\"1.3.1\"\nRUN git clone --branch v${UCX_VERSION} --depth 1 https://github.com/openucx/ucx.git\nRUN cd ucx \\\n && ./autogen.sh \\\n && ./contrib/configure-release --prefix=/usr/local \\\n && make -j$( getconf _NPROCESSORS_ONLN ;) install\n#   OpenMPI.\n#\n#   Patch OpenMPI to disable UCX plugin on systems with Intel or Cray HSNs. UCX\n#   has inferior performance than PSM2/uGNI but higher priority.\nENV MPI_URL=\"https://www.open-mpi.org/software/ompi/v3.1/downloads\"\nENV MPI_VERSION=\"3.1.4\"\nRUN wget -nv ${MPI_URL}/openmpi-${MPI_VERSION}.tar.gz\nRUN tar xf openmpi-${MPI_VERSION}.tar.gz\nCOPY dont-init-ucx-on-intel-cray.patch ./openmpi-${MPI_VERSION}\nRUN cd openmpi-${MPI_VERSION} \\\n && git apply dont-init-ucx-on-intel-cray.patch\nRUN cd openmpi-${MPI_VERSION} \\\n && CFLAGS=-O3 CXXFLAGS=-O3 ./configure --prefix=/usr/local --sysconfdir=/mnt/0 --with-slurm --with-pmi --with-pmix --with-ucx --disable-pty-support --enable-mca-no-build=btl-openib,plm-slurm \\\n && make -j$( getconf _NPROCESSORS_ONLN ;) install\nRUN ldconfig\nRUN rm -Rf openmpi-${MPI_VERSION}*\n#   OpenMPI expects this program to exist, even if it's not used. Default is\n#   \"ssh : rsh\", but that's not installed.\nRUN echo 'plm_rsh_agent = false' >> /mnt/0/openmpi-mca-params.conf\n","originalDockerfileUglifiedHash":"8d116257c0a28e1481b09197379c9d45","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/5c1103c389426f1f7ed41e0745ab337ef7de27ae.dockerfile"}