{"seed":2968376594,"processedDockerfileHash":"8c1f497e65c07759cc7e3a3e9b8b394d","fixedSmells":["use-no-install-recommends","do-not-use-apt-get-update-alone","pin-package-manager-versions-apt-get","pin-package-manager-versions-pip","pin-package-manager-versions-npm","pin-package-manager-versions-gem","pin-package-manager-versions-apk","use-copy-instead-of-add","use-wget-instead-of-add","do-not-have-secrets","have-a-healthcheck","have-a-user"],"successfullyFixedSmells":["pin-package-manager-versions-apt-get","use-copy-instead-of-add","have-a-healthcheck"],"processedDockerfile":"#   adapted from https://hub.docker.com/r/jupyter/base-notebook/ AKA https://github.com/jupyter/docker-stacks/tree/master/base-notebook\nFROM debian:stretch\nUSER root\n#  ######################\n#   Prerequisites\n#  ######################\nENV DEBIAN_FRONTEND=\"noninteractive\"\nENV DEBIAN_REPO=\"http://cdn-fastly.deb.debian.org\"\nENV CRAN_REPO=\"http://cran.mtu.edu\"\nRUN echo \"deb $DEBIAN_REPO/debian stretch main\" > /etc/apt/sources.list \\\n && echo \"deb $DEBIAN_REPO/debian-security stretch/updates main\" >> /etc/apt/sources.list \\\n && echo \"deb $DEBIAN_REPO/debian stretch-backports main\" >> /etc/apt/sources.list \\\n && echo \"deb $DEBIAN_REPO/debian testing main\" >> /etc/apt/sources.list \\\n && echo 'APT::Default-Release \"stable\";' | tee -a /etc/apt/apt.conf.d/00local \\\n && apt-get update \\\n && apt-get -yq dist-upgrade \\\n && apt-get install --no-install-recommends unzip=6.0-21+deb9u2 nano=2.7.4-1 sudo=1.8.19p1-2.1+deb9u3 default-jre=2:1.8-58+deb9u1 default-jdk=2:1.8-58+deb9u1 gnupg=2.1.18-8~deb9u4 dirmngr=2.1.18-8~deb9u4 wget=1.18-5+deb9u3 ca-certificates=20200601~deb9u2 curl=7.52.1-5+deb9u16 build-essential=12.3 lsb-release=9.20161125 procps=2:3.3.12-3+deb9u1 openssl=1.1.0l-1~deb9u6 make=4.1-9.1 aptitude=0.8.7-1 libssl-dev=1.1.0l-1~deb9u6 zlib1g-dev=1:1.2.8.dfsg-5+deb9u1 libbz2-dev=1.0.6-8.1 libreadline-dev=7.0-3 libsqlite3-dev=3.16.2-5+deb9u3 llvm=1:3.8-36 libncurses5-dev=6.0+20161126-1+deb9u2 libncursesw5-dev=6.0+20161126-1+deb9u2 xz-utils=5.2.2-1.2+deb9u1 tk-dev=8.6.0+9 samtools=1.3.1-3 git=1:2.11.0-3+deb9u7 locales=2.24-11+deb9u4 jq=1.5+dfsg-1.3 -yq \\\n && echo \"deb $CRAN_REPO/bin/linux/debian stretch-cran35/\" >> /etc/apt/sources.list \\\n && apt-key adv --no-tty --keyserver keyserver.ubuntu.com --recv-key 'E19F5F87128899B192B1A2C2AD5F960A256A04AF' \\\n && sed -i 's/^# *\\(en_US.UTF-8\\)/\\1/' /etc/locale.gen \\\n && locale-gen \\\n && export CLOUD_SDK_REPO=\"cloud-sdk-$( lsb_release -c -s ;)\" \\\n && echo \"deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main\" > /etc/apt/sources.list.d/google-cloud-sdk.list \\\n && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - \\\n && apt-get update \\\n && apt-get install --no-install-recommends google-cloud-sdk -yq \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\nENV LC_ALL=\"en_US.UTF-8\"\n#  ######################\n#   GATK\n#  ######################\nRUN set -e\nENV GATK_VERSION=\"4.1.0.0\"\nENV GATK_ZIP_PATH=\"/tmp/gatk-${GATK_VERSION}.zip\"\n#  download the gatk zip\nRUN curl -L -o $GATK_ZIP_PATH https://github.com/broadinstitute/gatk/releases/download/$GATK_VERSION/gatk-$GATK_VERSION.zip \\\n && unzip -o $GATK_ZIP_PATH -d /etc/ \\\n && ln -s /etc/gatk-$GATK_VERSION/gatk /bin/gatk\n#  #############################\n#   Spark / Hadoop / Hive / Hail\n#  #############################\n#   Use Spark 2.2.0 which corresponds to Dataproc 1.2. See:\n#     https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions\n#   Note: we are actually using Spark 2.2.1, but the Hail package is built using 2.2.0\nENV SPARK_VER=\"2.2.0\"\nENV SPARK_HOME=\"/usr/lib/spark\"\n#   result of `gsutil cat gs://hail-common/builds/0.2/latest-hash/cloudtools-3-spark-2.2.0.txt` on 26 March 2019\nENV HAILHASH=\"daed180b84d8\"\nENV HAILJAR=\"hail-0.2-$HAILHASH-Spark-$SPARK_VER.jar\"\nENV HAILPYTHON=\"hail-0.2-$HAILHASH.zip\"\nENV HAIL_HOME=\"/etc/hail\"\nENV KERNELSPEC_HOME=\"/usr/local/share/jupyter/kernels\"\n#   Note Spark and Hadoop are mounted from the outside Dataproc VM.\n#   Make empty conf dirs for the update-alternatives commands.\nRUN mkdir -p /etc/spark/conf.dist \\\n && mkdir -p /etc/hadoop/conf.empty \\\n && mkdir -p /etc/hive/conf.dist \\\n && update-alternatives --install /etc/spark/conf spark-conf /etc/spark/conf.dist 100 \\\n && update-alternatives --install /etc/hadoop/conf hadoop-conf /etc/hadoop/conf.empty 100 \\\n && update-alternatives --install /etc/hive/conf hive-conf /etc/hive/conf.dist 100 \\\n && mkdir $HAIL_HOME \\\n && cd $HAIL_HOME \\\n && wget -nv http://storage.googleapis.com/hail-common/builds/0.2/jars/$HAILJAR \\\n && wget -nv http://storage.googleapis.com/hail-common/builds/0.2/python/$HAILPYTHON \\\n && cd -\n#  ######################\n#   Python / Jupyter\n#  ######################\nENV USER=\"jupyter-user\"\nENV UID=\"1000\"\nENV HOME=\"/home/$USER\"\n#   ensure this matches c.NotebookApp.port in jupyter_notebook_config.py\nENV JUPYTER_PORT=\"8000\"\nENV JUPYTER_HOME=\"/etc/jupyter\"\nENV PYSPARK_DRIVER_PYTHON=\"jupyter\"\nENV PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\"\nENV PATH=\"$SPARK_HOME:$SPARK_HOME/python:$SPARK_HOME/bin:$HAIL_HOME:$PATH\"\nENV PYTHONPATH=\"$PYTHONPATH:$HAIL_HOME/$HAILPYTHON:$HAIL_HOME/python:$SPARK_HOME/python:$JUPYTER_HOME/custom\"\nRUN apt-get update \\\n && apt-get install --no-install-recommends python=2.7.13-2 python-dev=2.7.13-2 liblzo2-dev=2.08-1.2+b2 python-tk=2.7.13-1 liblzo2-dev=2.08-1.2+b2 libz-dev -yq \\\n && useradd -m -s /bin/bash -N -u $UID $USER \\\n && wget -nv https://bootstrap.pypa.io/get-pip.py \\\n && python get-pip.py \\\n && pip install ipykernel==4.10.0 \\\n && python2 -m ipykernel install --name python2 --display-name \"Python 2\" \\\n && pip install decorator==4.3.0 -U \\\n && pip install numpy==1.15.2 \\\n && pip install py4j==0.10.7 \\\n && python -mpip install matplotlib==2.2.3 \\\n && pip install pandas==0.23.4 \\\n && pip install seaborn==0.9.0 \\\n && pip install google-api-core==1.5.0 \\\n && pip install google-cloud-bigquery==1.7.0 \\\n && pip install google-cloud-bigquery-datatransfer==0.1.1 \\\n && pip install google-cloud-core==0.28.1 \\\n && pip install google-cloud-datastore==1.7.0 \\\n && pip install google-cloud-resource-manager==0.28.1 \\\n && pip install google-cloud-storage==1.13.0 \\\n && pip install google-auth==1.5.1 \\\n && pip install firecloud==0.16.18 --ignore-installed \\\n && pip install scikit-learn==0.20.0 -U \\\n && pip install statsmodels==0.9.0 \\\n && pip install ggplot==0.11.5 \\\n && sed -i 's/pandas.lib/pandas/g' /usr/local/lib/python2.7/dist-packages/ggplot/stats/smoothers.py \\\n && pip install bokeh==1.0.0 \\\n && pip install pyfasta==0.5.2 \\\n && pip install pdoc==0.3.2 \\\n && pip install biopython==1.72 \\\n && pip install bx-python==0.8.2 \\\n && pip install fastinterval==0.1.1 \\\n && pip install matplotlib-venn==0.11.5 \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   Python 3 Kernel\nENV PYTHON_VERSION=\"3.6.8\"\n#   lifted from https://github.com/docker-library/python/blob/dd36c08c1f94083476a8579b8bf20c4cd46c6400/3.6/stretch/Dockerfile\nRUN set -ex \\\n && wget -O python.tar.xz \"https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz\" \\\n && wget -O python.tar.xz.asc \"https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz.asc\" \\\n && export GNUPGHOME=\"$( mktemp -d ;)\" \\\n && gpg --batch --keyserver keyserver.ubuntu.com --recv-keys \"0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D\" \\\n && gpg --batch --verify python.tar.xz.asc python.tar.xz \\\n && { command -v gpgconf > /dev/null \\\n && gpgconf --kill all || : ; } \\\n && rm -rf \"$GNUPGHOME\" python.tar.xz.asc \\\n && mkdir -p /usr/src/python \\\n && tar -xJC /usr/src/python --strip-components=1 -f python.tar.xz \\\n && rm python.tar.xz \\\n && cd /usr/src/python \\\n && gnuArch=\"$( dpkg-architecture --query DEB_BUILD_GNU_TYPE ;)\" \\\n && ./configure --build=\"$gnuArch\" --enable-loadable-sqlite-extensions --enable-shared --with-system-expat --with-system-ffi --without-ensurepip \\\n && make -j \"$( nproc ;)\" \\\n && make install \\\n && ldconfig \\\n && find /usr/local -depth\n#   make some useful symlinks that are expected to exist\nRUN cd /usr/local/bin \\\n && ln -s idle3 idle \\\n && ln -s pydoc3 pydoc \\\n && ln -s python3 python \\\n && ln -s python3-config python-config\n#   if this is called \"PIP_VERSION\", pip explodes with \"ValueError: invalid truth value '<VERSION>'\"\nENV PYTHON_PIP_VERSION=\"19.0.1\"\nRUN set -ex ; wget -O get-pip.py 'https://bootstrap.pypa.io/get-pip.py' ; python get-pip.py --disable-pip-version-check --no-cache-dir \"pip==$PYTHON_PIP_VERSION\" ; pip --version ; find /usr/local -depth\nRUN apt-get update \\\n && apt-get install --no-install-recommends testing nodejs=4.8.2~dfsg-1 npm -t -yq \\\n && pip3 install tornado==4.5.3 \\\n && pip3 install -U decorator==4.3.0 \\\n && pip3 install parsimonious==0.8.1 \\\n && pip3 install numpy==1.15.2 \\\n && pip3 install py4j==0.10.7 \\\n && python3 -mpip install matplotlib==3.0.0 \\\n && pip3 install pandas==0.23.4 \\\n && pip3 install seaborn==0.9.0 \\\n && pip3 install jupyter==1.0.0 \\\n && pip3 install jupyterlab==0.35.4 \\\n && pip3 install python-lzo==1.12 \\\n && pip3 install google-api-core==1.5.0 \\\n && pip3 install google-cloud-bigquery==1.7.0 \\\n && pip3 install google-cloud-bigquery-datatransfer==0.1.1 \\\n && pip3 install google-cloud-core==0.28.1 \\\n && pip3 install google-cloud-datastore==1.7.0 \\\n && pip3 install google-cloud-resource-manager==0.28.1 \\\n && pip3 install google-cloud-storage==1.13.0 \\\n && pip3 install --ignore-installed firecloud==0.16.18 \\\n && pip3 install scikit-learn==0.20.0 \\\n && pip3 install statsmodels==0.9.0 \\\n && pip3 install ggplot==0.11.5 \\\n && sed -i 's/pandas.lib/pandas/g' /usr/local/lib/python3.6/site-packages/ggplot/stats/smoothers.py \\\n && pip3 install bokeh==1.0.0 \\\n && pip3 install pyfasta==0.5.2 \\\n && pip3 install pdoc==0.3.2 \\\n && pip3 install biopython==1.72 \\\n && pip3 install bx-python==0.8.2 \\\n && pip3 install fastinterval==0.1.1 \\\n && pip3 install matplotlib-venn==0.11.5 \\\n && pip3 install bleach==1.5.0 \\\n && pip3 install cycler==0.10.0 \\\n && pip3 install enum34==1.1.6 \\\n && pip3 install h5py==2.7.1 \\\n && pip3 install html5lib==0.9999999 \\\n && pip3 install joblib==0.11 \\\n && pip3 install keras==2.2.0 \\\n && pip3 install markdown==2.6.9 \\\n && pip3 install patsy==0.4.1 \\\n && pip3 install protobuf==3.7.1 \\\n && pip3 install pymc3==3.1 \\\n && pip3 install pyparsing==2.2.0 \\\n && pip3 install pysam==0.13 \\\n && pip3 install python-dateutil==2.6.1 \\\n && pip3 install pytz==2017.3 \\\n && pip3 install pyvcf==0.6.8 \\\n && pip3 install pyyaml==3.12 \\\n && pip3 install scipy==1.0.0 \\\n && pip3 install six==1.11.0 \\\n && pip3 install tensorflow==1.9.0 \\\n && pip3 install theano==0.9.0 \\\n && pip3 install tqdm==4.19.4 \\\n && pip3 install werkzeug==0.12.2 \\\n && pip3 install certifi==2016.2.28 \\\n && pip3 install intel-openmp==2018.0.0 \\\n && pip3 install mkl==2018.0.3 \\\n && pip3 install readline==6.2 \\\n && pip3 install setuptools==36.4.0 \\\n && pip3 install wheel \\\n && pip3 install python-datauri \\\n && pip3 install jupyter_contrib_nbextensions \\\n && pip3 install jupyter_nbextensions_configurator \\\n && pip3 install /etc/gatk-$GATK_VERSION/gatkPythonPackageArchive.zip \\\n && pip3 install cookiecutter \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   make pip install to a user directory, instead of a system directory which requires root.\n#   this is useful so `pip install` commands can be run in the context of a notebook.\nENV PIP_USER=\"true\"\n#  ######################\n#   R Kernel\n#  ######################\n#   using aptitude for R packages so that all dependencies are automatically installed\nRUN aptitude update \\\n && aptitude install -y apt-utils \\\n && aptitude update \\\n && aptitude -t stretch-cran35 install -y r-base=3.5.2-1 r-base-dev=3.5.2-1 r-base-core=3.5.2-1 r-recommended=3.5.2-1 \\\n && aptitude install -t stretch-cran35 -y fonts-dejavu tzdata gfortran gcc libcurl4 libcurl4-openssl-dev libssl-dev libxml2-dev \\\n && aptitude clean \\\n && rm -rf /var/lib/apt/lists/* \\\n && ln -s /usr/lib/x86_64-linux-gnu/libgfortran.so.3 /usr/lib/x86_64-linux-gnu/libgfortran.so\nRUN R -e 'install.packages(c( \"IRdisplay\", \"evaluate\", \"pbdZMQ\", \"devtools\", \"uuid\", \"reshape2\", \"bigrquery\", \"googleCloudStorageR\", \"tidyverse\"), repos=\"http://cran.mtu.edu\")' \\\n && R -e 'devtools::install_github(\"DataBiosphere/Ronaldo\")' \\\n && R -e 'devtools::install_github(\"IRkernel/IRkernel\")' \\\n && R -e 'IRkernel::installspec(user=FALSE)' \\\n && chown -R $USER:users /home/jupyter-user/.local \\\n && R -e 'devtools::install_github(\"apache/spark@v2.2.3\", subdir=\"R/pkg\")' \\\n && mkdir -p /home/jupyter-user/.rpackages \\\n && echo \"R_LIBS=/home/jupyter-user/.rpackages\" > /home/jupyter-user/.Renviron \\\n && chown -R $USER:users /home/jupyter-user/.rpackages\n#  ######################\n#   Utilities\n#  ######################\nCOPY scripts $JUPYTER_HOME/scripts\nCOPY custom/jupyter_delocalize.py $JUPYTER_HOME/custom/\nCOPY custom/jupyter_localize_extension.py $JUPYTER_HOME/custom/\nRUN chown -R $USER:users $JUPYTER_HOME \\\n && find $JUPYTER_HOME/scripts -name '*.sh' -type f | xargs chmod +x \\\n && chown -R $USER:users /usr/local/share/jupyter/lab \\\n && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-6 200 \\\n && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 100\nUSER $USER\nWORKDIR $HOME\nEXPOSE $JUPYTER_PORT\n#   Note: this entrypoint is provided for running Jupyter independently of Leonardo.\n#   When Leonardo deploys this image onto a cluster, the entrypoint is overwritten to enable\n#   additional setup inside the container before execution.  Jupyter execution occurs when the\n#   init-actions.sh script uses 'docker exec' to call run-jupyter.sh.\nENTRYPOINT [\"/usr/local/bin/jupyter\", \"notebook\"]\n# Please add your HEALTHCHECK here!!!\n","originalDockerfile":"#  adapted from https://hub.docker.com/r/jupyter/base-notebook/ AKA https://github.com/jupyter/docker-stacks/tree/master/base-notebook\nFROM debian:stretch\nUSER root\n# ######################\n#  Prerequisites\n# ######################\nENV DEBIAN_FRONTEND=\"noninteractive\"\nENV DEBIAN_REPO=\"http://cdn-fastly.deb.debian.org\"\nENV CRAN_REPO=\"http://cran.mtu.edu\"\nRUN echo \"deb $DEBIAN_REPO/debian stretch main\" > /etc/apt/sources.list \\\n && echo \"deb $DEBIAN_REPO/debian-security stretch/updates main\" >> /etc/apt/sources.list \\\n && echo \"deb $DEBIAN_REPO/debian stretch-backports main\" >> /etc/apt/sources.list \\\n && echo \"deb $DEBIAN_REPO/debian testing main\" >> /etc/apt/sources.list \\\n && echo 'APT::Default-Release \"stable\";' | tee -a /etc/apt/apt.conf.d/00local \\\n && apt-get update \\\n && apt-get -yq dist-upgrade \\\n && apt-get install --no-install-recommends unzip nano sudo default-jre default-jdk gnupg dirmngr wget ca-certificates curl build-essential lsb-release procps openssl make aptitude libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev samtools git locales jq -yq \\\n && echo \"deb $CRAN_REPO/bin/linux/debian stretch-cran35/\" >> /etc/apt/sources.list \\\n && apt-key adv --no-tty --keyserver keyserver.ubuntu.com --recv-key 'E19F5F87128899B192B1A2C2AD5F960A256A04AF' \\\n && sed -i 's/^# *\\(en_US.UTF-8\\)/\\1/' /etc/locale.gen \\\n && locale-gen \\\n && export CLOUD_SDK_REPO=\"cloud-sdk-$( lsb_release -c -s ;)\" \\\n && echo \"deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main\" > /etc/apt/sources.list.d/google-cloud-sdk.list \\\n && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - \\\n && apt-get update \\\n && apt-get install --no-install-recommends google-cloud-sdk -yq \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\nENV LC_ALL=\"en_US.UTF-8\"\n# ######################\n#  GATK\n# ######################\nRUN set -e\nENV GATK_VERSION=\"4.1.0.0\"\nENV GATK_ZIP_PATH=\"/tmp/gatk-${GATK_VERSION}.zip\"\n# download the gatk zip\nRUN curl -L -o $GATK_ZIP_PATH https://github.com/broadinstitute/gatk/releases/download/$GATK_VERSION/gatk-$GATK_VERSION.zip \\\n && unzip -o $GATK_ZIP_PATH -d /etc/ \\\n && ln -s /etc/gatk-$GATK_VERSION/gatk /bin/gatk\n# #############################\n#  Spark / Hadoop / Hive / Hail\n# #############################\n#  Use Spark 2.2.0 which corresponds to Dataproc 1.2. See:\n#    https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions\n#  Note: we are actually using Spark 2.2.1, but the Hail package is built using 2.2.0\nENV SPARK_VER=\"2.2.0\"\nENV SPARK_HOME=\"/usr/lib/spark\"\n#  result of `gsutil cat gs://hail-common/builds/0.2/latest-hash/cloudtools-3-spark-2.2.0.txt` on 26 March 2019\nENV HAILHASH=\"daed180b84d8\"\nENV HAILJAR=\"hail-0.2-$HAILHASH-Spark-$SPARK_VER.jar\"\nENV HAILPYTHON=\"hail-0.2-$HAILHASH.zip\"\nENV HAIL_HOME=\"/etc/hail\"\nENV KERNELSPEC_HOME=\"/usr/local/share/jupyter/kernels\"\n#  Note Spark and Hadoop are mounted from the outside Dataproc VM.\n#  Make empty conf dirs for the update-alternatives commands.\nRUN mkdir -p /etc/spark/conf.dist \\\n && mkdir -p /etc/hadoop/conf.empty \\\n && mkdir -p /etc/hive/conf.dist \\\n && update-alternatives --install /etc/spark/conf spark-conf /etc/spark/conf.dist 100 \\\n && update-alternatives --install /etc/hadoop/conf hadoop-conf /etc/hadoop/conf.empty 100 \\\n && update-alternatives --install /etc/hive/conf hive-conf /etc/hive/conf.dist 100 \\\n && mkdir $HAIL_HOME \\\n && cd $HAIL_HOME \\\n && wget -nv http://storage.googleapis.com/hail-common/builds/0.2/jars/$HAILJAR \\\n && wget -nv http://storage.googleapis.com/hail-common/builds/0.2/python/$HAILPYTHON \\\n && cd -\n# ######################\n#  Python / Jupyter\n# ######################\nENV USER=\"jupyter-user\"\nENV UID=\"1000\"\nENV HOME=\"/home/$USER\"\n#  ensure this matches c.NotebookApp.port in jupyter_notebook_config.py\nENV JUPYTER_PORT=\"8000\"\nENV JUPYTER_HOME=\"/etc/jupyter\"\nENV PYSPARK_DRIVER_PYTHON=\"jupyter\"\nENV PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\"\nENV PATH=\"$SPARK_HOME:$SPARK_HOME/python:$SPARK_HOME/bin:$HAIL_HOME:$PATH\"\nENV PYTHONPATH=\"$PYTHONPATH:$HAIL_HOME/$HAILPYTHON:$HAIL_HOME/python:$SPARK_HOME/python:$JUPYTER_HOME/custom\"\nRUN apt-get update \\\n && apt-get install --no-install-recommends python python-dev liblzo2-dev python-tk liblzo2-dev libz-dev -yq \\\n && useradd -m -s /bin/bash -N -u $UID $USER \\\n && wget -nv https://bootstrap.pypa.io/get-pip.py \\\n && python get-pip.py \\\n && pip install ipykernel==4.10.0 \\\n && python2 -m ipykernel install --name python2 --display-name \"Python 2\" \\\n && pip install decorator==4.3.0 -U \\\n && pip install numpy==1.15.2 \\\n && pip install py4j==0.10.7 \\\n && python -mpip install matplotlib==2.2.3 \\\n && pip install pandas==0.23.4 \\\n && pip install seaborn==0.9.0 \\\n && pip install google-api-core==1.5.0 \\\n && pip install google-cloud-bigquery==1.7.0 \\\n && pip install google-cloud-bigquery-datatransfer==0.1.1 \\\n && pip install google-cloud-core==0.28.1 \\\n && pip install google-cloud-datastore==1.7.0 \\\n && pip install google-cloud-resource-manager==0.28.1 \\\n && pip install google-cloud-storage==1.13.0 \\\n && pip install google-auth==1.5.1 \\\n && pip install firecloud==0.16.18 --ignore-installed \\\n && pip install scikit-learn==0.20.0 -U \\\n && pip install statsmodels==0.9.0 \\\n && pip install ggplot==0.11.5 \\\n && sed -i 's/pandas.lib/pandas/g' /usr/local/lib/python2.7/dist-packages/ggplot/stats/smoothers.py \\\n && pip install bokeh==1.0.0 \\\n && pip install pyfasta==0.5.2 \\\n && pip install pdoc==0.3.2 \\\n && pip install biopython==1.72 \\\n && pip install bx-python==0.8.2 \\\n && pip install fastinterval==0.1.1 \\\n && pip install matplotlib-venn==0.11.5 \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#  Python 3 Kernel\nENV PYTHON_VERSION=\"3.6.8\"\n#  lifted from https://github.com/docker-library/python/blob/dd36c08c1f94083476a8579b8bf20c4cd46c6400/3.6/stretch/Dockerfile\nRUN set -ex \\\n && wget -O python.tar.xz \"https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz\" \\\n && wget -O python.tar.xz.asc \"https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz.asc\" \\\n && export GNUPGHOME=\"$( mktemp -d ;)\" \\\n && gpg --batch --keyserver keyserver.ubuntu.com --recv-keys \"0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D\" \\\n && gpg --batch --verify python.tar.xz.asc python.tar.xz \\\n && { command -v gpgconf > /dev/null \\\n && gpgconf --kill all || : ; } \\\n && rm -rf \"$GNUPGHOME\" python.tar.xz.asc \\\n && mkdir -p /usr/src/python \\\n && tar -xJC /usr/src/python --strip-components=1 -f python.tar.xz \\\n && rm python.tar.xz \\\n && cd /usr/src/python \\\n && gnuArch=\"$( dpkg-architecture --query DEB_BUILD_GNU_TYPE ;)\" \\\n && ./configure --build=\"$gnuArch\" --enable-loadable-sqlite-extensions --enable-shared --with-system-expat --with-system-ffi --without-ensurepip \\\n && make -j \"$( nproc ;)\" \\\n && make install \\\n && ldconfig \\\n && find /usr/local -depth ( ( -type d -a ( -name test -o -name tests ) ) -o ( -type f -a ( -name '*.pyc' -o -name '*.pyo' ) ) ) -exec rm -rf '{}' + \\\n && rm -rf /usr/src/python \\\n && python3 --version\n#  make some useful symlinks that are expected to exist\nRUN cd /usr/local/bin \\\n && ln -s idle3 idle \\\n && ln -s pydoc3 pydoc \\\n && ln -s python3 python \\\n && ln -s python3-config python-config\n#  if this is called \"PIP_VERSION\", pip explodes with \"ValueError: invalid truth value '<VERSION>'\"\nENV PYTHON_PIP_VERSION=\"19.0.1\"\nRUN set -ex ; wget -O get-pip.py 'https://bootstrap.pypa.io/get-pip.py' ; python get-pip.py --disable-pip-version-check --no-cache-dir \"pip==$PYTHON_PIP_VERSION\" ; pip --version ; find /usr/local -depth ( ( -type d -a ( -name test -o -name tests ) ) -o ( -type f -a ( -name '*.pyc' -o -name '*.pyo' ) ) ) -exec rm -rf '{}' + ; rm -f get-pip.py\nRUN apt-get update \\\n && apt-get install --no-install-recommends testing nodejs npm -t -yq \\\n && pip3 install tornado==4.5.3 \\\n && pip3 install -U decorator==4.3.0 \\\n && pip3 install parsimonious==0.8.1 \\\n && pip3 install numpy==1.15.2 \\\n && pip3 install py4j==0.10.7 \\\n && python3 -mpip install matplotlib==3.0.0 \\\n && pip3 install pandas==0.23.4 \\\n && pip3 install seaborn==0.9.0 \\\n && pip3 install jupyter==1.0.0 \\\n && pip3 install jupyterlab==0.35.4 \\\n && pip3 install python-lzo==1.12 \\\n && pip3 install google-api-core==1.5.0 \\\n && pip3 install google-cloud-bigquery==1.7.0 \\\n && pip3 install google-cloud-bigquery-datatransfer==0.1.1 \\\n && pip3 install google-cloud-core==0.28.1 \\\n && pip3 install google-cloud-datastore==1.7.0 \\\n && pip3 install google-cloud-resource-manager==0.28.1 \\\n && pip3 install google-cloud-storage==1.13.0 \\\n && pip3 install --ignore-installed firecloud==0.16.18 \\\n && pip3 install scikit-learn==0.20.0 \\\n && pip3 install statsmodels==0.9.0 \\\n && pip3 install ggplot==0.11.5 \\\n && sed -i 's/pandas.lib/pandas/g' /usr/local/lib/python3.6/site-packages/ggplot/stats/smoothers.py \\\n && pip3 install bokeh==1.0.0 \\\n && pip3 install pyfasta==0.5.2 \\\n && pip3 install pdoc==0.3.2 \\\n && pip3 install biopython==1.72 \\\n && pip3 install bx-python==0.8.2 \\\n && pip3 install fastinterval==0.1.1 \\\n && pip3 install matplotlib-venn==0.11.5 \\\n && pip3 install bleach==1.5.0 \\\n && pip3 install cycler==0.10.0 \\\n && pip3 install enum34==1.1.6 \\\n && pip3 install h5py==2.7.1 \\\n && pip3 install html5lib==0.9999999 \\\n && pip3 install joblib==0.11 \\\n && pip3 install keras==2.2.0 \\\n && pip3 install markdown==2.6.9 \\\n && pip3 install patsy==0.4.1 \\\n && pip3 install protobuf==3.7.1 \\\n && pip3 install pymc3==3.1 \\\n && pip3 install pyparsing==2.2.0 \\\n && pip3 install pysam==0.13 \\\n && pip3 install python-dateutil==2.6.1 \\\n && pip3 install pytz==2017.3 \\\n && pip3 install pyvcf==0.6.8 \\\n && pip3 install pyyaml==3.12 \\\n && pip3 install scipy==1.0.0 \\\n && pip3 install six==1.11.0 \\\n && pip3 install tensorflow==1.9.0 \\\n && pip3 install theano==0.9.0 \\\n && pip3 install tqdm==4.19.4 \\\n && pip3 install werkzeug==0.12.2 \\\n && pip3 install certifi==2016.2.28 \\\n && pip3 install intel-openmp==2018.0.0 \\\n && pip3 install mkl==2018.0.3 \\\n && pip3 install readline==6.2 \\\n && pip3 install setuptools==36.4.0 \\\n && pip3 install wheel \\\n && pip3 install python-datauri \\\n && pip3 install jupyter_contrib_nbextensions \\\n && pip3 install jupyter_nbextensions_configurator \\\n && pip3 install /etc/gatk-$GATK_VERSION/gatkPythonPackageArchive.zip \\\n && pip3 install cookiecutter \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#  make pip install to a user directory, instead of a system directory which requires root.\n#  this is useful so `pip install` commands can be run in the context of a notebook.\nENV PIP_USER=\"true\"\n# ######################\n#  R Kernel\n# ######################\n#  using aptitude for R packages so that all dependencies are automatically installed\nRUN aptitude update \\\n && aptitude install -y apt-utils \\\n && aptitude update \\\n && aptitude -t stretch-cran35 install -y r-base=3.5.2-1 r-base-dev=3.5.2-1 r-base-core=3.5.2-1 r-recommended=3.5.2-1 \\\n && aptitude install -t stretch-cran35 -y fonts-dejavu tzdata gfortran gcc libcurl4 libcurl4-openssl-dev libssl-dev libxml2-dev \\\n && aptitude clean \\\n && rm -rf /var/lib/apt/lists/* \\\n && ln -s /usr/lib/x86_64-linux-gnu/libgfortran.so.3 /usr/lib/x86_64-linux-gnu/libgfortran.so\nRUN R -e 'install.packages(c( \"IRdisplay\", \"evaluate\", \"pbdZMQ\", \"devtools\", \"uuid\", \"reshape2\", \"bigrquery\", \"googleCloudStorageR\", \"tidyverse\"), repos=\"http://cran.mtu.edu\")' \\\n && R -e 'devtools::install_github(\"DataBiosphere/Ronaldo\")' \\\n && R -e 'devtools::install_github(\"IRkernel/IRkernel\")' \\\n && R -e 'IRkernel::installspec(user=FALSE)' \\\n && chown -R $USER:users /home/jupyter-user/.local \\\n && R -e 'devtools::install_github(\"apache/spark@v2.2.3\", subdir=\"R/pkg\")' \\\n && mkdir -p /home/jupyter-user/.rpackages \\\n && echo \"R_LIBS=/home/jupyter-user/.rpackages\" > /home/jupyter-user/.Renviron \\\n && chown -R $USER:users /home/jupyter-user/.rpackages\n# ######################\n#  Utilities\n# ######################\nADD scripts $JUPYTER_HOME/scripts\nADD custom/jupyter_delocalize.py $JUPYTER_HOME/custom/\nADD custom/jupyter_localize_extension.py $JUPYTER_HOME/custom/\nRUN chown -R $USER:users $JUPYTER_HOME \\\n && find $JUPYTER_HOME/scripts -name '*.sh' -type f | xargs chmod +x \\\n && chown -R $USER:users /usr/local/share/jupyter/lab \\\n && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-6 200 \\\n && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 100\nUSER $USER\nWORKDIR $HOME\nEXPOSE $JUPYTER_PORT\n#  Note: this entrypoint is provided for running Jupyter independently of Leonardo.\n#  When Leonardo deploys this image onto a cluster, the entrypoint is overwritten to enable\n#  additional setup inside the container before execution.  Jupyter execution occurs when the\n#  init-actions.sh script uses 'docker exec' to call run-jupyter.sh.\nENTRYPOINT [\"/usr/local/bin/jupyter\", \"notebook\"]\n","injectedSmells":[],"originalDockerfileHash":"93b420101694d2c75a637a8eb0edd512","successfullyInjectedSmells":[],"originalDockerfileUglified":"#   adapted from https://hub.docker.com/r/jupyter/base-notebook/ AKA https://github.com/jupyter/docker-stacks/tree/master/base-notebook\nFROM debian:stretch\nUSER root\n#  ######################\n#   Prerequisites\n#  ######################\nENV DEBIAN_FRONTEND=\"noninteractive\"\nENV DEBIAN_REPO=\"http://cdn-fastly.deb.debian.org\"\nENV CRAN_REPO=\"http://cran.mtu.edu\"\nRUN echo \"deb $DEBIAN_REPO/debian stretch main\" > /etc/apt/sources.list \\\n && echo \"deb $DEBIAN_REPO/debian-security stretch/updates main\" >> /etc/apt/sources.list \\\n && echo \"deb $DEBIAN_REPO/debian stretch-backports main\" >> /etc/apt/sources.list \\\n && echo \"deb $DEBIAN_REPO/debian testing main\" >> /etc/apt/sources.list \\\n && echo 'APT::Default-Release \"stable\";' | tee -a /etc/apt/apt.conf.d/00local \\\n && apt-get update \\\n && apt-get -yq dist-upgrade \\\n && apt-get install --no-install-recommends unzip nano sudo default-jre default-jdk gnupg dirmngr wget ca-certificates curl build-essential lsb-release procps openssl make aptitude libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev llvm libncurses5-dev libncursesw5-dev xz-utils tk-dev samtools git locales jq -yq \\\n && echo \"deb $CRAN_REPO/bin/linux/debian stretch-cran35/\" >> /etc/apt/sources.list \\\n && apt-key adv --no-tty --keyserver keyserver.ubuntu.com --recv-key 'E19F5F87128899B192B1A2C2AD5F960A256A04AF' \\\n && sed -i 's/^# *\\(en_US.UTF-8\\)/\\1/' /etc/locale.gen \\\n && locale-gen \\\n && export CLOUD_SDK_REPO=\"cloud-sdk-$( lsb_release -c -s ;)\" \\\n && echo \"deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main\" > /etc/apt/sources.list.d/google-cloud-sdk.list \\\n && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - \\\n && apt-get update \\\n && apt-get install --no-install-recommends google-cloud-sdk -yq \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\nENV LC_ALL=\"en_US.UTF-8\"\n#  ######################\n#   GATK\n#  ######################\nRUN set -e\nENV GATK_VERSION=\"4.1.0.0\"\nENV GATK_ZIP_PATH=\"/tmp/gatk-${GATK_VERSION}.zip\"\n#  download the gatk zip\nRUN curl -L -o $GATK_ZIP_PATH https://github.com/broadinstitute/gatk/releases/download/$GATK_VERSION/gatk-$GATK_VERSION.zip \\\n && unzip -o $GATK_ZIP_PATH -d /etc/ \\\n && ln -s /etc/gatk-$GATK_VERSION/gatk /bin/gatk\n#  #############################\n#   Spark / Hadoop / Hive / Hail\n#  #############################\n#   Use Spark 2.2.0 which corresponds to Dataproc 1.2. See:\n#     https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-versions\n#   Note: we are actually using Spark 2.2.1, but the Hail package is built using 2.2.0\nENV SPARK_VER=\"2.2.0\"\nENV SPARK_HOME=\"/usr/lib/spark\"\n#   result of `gsutil cat gs://hail-common/builds/0.2/latest-hash/cloudtools-3-spark-2.2.0.txt` on 26 March 2019\nENV HAILHASH=\"daed180b84d8\"\nENV HAILJAR=\"hail-0.2-$HAILHASH-Spark-$SPARK_VER.jar\"\nENV HAILPYTHON=\"hail-0.2-$HAILHASH.zip\"\nENV HAIL_HOME=\"/etc/hail\"\nENV KERNELSPEC_HOME=\"/usr/local/share/jupyter/kernels\"\n#   Note Spark and Hadoop are mounted from the outside Dataproc VM.\n#   Make empty conf dirs for the update-alternatives commands.\nRUN mkdir -p /etc/spark/conf.dist \\\n && mkdir -p /etc/hadoop/conf.empty \\\n && mkdir -p /etc/hive/conf.dist \\\n && update-alternatives --install /etc/spark/conf spark-conf /etc/spark/conf.dist 100 \\\n && update-alternatives --install /etc/hadoop/conf hadoop-conf /etc/hadoop/conf.empty 100 \\\n && update-alternatives --install /etc/hive/conf hive-conf /etc/hive/conf.dist 100 \\\n && mkdir $HAIL_HOME \\\n && cd $HAIL_HOME \\\n && wget -nv http://storage.googleapis.com/hail-common/builds/0.2/jars/$HAILJAR \\\n && wget -nv http://storage.googleapis.com/hail-common/builds/0.2/python/$HAILPYTHON \\\n && cd -\n#  ######################\n#   Python / Jupyter\n#  ######################\nENV USER=\"jupyter-user\"\nENV UID=\"1000\"\nENV HOME=\"/home/$USER\"\n#   ensure this matches c.NotebookApp.port in jupyter_notebook_config.py\nENV JUPYTER_PORT=\"8000\"\nENV JUPYTER_HOME=\"/etc/jupyter\"\nENV PYSPARK_DRIVER_PYTHON=\"jupyter\"\nENV PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\"\nENV PATH=\"$SPARK_HOME:$SPARK_HOME/python:$SPARK_HOME/bin:$HAIL_HOME:$PATH\"\nENV PYTHONPATH=\"$PYTHONPATH:$HAIL_HOME/$HAILPYTHON:$HAIL_HOME/python:$SPARK_HOME/python:$JUPYTER_HOME/custom\"\nRUN apt-get update \\\n && apt-get install --no-install-recommends python python-dev liblzo2-dev python-tk liblzo2-dev libz-dev -yq \\\n && useradd -m -s /bin/bash -N -u $UID $USER \\\n && wget -nv https://bootstrap.pypa.io/get-pip.py \\\n && python get-pip.py \\\n && pip install ipykernel==4.10.0 \\\n && python2 -m ipykernel install --name python2 --display-name \"Python 2\" \\\n && pip install decorator==4.3.0 -U \\\n && pip install numpy==1.15.2 \\\n && pip install py4j==0.10.7 \\\n && python -mpip install matplotlib==2.2.3 \\\n && pip install pandas==0.23.4 \\\n && pip install seaborn==0.9.0 \\\n && pip install google-api-core==1.5.0 \\\n && pip install google-cloud-bigquery==1.7.0 \\\n && pip install google-cloud-bigquery-datatransfer==0.1.1 \\\n && pip install google-cloud-core==0.28.1 \\\n && pip install google-cloud-datastore==1.7.0 \\\n && pip install google-cloud-resource-manager==0.28.1 \\\n && pip install google-cloud-storage==1.13.0 \\\n && pip install google-auth==1.5.1 \\\n && pip install firecloud==0.16.18 --ignore-installed \\\n && pip install scikit-learn==0.20.0 -U \\\n && pip install statsmodels==0.9.0 \\\n && pip install ggplot==0.11.5 \\\n && sed -i 's/pandas.lib/pandas/g' /usr/local/lib/python2.7/dist-packages/ggplot/stats/smoothers.py \\\n && pip install bokeh==1.0.0 \\\n && pip install pyfasta==0.5.2 \\\n && pip install pdoc==0.3.2 \\\n && pip install biopython==1.72 \\\n && pip install bx-python==0.8.2 \\\n && pip install fastinterval==0.1.1 \\\n && pip install matplotlib-venn==0.11.5 \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   Python 3 Kernel\nENV PYTHON_VERSION=\"3.6.8\"\n#   lifted from https://github.com/docker-library/python/blob/dd36c08c1f94083476a8579b8bf20c4cd46c6400/3.6/stretch/Dockerfile\nRUN set -ex \\\n && wget -O python.tar.xz \"https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz\" \\\n && wget -O python.tar.xz.asc \"https://www.python.org/ftp/python/${PYTHON_VERSION%%[a-z]*}/Python-$PYTHON_VERSION.tar.xz.asc\" \\\n && export GNUPGHOME=\"$( mktemp -d ;)\" \\\n && gpg --batch --keyserver keyserver.ubuntu.com --recv-keys \"0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D\" \\\n && gpg --batch --verify python.tar.xz.asc python.tar.xz \\\n && { command -v gpgconf > /dev/null \\\n && gpgconf --kill all || : ; } \\\n && rm -rf \"$GNUPGHOME\" python.tar.xz.asc \\\n && mkdir -p /usr/src/python \\\n && tar -xJC /usr/src/python --strip-components=1 -f python.tar.xz \\\n && rm python.tar.xz \\\n && cd /usr/src/python \\\n && gnuArch=\"$( dpkg-architecture --query DEB_BUILD_GNU_TYPE ;)\" \\\n && ./configure --build=\"$gnuArch\" --enable-loadable-sqlite-extensions --enable-shared --with-system-expat --with-system-ffi --without-ensurepip \\\n && make -j \"$( nproc ;)\" \\\n && make install \\\n && ldconfig \\\n && find /usr/local -depth\n#   make some useful symlinks that are expected to exist\nRUN cd /usr/local/bin \\\n && ln -s idle3 idle \\\n && ln -s pydoc3 pydoc \\\n && ln -s python3 python \\\n && ln -s python3-config python-config\n#   if this is called \"PIP_VERSION\", pip explodes with \"ValueError: invalid truth value '<VERSION>'\"\nENV PYTHON_PIP_VERSION=\"19.0.1\"\nRUN set -ex ; wget -O get-pip.py 'https://bootstrap.pypa.io/get-pip.py' ; python get-pip.py --disable-pip-version-check --no-cache-dir \"pip==$PYTHON_PIP_VERSION\" ; pip --version ; find /usr/local -depth\nRUN apt-get update \\\n && apt-get install --no-install-recommends testing nodejs npm -t -yq \\\n && pip3 install tornado==4.5.3 \\\n && pip3 install -U decorator==4.3.0 \\\n && pip3 install parsimonious==0.8.1 \\\n && pip3 install numpy==1.15.2 \\\n && pip3 install py4j==0.10.7 \\\n && python3 -mpip install matplotlib==3.0.0 \\\n && pip3 install pandas==0.23.4 \\\n && pip3 install seaborn==0.9.0 \\\n && pip3 install jupyter==1.0.0 \\\n && pip3 install jupyterlab==0.35.4 \\\n && pip3 install python-lzo==1.12 \\\n && pip3 install google-api-core==1.5.0 \\\n && pip3 install google-cloud-bigquery==1.7.0 \\\n && pip3 install google-cloud-bigquery-datatransfer==0.1.1 \\\n && pip3 install google-cloud-core==0.28.1 \\\n && pip3 install google-cloud-datastore==1.7.0 \\\n && pip3 install google-cloud-resource-manager==0.28.1 \\\n && pip3 install google-cloud-storage==1.13.0 \\\n && pip3 install --ignore-installed firecloud==0.16.18 \\\n && pip3 install scikit-learn==0.20.0 \\\n && pip3 install statsmodels==0.9.0 \\\n && pip3 install ggplot==0.11.5 \\\n && sed -i 's/pandas.lib/pandas/g' /usr/local/lib/python3.6/site-packages/ggplot/stats/smoothers.py \\\n && pip3 install bokeh==1.0.0 \\\n && pip3 install pyfasta==0.5.2 \\\n && pip3 install pdoc==0.3.2 \\\n && pip3 install biopython==1.72 \\\n && pip3 install bx-python==0.8.2 \\\n && pip3 install fastinterval==0.1.1 \\\n && pip3 install matplotlib-venn==0.11.5 \\\n && pip3 install bleach==1.5.0 \\\n && pip3 install cycler==0.10.0 \\\n && pip3 install enum34==1.1.6 \\\n && pip3 install h5py==2.7.1 \\\n && pip3 install html5lib==0.9999999 \\\n && pip3 install joblib==0.11 \\\n && pip3 install keras==2.2.0 \\\n && pip3 install markdown==2.6.9 \\\n && pip3 install patsy==0.4.1 \\\n && pip3 install protobuf==3.7.1 \\\n && pip3 install pymc3==3.1 \\\n && pip3 install pyparsing==2.2.0 \\\n && pip3 install pysam==0.13 \\\n && pip3 install python-dateutil==2.6.1 \\\n && pip3 install pytz==2017.3 \\\n && pip3 install pyvcf==0.6.8 \\\n && pip3 install pyyaml==3.12 \\\n && pip3 install scipy==1.0.0 \\\n && pip3 install six==1.11.0 \\\n && pip3 install tensorflow==1.9.0 \\\n && pip3 install theano==0.9.0 \\\n && pip3 install tqdm==4.19.4 \\\n && pip3 install werkzeug==0.12.2 \\\n && pip3 install certifi==2016.2.28 \\\n && pip3 install intel-openmp==2018.0.0 \\\n && pip3 install mkl==2018.0.3 \\\n && pip3 install readline==6.2 \\\n && pip3 install setuptools==36.4.0 \\\n && pip3 install wheel \\\n && pip3 install python-datauri \\\n && pip3 install jupyter_contrib_nbextensions \\\n && pip3 install jupyter_nbextensions_configurator \\\n && pip3 install /etc/gatk-$GATK_VERSION/gatkPythonPackageArchive.zip \\\n && pip3 install cookiecutter \\\n && apt-get clean \\\n && rm -rf /var/lib/apt/lists/*\n#   make pip install to a user directory, instead of a system directory which requires root.\n#   this is useful so `pip install` commands can be run in the context of a notebook.\nENV PIP_USER=\"true\"\n#  ######################\n#   R Kernel\n#  ######################\n#   using aptitude for R packages so that all dependencies are automatically installed\nRUN aptitude update \\\n && aptitude install -y apt-utils \\\n && aptitude update \\\n && aptitude -t stretch-cran35 install -y r-base=3.5.2-1 r-base-dev=3.5.2-1 r-base-core=3.5.2-1 r-recommended=3.5.2-1 \\\n && aptitude install -t stretch-cran35 -y fonts-dejavu tzdata gfortran gcc libcurl4 libcurl4-openssl-dev libssl-dev libxml2-dev \\\n && aptitude clean \\\n && rm -rf /var/lib/apt/lists/* \\\n && ln -s /usr/lib/x86_64-linux-gnu/libgfortran.so.3 /usr/lib/x86_64-linux-gnu/libgfortran.so\nRUN R -e 'install.packages(c( \"IRdisplay\", \"evaluate\", \"pbdZMQ\", \"devtools\", \"uuid\", \"reshape2\", \"bigrquery\", \"googleCloudStorageR\", \"tidyverse\"), repos=\"http://cran.mtu.edu\")' \\\n && R -e 'devtools::install_github(\"DataBiosphere/Ronaldo\")' \\\n && R -e 'devtools::install_github(\"IRkernel/IRkernel\")' \\\n && R -e 'IRkernel::installspec(user=FALSE)' \\\n && chown -R $USER:users /home/jupyter-user/.local \\\n && R -e 'devtools::install_github(\"apache/spark@v2.2.3\", subdir=\"R/pkg\")' \\\n && mkdir -p /home/jupyter-user/.rpackages \\\n && echo \"R_LIBS=/home/jupyter-user/.rpackages\" > /home/jupyter-user/.Renviron \\\n && chown -R $USER:users /home/jupyter-user/.rpackages\n#  ######################\n#   Utilities\n#  ######################\nADD scripts $JUPYTER_HOME/scripts\nADD custom/jupyter_delocalize.py $JUPYTER_HOME/custom/\nADD custom/jupyter_localize_extension.py $JUPYTER_HOME/custom/\nRUN chown -R $USER:users $JUPYTER_HOME \\\n && find $JUPYTER_HOME/scripts -name '*.sh' -type f | xargs chmod +x \\\n && chown -R $USER:users /usr/local/share/jupyter/lab \\\n && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-6 200 \\\n && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 100\nUSER $USER\nWORKDIR $HOME\nEXPOSE $JUPYTER_PORT\n#   Note: this entrypoint is provided for running Jupyter independently of Leonardo.\n#   When Leonardo deploys this image onto a cluster, the entrypoint is overwritten to enable\n#   additional setup inside the container before execution.  Jupyter execution occurs when the\n#   init-actions.sh script uses 'docker exec' to call run-jupyter.sh.\nENTRYPOINT [\"/usr/local/bin/jupyter\", \"notebook\"]\n","originalDockerfileUglifiedHash":"7531a330fdcc433b12f3d4d7223030eb","fileName":"/ICSME-replicationpackage/dataset/smelly_dockerfiles_bianncle/8176a58e00921bbda8c8a91b8a7191fb997d76dd.dockerfile"}